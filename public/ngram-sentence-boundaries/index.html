<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-01-20">

<title>skeptric - Sentence Boundaries in N-gram Language Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">skeptric</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/EdwardJRoss"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Sentence Boundaries in N-gram Language Models</h1>
  <div class="quarto-categories">
    <div class="quarto-category">nlp</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 20, 2021</p>
    </div>
  </div>
    
  </div>
  

</header>

<p>An N-gram language model guesses the next possible word by looking at how frequently is has previously occurred after the previous N-1 words. I think this is how my mobile phone suggests completions of text; if I type “I am” it suggests “glad”, “not” or “very” which are likely occurrences. To make everything add up you have to have special markers for the start and end of the sentence, and the I think the best way is to make them <em>the same marker</em>.</p>
<p>I’m reading through the December 30, 2020 draft of <a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing, by Jurafsky and Martin</a>, in particular Chapter 3 <em>N-gram Language Models</em>. To create the language model you simply count how often each word follows the previous N-1 words to create a count matrix, and then normalise each row to 1 so it’s a conditional probability. Then, under the assumption that the probability of a word just depends on the previous N-1 words, you can calculate the probability of every sentence. As shown in Exercise 3.5 of the text if you don’t have an end sentence marker then the probabilities over every possible sentence don’t add up to 1.</p>
<p>As an example consider the corpus of two sentences, with the special markers to start a sentence, <code>&lt;s&gt;</code>, and end a sentence <code>&lt;/s&gt;</code>:</p>
<pre><code>&lt;s&gt; I am Sam &lt;/s&gt;
&lt;s&gt; Sam I am &lt;/s&gt;</code></pre>
<p>Then we can generate the counts for a bigram model on words (i.e.&nbsp;N=2), with the first word on the left</p>
<table class="table">
<thead>
<tr class="header">
<th><strong>Counts</strong></th>
<th>&lt;s&gt;</th>
<th>I</th>
<th>am</th>
<th>Sam</th>
<th>&lt;/s&gt;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;s&gt;</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td>I</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>am</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>Sam</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>&lt;/s&gt;</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Notice that structurally the first column and last row <em>have</em> to be zero; a start sentence marker can never occur after any token and no token can follow the end sentence marker. Now if we wanted to use add-k smoothing to allow for combinations of words not in the text, then we can’t add k to the first column or last row, but we want to add it to every other cell. I suggest instead unifying <code>&lt;s&gt;</code> and <code>&lt;/s&gt;</code> as the same token, giving the count matrix:</p>
<table class="table">
<thead>
<tr class="header">
<th><strong>Counts</strong></th>
<th>&lt;s&gt;</th>
<th>I</th>
<th>am</th>
<th>Sam</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;s&gt;</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td>I</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>0</td>
</tr>
<tr class="odd">
<td>am</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td>Sam</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>In this matrix any cell can be non-zero, as long as we allow empty sentences <code>&lt;s&gt; &lt;s&gt;</code>. In this case we can convert them to conditional probabilities by dividing each row by its sum:</p>
<table class="table">
<thead>
<tr class="header">
<th><strong>P(column | row)</strong></th>
<th>&lt;s&gt;</th>
<th>I</th>
<th>am</th>
<th>Sam</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;s&gt;</td>
<td>0</td>
<td>0.5</td>
<td>0</td>
<td>0.5</td>
</tr>
<tr class="even">
<td>I</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>am</td>
<td>0.5</td>
<td>0</td>
<td>0</td>
<td>0.5</td>
</tr>
<tr class="even">
<td>Sam</td>
<td>0</td>
<td>0.5</td>
<td>0.5</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>We can use this to calculate the probability of any sentence under the bigram model, for example the sentence <code>&lt;s&gt; Sam I am &lt;s&gt;</code> has probability (using <code>.</code> in place of <code>&lt;s&gt;</code>)</p>
<p><span class="math display">\[P(\rm{Sam\ I\ am}) = P(\rm{Sam} \vert .) P(\rm{I} \vert \rm{Sam}) P(\rm{am} \vert \rm{I}) P(. \vert \rm{am})= 0.5 \times 0.5 \times 1 \times 0.5 = 0.125\]</span></p>
<p>Note this generalises and we can get sentences like <code>&lt;s&gt; I am &lt;s&gt;</code> or <code>&lt;s&gt; Sam I am Sam am &lt;s&gt;</code>, but we can’t possibly get <code>&lt;s&gt; am I Sam &lt;s&gt;</code> since <span class="math inline">\(P(\rm{am}| .) = 0\)</span>.</p>
<p>The add-k method adds a constant k to every element of the matrix. As discussed we can only do this naively if we’ve got a single sentence boundary token.</p>
<table class="table">
<thead>
<tr class="header">
<th><strong>Add 0.5 counts</strong></th>
<th>&lt;s&gt;</th>
<th>I</th>
<th>am</th>
<th>Sam</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;s&gt;</td>
<td>0.5</td>
<td>1.5</td>
<td>0.5</td>
<td>1.5</td>
</tr>
<tr class="even">
<td>I</td>
<td>0.5</td>
<td>0.5</td>
<td>2.5</td>
<td>0.5</td>
</tr>
<tr class="odd">
<td>am</td>
<td>1.5</td>
<td>0.5</td>
<td>0.5</td>
<td>1.5</td>
</tr>
<tr class="even">
<td>Sam</td>
<td>0.5</td>
<td>1.5</td>
<td>1.5</td>
<td>0.5</td>
</tr>
</tbody>
</table>
<p>We can then normalise these into probabilities:</p>
<table class="table">
<thead>
<tr class="header">
<th>**P*(column | row)**</th>
<th>&lt;s&gt;</th>
<th>I</th>
<th>am</th>
<th>Sam</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;s&gt;</td>
<td>0.125</td>
<td>0.375</td>
<td>0.125</td>
<td>0.375</td>
</tr>
<tr class="even">
<td>I</td>
<td>0.125</td>
<td>0.125</td>
<td>0.625</td>
<td>0.125</td>
</tr>
<tr class="odd">
<td>am</td>
<td>0.375</td>
<td>0.125</td>
<td>0.125</td>
<td>0.375</td>
</tr>
<tr class="even">
<td>Sam</td>
<td>0.125</td>
<td>0.375</td>
<td>0.375</td>
<td>0.125</td>
</tr>
</tbody>
</table>
<p>Now any combination of the words is possible, even the empty sentence <code>&lt;s&gt; &lt;s&gt;</code> (with probability 12.5%).</p>
<p>If we move to a higher order model such as a trigram model we need to add more padding tokens <em>at the start of the sentence</em>, which again should all be the same. For example with our corpus the counts would look like:</p>
<pre><code>&lt;s&gt; &lt;s&gt; I am Sam &lt;s&gt;
&lt;s&gt; &lt;s&gt; Sam I am &lt;s&gt;</code></pre>
<table class="table">
<thead>
<tr class="header">
<th><strong>Counts</strong></th>
<th>&lt;s&gt;</th>
<th>I</th>
<th>am</th>
<th>Sam</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;s&gt; &lt;s&gt;</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td>&lt;s&gt; I</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>&lt;s&gt; Sam</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>I am</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>am Sam</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Sam I</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Note that we don’t want an additional padding token at the end, because given any token followed by <code>&lt;s&gt;</code> the next token must be constrained to be <code>&lt;s&gt;</code>.</p>
<p>This is one of those little tricks in how you frame a problem that makes the calculations much easier in practice.</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>