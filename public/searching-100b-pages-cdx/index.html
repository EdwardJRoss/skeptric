<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2020-06-11">

<title>skeptric - Searching 100 Billion Webpages Pages With Capture Index</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">skeptric</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/EdwardJRoss"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Searching 100 Billion Webpages Pages With Capture Index</h1>
  <div class="quarto-categories">
    <div class="quarto-category">commoncrawl</div>
    <div class="quarto-category">data</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 11, 2020</p>
    </div>
  </div>
    
  </div>
  

</header>

<p><a href="https://commoncrawl.org">Common Crawl</a> builds an open dataset containing <a href="https://commoncrawl.github.io/cc-crawl-statistics/plots/crawlsize">over 100 billion unique items</a> downloaded from the internet. Every month they use <a href="http://nutch.apache.org/">Apache Nutch</a> to follow links accross the web and download over a billion unique items to Amazon S3, and have data back to 2008. This is like what Google and Bing do to build their search engines, the difference being that Common Crawl provides their data to the world for free.</p>
<p>But how do you find for a particular webpage in petabytes of data? Common Crawl provides two types of indexes for this: the <a href="https://index.commoncrawl.org/">Common Crawl Capture Index (CDX)</a> and the <a href="https://commoncrawl.org/2018/03/index-to-warc-files-and-urls-in-columnar-format/">Columnar Index</a>. This article talks about the CDX Index Server and a future article will talk about the more powerful columnar index.</p>
<p>Common Crawl tries to do a broad search, getting a wide sample of the web rather than a deep sample of a few websites, and respects <a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard">robots.txt</a> so not every page will be in there. It’s useful to know whether Common Crawl even contains the information you’re looking before you start, and the index will tell you where to look.</p>
<p>This article covers <a href="#using-the-web-interface">using the web interface</a> for quickly checking what’s there, <a href="#cdx-toolkit">using cdx_toolkit</a> to get and download results from the command line or Python, and <a href="#using-the-index-directly">using the index and fetching with HTTP requests</a> for custom usecases. There are other tools as well like the <a href="https://github.com/ikreymer/cdx-index-client/">CDX Index Client</a> for command line use and <a href="$searching-and-fetching-with-python-and-comcrawl">comcrawl from python</a>, but they seem less flexible than the other options.</p>
<p>See the corresponding <a href="../notebooks/Searching Common Crawl Index.html">Jupyter notebook</a> (<a href="https://nbviewer.org/github/EdwardJRoss/skeptric/blob/master/static/notebooks/Searching%20Common%20Crawl%20Index.ipynb">raw</a>) for more code examples.</p>
<section id="using-the-web-interface" class="level1">
<h1>Using the Web Interface</h1>
<p>Go to <a href="https://index.commoncrawl.org/">the Common Crawl Index Server</a> and select a Search Page from the left column. Note that the crawl names are <code>CC-MAIN-&lt;YYYY&gt;-&lt;WW&gt;</code> where <code>&lt;YYYY&gt;-&lt;WW&gt;</code> is the crawl <a href="https://en.wikipedia.org/wiki/ISO_8601#Week_dates">ISO 8601 Week Date</a>. Then you can type your website and can have a wildcard at the end of the URL or in the domain. It will then return JSON lines of results showing the URLs and the metadata you need to find them.</p>
<p>For example in the <a href="https://index.commoncrawl.org/CC-MAIN-2020-16">2020-16 crawl</a> if I type <code>https://www.reddit.com/r/dataisbeautiful/*</code> I get <a href="https://index.commoncrawl.org/CC-MAIN-2020-16-index?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fdataisbeautiful%2F*&amp;output=json">43 results</a>. I can see the first result is https://www.reddit.com/r/dataisbeautiful/comments/718wt7/heatmap_of_my_location_during_last_2_years_living/, that the HTTP status was 200 (it was successfully retrieved) and that the archived HTML is available in segment 1585370497042.33.</p>
<p>I could also look for all subdomains of a particular domain. For example Learn Bayes Stats has a website https://learnbayesstats.anvil.app/ which is a subdomain of <code>anvil.app</code>. We can find other websites created with anvil by searching for <a href="https://index.commoncrawl.org/CC-MAIN-2020-16-index?url=*.anvil.app&amp;output=json"><code>*.anvil.app</code></a> giving 48 results.</p>
</section>
<section id="cdx-toolkit" class="level1">
<h1>CDX Toolkit</h1>
<p><a href="https://github.com/cocrawler/cdx_toolkit/">CDX Toolkit</a> gives a way to search the indexes of both Common Crawl and Internet Archive in a straightforward way. It provides a useful command line and Python interface, and is highly flexible and relatively straightforward to use. I would recommend it as a starting point with Common Crawl, but haven’t tested it’s speed on large amounts of data. It’s easy to install with <code>python -m pip install cdx_toolkit</code>.</p>
<section id="cdx-toolkit-in-the-command-line" class="level2">
<h2 class="anchored" data-anchor-id="cdx-toolkit-in-the-command-line">CDX Toolkit in the Command Line</h2>
<p>You can use it from the command line with <code>cdxt</code>. You can specify a range of dates in the form YYYYMM (not weeks like in the index files!), and whether to return a CSV (default) or lines of JSON:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">cdxt</span> <span class="at">--cc</span> <span class="at">--from</span> 202002 <span class="at">--to</span> 202005 iter <span class="dt">\</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">'https://www.reddit.com/r/dataisbeautiful/*'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can pass other arguments to filter the result or customise the fields returned. Here’s an example to count the number of archived pages in dataisbeautiful fetched with <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200">200 OK</a> status between Feb and May 2020 (I removed query parameters with <code>sed</code> because here they are just tracking tags).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">cdxt</span> <span class="at">--cc</span> <span class="at">--from</span> 202002 <span class="at">--to</span> 202005 <span class="dt">\</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">--filter</span> <span class="st">'=status:200'</span> iter <span class="dt">\</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>     <span class="st">'https://www.reddit.com/r/dataisbeautiful/*'</span> <span class="dt">\</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">--fields</span> url <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sed</span> <span class="st">'s/\?.*//'</span> <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sort</span> <span class="at">-u</span> <span class="kw">|</span> <span class="dt">\</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">wc</span> <span class="at">-l</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can easily switch from Common Crawl with <code>-cc</code> to the <a href="https://archive.org/web/">Internet Archive’s Wayback Machine</a> with <code>-ia</code> (but it doesn’t support all the same filters).</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">cdxt</span> <span class="at">--ia</span> <span class="at">--from</span> 202002 <span class="at">--to</span> 202005 iter <span class="dt">\</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">'https://www.reddit.com/r/dataisbeautiful/*'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can download the Web Archive content using the <code>warc</code> subcommand.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">cdxt</span> <span class="at">--cc</span> <span class="at">--from</span> 202002 <span class="at">--to</span> 202005 <span class="dt">\</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">--filter</span> <span class="st">'=status:200'</span> <span class="at">--limit</span> 10 warc <span class="dt">\</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">--prefix</span> DATAISBEAUTIFUL <span class="dt">\</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>     <span class="st">'https://www.reddit.com/r/dataisbeautiful/*'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A bunch of <code>None</code>s get printed to the screen and produces a file <code>DATAISBEAUTIFUL-000000.extracted.warc.gz</code>. A WARC is essentially the HTML preceded by some headers containing metadata about the request and the response. It’s simple enough that you could parse it manually, or you could use the Python <a href="https://github.com/webrecorder/warcio">warcio library</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/cc_cdxt_warc.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Sample of WARC Output</figcaption><p></p>
</figure>
</div>
</section>
<section id="cdx-toolkit-in-python" class="level2">
<h2 class="anchored" data-anchor-id="cdx-toolkit-in-python">CDX Toolkit in Python</h2>
<p>You can also use the CDX Toolkit as a library in Python. The API for the <code>CDXFetcher</code> is similar to the CLI except <code>from</code> becomes <code>from_ts</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cdx_toolkit</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>cdx <span class="op">=</span> cdx_toolkit.CDXFetcher(source<span class="op">=</span><span class="st">'cc'</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>objs <span class="op">=</span> <span class="bu">list</span>(cdx.<span class="bu">iter</span>(url, from_ts<span class="op">=</span><span class="st">'202002'</span>, to<span class="op">=</span><span class="st">'202006'</span>, </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>                     limit<span class="op">=</span><span class="dv">5</span>, <span class="bu">filter</span><span class="op">=</span><span class="st">'=status:200'</span>))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>[o.data <span class="cf">for</span> o <span class="kw">in</span> objs]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 22%">
<col style="width: 3%">
<col style="width: 1%">
<col style="width: 2%">
<col style="width: 25%">
<col style="width: 2%">
<col style="width: 24%">
<col style="width: 1%">
<col style="width: 1%">
<col style="width: 7%">
<col style="width: 2%">
<col style="width: 3%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">urlkey</th>
<th style="text-align: right;">timestamp</th>
<th style="text-align: right;">status</th>
<th style="text-align: left;">mime</th>
<th style="text-align: left;">url</th>
<th style="text-align: left;">languages</th>
<th style="text-align: left;">filename</th>
<th style="text-align: right;">length</th>
<th style="text-align: left;">charset</th>
<th style="text-align: left;">digest</th>
<th style="text-align: right;">offset</th>
<th style="text-align: left;">mime-detected</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/718wt7/heatmap_of_my_location_during_last_2_years_living</td>
<td style="text-align: right;">20200330143847</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/718wt7/heatmap_of_my_location_during_last_2_years_living/</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-16/segments/1585370497042.33/warc/CC-MAIN-20200330120036-20200330150036-00407.warc.gz</td>
<td style="text-align: right;">69934</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">K7RHDCY4H6XIAFL7SLFTMUV76XFOEM7K</td>
<td style="text-align: right;">1143289534</td>
<td style="text-align: left;">text/html</td>
</tr>
<tr class="even">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/7wcyiq/this_is_what_8_months_of_roulette_looks_like_oc</td>
<td style="text-align: right;">20200408190429</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/7wcyiq/this_is_what_8_months_of_roulette_looks_like_oc/</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-16/segments/1585371821680.80/warc/CC-MAIN-20200408170717-20200408201217-00043.warc.gz</td>
<td style="text-align: right;">85936</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">3VQ6OENLZIZGFNY7X3TIYNOYMGLABZFR</td>
<td style="text-align: right;">1099976248</td>
<td style="text-align: left;">text/html</td>
</tr>
<tr class="odd">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/c89mz2/battle_dataviz_battle_for_the_month_of_july_2019/eskzdhd</td>
<td style="text-align: right;">20200403174615</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/c89mz2/battle_dataviz_battle_for_the_month_of_july_2019/eskzdhd/</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-16/segments/1585370515113.54/warc/CC-MAIN-20200403154746-20200403184746-00236.warc.gz</td>
<td style="text-align: right;">23114</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">IS4SLLIK7QHNEAJ23E7H4H5ZK2HEMME3</td>
<td style="text-align: right;">1080275232</td>
<td style="text-align: left;">text/html</td>
</tr>
<tr class="even">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/csl706/i_recorded_my_travels_as_a_professional_truck</td>
<td style="text-align: right;">20200404003226</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/csl706/i_recorded_my_travels_as_a_professional_truck/</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-16/segments/1585370518767.60/warc/CC-MAIN-20200403220847-20200404010847-00342.warc.gz</td>
<td style="text-align: right;">81851</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">3BP6SQLMDA3EHICA5TRBNFBCRNDPEOLT</td>
<td style="text-align: right;">1106586323</td>
<td style="text-align: left;">text/html</td>
</tr>
<tr class="odd">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/dp5tda/oc_i_cycled_through_all_the_streets_central_london</td>
<td style="text-align: right;">20200331141918</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/dp5tda/oc_i_cycled_through_all_the_streets_central_london/</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-16/segments/1585370500482.27/warc/CC-MAIN-20200331115844-20200331145844-00166.warc.gz</td>
<td style="text-align: right;">79999</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">POVTU3VOPDUU2CAB2OWZTTBVYGM7HMFX</td>
<td style="text-align: right;">1104520094</td>
<td style="text-align: left;">text/html</td>
</tr>
</tbody>
</table>
<p>The raw archived HTML can be retrieved with <code>.content</code>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> objs[<span class="dv">0</span>].content</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(html, <span class="st">'lxml'</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>soup.head.title.text</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also get the <a href="https://github.com/webrecorder/warcio">warcio object</a> with <code>.warc_record</code></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>objs[<span class="dv">0</span>].warc_record.rec_headers.get_header(<span class="st">'WARC-Target-URI'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="using-the-index-directly" class="level1">
<h1>Using the index directly</h1>
<p>The Capture Index (CDX) API is just a HTTP endpoint for a compressed text file giving describing the underlying Web Archives. Common Crawl use <a href="https://github.com/webrecorder/pywb/wiki/CDX-Server-API">pywb</a> to serve the index and have a great <a href="https://commoncrawl.org/2015/04/announcing-the-common-crawl-index/">introductory blog post to CDX</a>. You can access it directly with <code>curl</code> or the Python <code>requests</code> library.</p>
<p>Doing it yourself you have to find the right collections, deal with pagination and retrieve and decompress the content. This is what CDX toolkit handles for you, but sometimes it might be useful to do it directly.</p>
<section id="getting-the-available-collections" class="level2">
<h2 class="anchored" data-anchor-id="getting-the-available-collections">Getting the available collections</h2>
<p>First we need to know what indexes are available; this is stored in a JSON file called <code>collinfo.json</code>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>cdx_indexes <span class="op">=</span> requests.get(<span class="st">'https://index.commoncrawl.org/collinfo.json'</span>).json()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This contains JSON data with the id, description, and API locations for each crawl.</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 20%">
<col style="width: 32%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">id</th>
<th style="text-align: left;">name</th>
<th style="text-align: left;">timegate</th>
<th style="text-align: left;">cdx-api</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">CC-MAIN-2020-24</td>
<td style="text-align: left;">May 2020 Index</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2020-24/</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2020-24-index</td>
</tr>
<tr class="even">
<td style="text-align: left;">CC-MAIN-2020-16</td>
<td style="text-align: left;">March 2020 Index</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2020-16/</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2020-16-index</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CC-MAIN-2020-10</td>
<td style="text-align: left;">February 2020 Index</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2020-10/</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2020-10-index</td>
</tr>
<tr class="even">
<td style="text-align: left;">CC-MAIN-2020-05</td>
<td style="text-align: left;">January 2020 Index</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2020-05/</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2020-05-index</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CC-MAIN-2019-51</td>
<td style="text-align: left;">December 2019 Index</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2019-51/</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2019-51-index</td>
</tr>
<tr class="even">
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CC-MAIN-2008-2009</td>
<td style="text-align: left;">Index of 2008 - 2009 ARC files</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2008-2009/</td>
<td style="text-align: left;">https://index.commoncrawl.org/CC-MAIN-2008-2009-index</td>
</tr>
</tbody>
</table>
<p>If we want to look through multiple collections we would have to query each API endpoint separately. Note that really old indexes use a different id format with a range of years.</p>
<p>Let’s pick the most recent crawl’s API endpoint.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>api_url <span class="op">=</span> cdx_indexes[<span class="dv">0</span>][<span class="st">'cdx-api'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="simple-cdx-query" class="level2">
<h2 class="anchored" data-anchor-id="simple-cdx-query">Simple CDX Query</h2>
<p>We can then use the <code>cdx-api</code> URL to query the relevant indexes.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.get(api_url,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                 params <span class="op">=</span> {</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'url'</span>: <span class="st">'reddit.com'</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'limit'</span>: <span class="dv">10</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'output'</span>: <span class="st">'json'</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>                 })</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>records <span class="op">=</span> [json.loads(line) <span class="cf">for</span> line <span class="kw">in</span> r.text.split(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>) <span class="cf">if</span> line]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The JSON records look the same as</p>
<table class="table">
<colgroup>
<col style="width: 4%">
<col style="width: 5%">
<col style="width: 3%">
<col style="width: 2%">
<col style="width: 3%">
<col style="width: 11%">
<col style="width: 2%">
<col style="width: 5%">
<col style="width: 40%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 8%">
<col style="width: 3%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">urlkey</th>
<th style="text-align: right;">timestamp</th>
<th style="text-align: right;">offset</th>
<th style="text-align: right;">status</th>
<th style="text-align: left;">languages</th>
<th style="text-align: left;">digest</th>
<th style="text-align: right;">length</th>
<th style="text-align: left;">mime-detected</th>
<th style="text-align: left;">filename</th>
<th style="text-align: left;">charset</th>
<th style="text-align: left;">mime</th>
<th style="text-align: left;">url</th>
<th style="text-align: right;">redirect</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">com,reddit)/</td>
<td style="text-align: right;">20200525024432</td>
<td style="text-align: right;">873986269</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">C6Y4VCGYLE3NGEWLJNONES6JMNA74IA3</td>
<td style="text-align: right;">40851</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-24/segments/1590347387155.10/warc/CC-MAIN-20200525001747-20200525031747-00335.warc.gz</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/</td>
<td style="text-align: right;">nan</td>
</tr>
<tr class="even">
<td style="text-align: left;">com,reddit)/</td>
<td style="text-align: right;">20200526071834</td>
<td style="text-align: right;">787273867</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">PHMHCKU365PLDN5UQETZVR4UGMSPDXQJ</td>
<td style="text-align: right;">42855</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-24/segments/1590347390448.11/warc/CC-MAIN-20200526050333-20200526080333-00335.warc.gz</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/</td>
<td style="text-align: right;">nan</td>
</tr>
<tr class="odd">
<td style="text-align: left;">com,reddit)/</td>
<td style="text-align: right;">20200526163829</td>
<td style="text-align: right;">3815970</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">X67YXUXXE5GQPMJKMEE6555BNFPIER7L</td>
<td style="text-align: right;">35345</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-24/segments/1590347391277.13/robotstxt/CC-MAIN-20200526160400-20200526190400-00048.warc.gz</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com</td>
<td style="text-align: right;">nan</td>
</tr>
<tr class="even">
<td style="text-align: left;">com,reddit)/</td>
<td style="text-align: right;">20200526165552</td>
<td style="text-align: right;">879974740</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">OSGHIVCFBI47ZSNMLG574K6SBZJ3LTBC</td>
<td style="text-align: right;">39146</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-24/segments/1590347391277.13/warc/CC-MAIN-20200526160400-20200526190400-00335.warc.gz</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/</td>
<td style="text-align: right;">nan</td>
</tr>
<tr class="odd">
<td style="text-align: left;">com,reddit)/</td>
<td style="text-align: right;">20200527211917</td>
<td style="text-align: right;">858583595</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">UHM2VERG5OUOELJFD7O25JVUBZVDPDLU</td>
<td style="text-align: right;">35751</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-24/segments/1590347396163.18/warc/CC-MAIN-20200527204212-20200527234212-00335.warc.gz</td>
<td style="text-align: left;">UTF-8</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/</td>
<td style="text-align: right;">nan</td>
</tr>
</tbody>
</table>
<p>Of course you can also query the endpoint directly with curl to get the JSON lines:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">curl</span> <span class="st">'https://index.commoncrawl.org/CC-MAIN-2020-24-index?url=reddit.com&amp;limit=10&amp;output=json'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="adding-filters-and-options" class="level2">
<h2 class="anchored" data-anchor-id="adding-filters-and-options">Adding filters and options</h2>
<p>We can add additional options like <a href="https://github.com/webrecorder/pywb/wiki/CDX-Server-API#filter">filters</a> and selecting fields, in the same way exposed by cdx_toolkit. Here we filter to results with a status of 200, that were detected to have mime text/html and that have a URL matching the regex <code>.*/comments/</code> (so have <code>/comments/</code> somewhere in the URL).</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.get(api_url,</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>                 params <span class="op">=</span> {</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'url'</span>: <span class="st">'https://www.reddit.com/r/*'</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'limit'</span>: <span class="dv">10</span>,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'output'</span>: <span class="st">'json'</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'fl'</span>: <span class="st">'url,filename,offset,length'</span>,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'filter'</span>: [<span class="st">'=status:200'</span>, </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'=mime-detected:text/html'</span>,</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'~url:.*/comments/'</span>]</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>                 })</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>records <span class="op">=</span> [json.loads(line) <span class="cf">for</span> line <span class="kw">in</span> r.text.split(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>) <span class="cf">if</span> line]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="handling-zero-results" class="level2">
<h2 class="anchored" data-anchor-id="handling-zero-results">Handling zero results</h2>
<p>When there are no results then the response is a 404 with a JSON error message “No Captures found …”.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.get(api_url,</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>                 params <span class="op">=</span> {</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'url'</span>: <span class="st">'skeptric.com/*'</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'output'</span>: <span class="st">'json'</span>,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>                 })</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>r.status_code  <span class="co"># 404</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>r.json()       <span class="co"># {'error': 'No Captures found for: skeptric.com/*'}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="dealing-with-pagination" class="level2">
<h2 class="anchored" data-anchor-id="dealing-with-pagination">Dealing with Pagination</h2>
<p>The Common Crawl API by default returns around 15,000 records per page (it’s 5 compressed blocks, which can vary in the number of actual records). You can choose the number of compressed blocks it returns (about 3,000 records per block) with <code>pageSize</code> and the page number with <code>page</code>.</p>
<p>To find the total number of pages you can use the <code>showNumPages=True</code> parameter, which gives back a JSON object containing the <code>pageSize</code>, <code>blocks</code> (total compressed blocks of data) and <code>pages</code> to return. The <code>pageSize</code> is in blocks, so <code>pages = math.ceil(blocks/pageSize)</code>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.get(api_url,</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>                 params <span class="op">=</span> {</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'url'</span>: <span class="st">'*.wikipedia.org'</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'output'</span>: <span class="st">'json'</span>,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'showNumPages'</span>: <span class="va">True</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>                 })</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>r.json()  <span class="co"># {'pageSize': 5, 'blocks': 2044, 'pages': 409}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can then iterate from <code>page</code> 0 to <code>pages - 1</code>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.get(api_url,</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>                 params <span class="op">=</span> {</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'url'</span>: <span class="st">'*.wikipedia.org'</span>,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'output'</span>: <span class="st">'json'</span>,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'page'</span>: <span class="dv">2</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                 })</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>When you go past the end of the pages you will get a HTTP 400 error response. You could use this to avoid having to ask the number of pages up front, just iterate until you get an error.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.get(api_url,</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>                 params <span class="op">=</span> {</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'url'</span>: <span class="st">'*.wikipedia.org'</span>,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'output'</span>: <span class="st">'json'</span>,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'page'</span>: <span class="dv">409</span>,</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>                 })</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>r.status_code   <span class="co"># 400</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The response includes information telling you what went wrong (<code>r.text</code>):</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode html code-with-copy"><code class="sourceCode html"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;!DOCTYPE </span>html<span class="dt">&gt;</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;html&gt;</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;head&gt;</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;link</span> <span class="er">rel</span><span class="ot">=</span><span class="st">"stylesheet"</span> <span class="er">href</span><span class="ot">=</span><span class="st">"/static/__shared/shared.css"</span><span class="kw">/&gt;</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/head&gt;</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body&gt;</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;h2&gt;</span>Common Crawl Index Server Error<span class="kw">&lt;/h2&gt;</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;b&gt;</span>Page 409 invalid: First Page is 0, Last Page is 408<span class="kw">&lt;/b&gt;</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/body&gt;</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/html&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="retrieving-content" class="level2">
<h2 class="anchored" data-anchor-id="retrieving-content">Retrieving Content</h2>
<p>The CDX queries return a <code>filename</code> which is on S3 and accessible at <a href="https://data.commoncrawl.org/">https://data.commoncrawl.org/</a>. They also contain a <code>offset</code> and <code>length</code> which tells you where in bytes the record data is and how long it is. We can use a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range">Range header</a> to get just this data (since each whole file is around 1GB).</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>record <span class="op">=</span> records[<span class="dv">0</span>]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>prefix_url <span class="op">=</span> <span class="st">'https://data.commoncrawl.org/'</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>data_url <span class="op">=</span> prefix_url <span class="op">+</span> record[<span class="st">'filename'</span>]</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>start_byte <span class="op">=</span> <span class="bu">int</span>(record[<span class="st">'offset'</span>])</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>end_byte <span class="op">=</span> start_byte <span class="op">+</span> <span class="bu">int</span>(record[<span class="st">'length'</span>])</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>headers <span class="op">=</span> {<span class="st">'Range'</span>: <span class="ss">f'bytes=</span><span class="sc">{</span>start_byte<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>end_byte<span class="sc">}</span><span class="ss">'</span>}</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.get(data_url, headers<span class="op">=</span>headers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We then have to decompress the data since it is gzipped. The gzip library only works on files with headers, so we have to decompress using zlib. We need to set <a href="https://stackoverflow.com/a/22310760">wbits to the right value for gzip</a>, otherwise we get <code>Error -3 while decompressing data: incorrect header check</code>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zlib</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> zlib.decompress(r.content, wbits <span class="op">=</span> zlib.MAX_WBITS <span class="op">|</span> <span class="dv">16</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data.decode(<span class="st">'utf-8'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This then gives the WARC request headers, HTTP response headers and full HTML retrieved (I’ve truncated the output because there’s a <em>lot</em> of HTML):</p>
<pre><code>WARC/1.0
WARC-Type: response
WARC-Date: 2020-05-25T02:44:32Z
WARC-Record-ID: &lt;urn:uuid:fa7c243e-d055-469b-bb4f-aa8580bc8330&gt;
Content-Length: 238774
Content-Type: application/http; msgtype=response
WARC-Warcinfo-ID: &lt;urn:uuid:2a234f6f-6796-4962-8c6f-84a6fe8b8945&gt;
WARC-Concurrent-To: &lt;urn:uuid:b7ec4524-bc4a-4da1-906b-6c53f9c9836e&gt;
WARC-IP-Address: 199.232.65.140
WARC-Target-URI: https://www.reddit.com/
WARC-Payload-Digest: sha1:C6Y4VCGYLE3NGEWLJNONES6JMNA74IA3
WARC-Block-Digest: sha1:HJ6BA5YAW24SEPDAYA5NUAXA6RG2UBBJ
WARC-Identified-Payload-Type: text/html

HTTP/1.1 200 OK
Connection: keep-alive
X-Crawler-Content-Length: 41748
Content-Length: 237219
Content-Type: text/html; charset=UTF-8
x-ua-compatible: IE=edge
x-frame-options: SAMEORIGIN
x-content-type-options: nosniff
x-xss-protection: 1; mode=block
X-Crawler-Content-Encoding: gzip
cache-control: max-age=0, must-revalidate
X-Moose: majestic
Accept-Ranges: bytes
Date: Mon, 25 May 2020 02:44:32 GMT
Via: 1.1 varnish
X-Served-By: cache-wdc5543-WDC
X-Cache: MISS
X-Cache-Hits: 0
X-Timer: S1590374672.949570,VS0,VE950
Vary: accept-encoding
Set-Cookie: loid=00000000006kkgzyec.2.1590374671996.Z0FBQUFBQmV5ekVRNHBWX0ZOM3RJb0FRX0FHRzVzNVdlMXY2ejUwdFBxeHJkczRtLUlNR2o1SUxNUGlhSU12WnBsSjFfdmNkYl9fTm9GSUk2SHJHTmdmejUwblMzcnBESm0yZVlYUXBmekNqTVNuQXRTOUpHRndXek9zS1pvVVJxN05HdmVBUmFXZUI; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Wed, 25-May-2022 02:44:32 GMT; secure; SameSite=None; Secure
Set-Cookie: session_tracker=LwR2XV8052i86pF3B7.0.1590374671996.Z0FBQUFBQmV5ekVRZ2tNSkRpM0ZsYUlLcVJtRFBfOXRsREVCRlRPWElkRFpIUkJtODl3dnpnaDloZDM1NXplM0xMZEZialZxT0RhR250cEtTTTdfbXAyT2dqWGYyVVlSOV9TQ2paLUpITWloVkRibGw1SzhyMGo3b0RCdVhNT0tuN0pZSWU3ZE45Nkc; Domain=reddit.com; Max-Age=7199; Path=/; expires=Mon, 25-May-2020 04:44:32 GMT; secure; SameSite=None; Secure
Set-Cookie: csv=1; Max-Age=63072000; Domain=.reddit.com; Path=/; Secure; SameSite=None
Set-Cookie: edgebucket=gwfpIQWim0qQ1ddmdP; Domain=reddit.com; Max-Age=63071999; Path=/;  secure
Strict-Transport-Security: max-age=15552000; includeSubDomains; preload
Server: snooserv

&lt;!doctype html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"&gt;&lt;head&gt;&lt;title&gt;reddit: the front page of the internet&lt;/title&gt;&lt;meta name="keywords" content=" reddit, reddit.com, vote, comment, submit " /&gt;&lt;meta name="description" content="Reddit gives you the best of the internet in one place. Get a constantly updating feed of breaking news, fun stories, pics, memes, and videos...</code></pre>
</section>
</section>
<section id="searching-and-fetching-with-python-and-comcrawl" class="level1">
<h1>Searching and fetching with Python and comcrawl</h1>
<p>The <a href="https://github.com/michaelharms/comcrawl">comcrawl</a> library makes it easy to search the index and download the data. The interface is a bit simpler than cdx_toolkit, but it doesn’t allow you to pass filters, query the Internet Archive Wayback Machine, or retrieve the request/response metadata. You can install it with <code>python -m pip install commcrawl</code>.</p>
<p>You create an <code>IndexClient</code> with the indexes you want to search and call <code>search</code></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> comcrawl <span class="im">import</span> IndexClient</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Only get results from these two crawls</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Passing no arguments does all crawls</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> IndexClient([<span class="st">'2020-10'</span>, <span class="st">'2020-16'</span>])</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># If using lots of indexes increase threads to speed it up</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>client.search(<span class="st">'https://www.reddit.com/r/dataisbeautiful/*'</span>, threads<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then <code>client.results</code> is a list of dictionaries containing the data from the CDX. Here’s the first few results in tabular form.</p>
<table class="table">
<colgroup>
<col style="width: 17%">
<col style="width: 2%">
<col style="width: 1%">
<col style="width: 1%">
<col style="width: 19%">
<col style="width: 21%">
<col style="width: 1%">
<col style="width: 18%">
<col style="width: 5%">
<col style="width: 1%">
<col style="width: 4%">
<col style="width: 1%">
<col style="width: 1%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">urlkey</th>
<th style="text-align: right;">timestamp</th>
<th style="text-align: right;">status</th>
<th style="text-align: left;">mime</th>
<th style="text-align: left;">url</th>
<th style="text-align: left;">filename</th>
<th style="text-align: right;">length</th>
<th style="text-align: left;">redirect</th>
<th style="text-align: left;">digest</th>
<th style="text-align: right;">offset</th>
<th style="text-align: left;">mime-detected</th>
<th style="text-align: left;">languages</th>
<th style="text-align: left;">charset</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/2wlsvz/why_the_mlb_rule_changes_since_2004_game_time_is</td>
<td style="text-align: right;">20200217065457</td>
<td style="text-align: right;">301</td>
<td style="text-align: left;">unk</td>
<td style="text-align: left;">http://www.reddit.com/r/dataisbeautiful/comments/2wlsvz/why_the_mlb_rule_changes_since_2004_game_time_is/</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-10/segments/1581875141749.3/crawldiagnostics/CC-MAIN-20200217055517-20200217085517-00493.warc.gz</td>
<td style="text-align: right;">679</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/2wlsvz/why_the_mlb_rule_changes_since_2004_game_time_is/</td>
<td style="text-align: left;">3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ</td>
<td style="text-align: right;">13689701</td>
<td style="text-align: left;">application/octet-stream</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">nan</td>
</tr>
<tr class="even">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/2wlsvz/why_the_mlb_rule_changes_since_2004_game_time_is</td>
<td style="text-align: right;">20200217065459</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/2wlsvz/why_the_mlb_rule_changes_since_2004_game_time_is/</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-10/segments/1581875141749.3/warc/CC-MAIN-20200217055517-20200217085517-00108.warc.gz</td>
<td style="text-align: right;">74716</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">L4C22PRVUOGG22PXMKSB7KYVCWQUKEQ7</td>
<td style="text-align: right;">915522267</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">UTF-8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/7f2sfy/natural_language_processing_techniques_used_to/dq9qzkh</td>
<td style="text-align: right;">20200223060640</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/7f2sfy/natural_language_processing_techniques_used_to/dq9qzkh/</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-10/segments/1581875145746.24/warc/CC-MAIN-20200223032129-20200223062129-00153.warc.gz</td>
<td style="text-align: right;">29470</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">GEWEQE4I2JOSKTL3QXPEI7FXVI3BP52O</td>
<td style="text-align: right;">884674375</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">UTF-8</td>
</tr>
<tr class="even">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/7jbefu/four_years_of_initial_coin_offerings_in_one</td>
<td style="text-align: right;">20200217195615</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/7jbefu/four_years_of_initial_coin_offerings_in_one/</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-10/segments/1581875143079.30/warc/CC-MAIN-20200217175826-20200217205826-00313.warc.gz</td>
<td style="text-align: right;">21516</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">42HZLBLZI5DQYGQAZNUAQ5NRCMEEVERW</td>
<td style="text-align: right;">890110347</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">UTF-8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">com,reddit)/r/dataisbeautiful/comments/8f1rk7/united_states_of_apathy_2016_us_presidential</td>
<td style="text-align: right;">20200222202649</td>
<td style="text-align: right;">200</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">https://www.reddit.com/r/dataisbeautiful/comments/8f1rk7/united_states_of_apathy_2016_us_presidential/</td>
<td style="text-align: left;">crawl-data/CC-MAIN-2020-10/segments/1581875145713.39/warc/CC-MAIN-20200222180557-20200222210557-00466.warc.gz</td>
<td style="text-align: right;">95956</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">IDKDLHSVB7YH3L2AUIMKPJFER3VLBZRU</td>
<td style="text-align: right;">859518253</td>
<td style="text-align: left;">text/html</td>
<td style="text-align: left;">eng</td>
<td style="text-align: left;">UTF-8</td>
</tr>
</tbody>
</table>
<p>Notice that the first result has a status <code>301</code>; let’s filter to the first 2 ok results and download their data. The <code>download</code> method downloads every record in <code>results</code> and adds a <code>html</code> field with the raw HTML Common Crawl fetched.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>client.results <span class="op">=</span> [res <span class="cf">for</span> res <span class="kw">in</span> client.results <span class="cf">if</span> res[<span class="st">'status'</span>] <span class="op">==</span> <span class="st">'200'</span>][:<span class="dv">2</span>]</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>client.results(threads<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can then process the HTML with <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">beautifulsoup</a> or even display it in a Jupyter notebook with <code>IPython.display.HTML</code> (though this may fetch a bunch of assets from the internet, and the CSS may make your notebook funny):</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>HTML(client.results[<span class="dv">0</span>][<span class="st">'html'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/cc_dataisbeautiful_html.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Reddit Data is Beautiful post inside a Jupyter notebook</figcaption><p></p>
</figure>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>