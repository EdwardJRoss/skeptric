<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-10-10">

<title>skeptric - A Reading Guide to Stein’s Paradox</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">skeptric</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/EdwardJRoss"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">A Reading Guide to Stein’s Paradox</h1>
  <div class="quarto-categories">
    <div class="quarto-category">maths</div>
    <div class="quarto-category">data</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 10, 2021</p>
    </div>
  </div>
    
  </div>
  

</header>

<p><a href="https://en.wikipedia.org/wiki/Stein%27s_example">Stein’s Paradox</a> states that when trying to estimate the 3 or more means of normally distributed data together, it’s <em>always</em> better (on average) to shrink the estimates. Specifically if you’ve got p independent normally distributed variables <span class="math inline">\(X_i \sim N(\theta_i, 1) ;\, i=1,\ldots,p\)</span> the best estimates for minimising the mean squared error of <em>all</em> the estimates isn’t the values themselves <span class="math inline">\(X\)</span>, and the James-Stein estimator is better (has strictly lower risk).</p>
<p><span class="math display">\[\hat\theta^{JS}(X) = \left(1 - \frac{p-2}{\lVert X\rVert^2}\right)X\]</span></p>
<p>A lot of the details here can be weakened substantially.</p>
<p>This article will give a guide on how to understand this phenomenon a bit better.</p>
<section id="what-is-steins-paradox" class="level1">
<h1>What is Stein’s Paradox?</h1>
<p>The best introductory resource is this <a href="http://www.statslab.cam.ac.uk/~rjs57/SteinParadox.pdf">Statslab Cambridge</a> article by Richard Samsworth, which gives a clear explanation and a very simple proof. If the notation is a bit hard to follow I recommend the book <a href="http://www.stat.cmu.edu/~larry/all-of-statistics/index.html">All of Statistics</a> which covers Decision Theory in Chapter 10 (and touches on the James-Stein Estimator).</p>
<p>One thing to note from this article is the improvement in risk over the Maximum Likelihood Estimator <span class="math inline">\(X\)</span> is <span class="math inline">\((p-2){\mathbb E}\left(\frac{1}{\lVert X \rVert^2}\right)\)</span>. So the closer the points are to the origin the more the improvement (although there is always <em>some</em> improvement). And since the choice of origin is arbitrary (through a change in coordinates) having a good guess of where to shrink the estimates to will give a much better result like in the baseball example.</p>
</section>
<section id="why-is-it-important" class="level1">
<h1>Why is it important?</h1>
<p>Bradley Efron has done a lot of writing connecting it to <em>empirical Bayes</em> methods, showing it as a striking example of how on large datasets blending Bayesian methods with frequentist estimates can lead to striking solutions. The 1977 Scientific American Article <a href="https://statweb.stanford.edu/~ckirby/brad/other/Article1977.pdf">Stein’s Paradox in Statistics</a> by Efron and Morris gives a good flavour of what it means an why it’s important. They state a slightly different estimate (where <span class="math inline">\(X_i \sim N(\theta_i, \sigma)\)</span>):</p>
<p><span class="math display">\[\hat\theta^{JS} = \bar X + \left(1 - \frac{(p-3) \sigma^2}{\lVert X - \bar X \rVert^2} \right) (X-\bar X)\]</span></p>
<p>here instead of picking the origin they’re estimating it from the data as the <em>grand mean</em> <span class="math inline">\(\bar X = \frac{\sum_{i=1}^{p} X_i}{p}\)</span>, which will give a better than random risk but at the cost of 1 degree of freedom (the p-3 in the numerator instead of p-2). The other thing to note is the larger the standard deviation the more we shrink the estimate (which makes sense since we are less certain about it). I suspect if they had different standard deviations you would shrink more in directions with larger standard deviation.</p>
<p>To understand this connection Chapter 1 of Efron’s <a href="https://statweb.stanford.edu/~ckirby/brad/LSI/monograph_CUP.pdf">Large-Scale Inference</a> gives a very good introduction. It walks through how starting with the model <span class="math inline">\(\theta \sim N(0, A)\)</span> and <span class="math inline">\(X \vert \theta \sim N(\theta, 1)\)</span> the James-Stein estimator can be recovered, and then how it can be extended to estimate the mean or standard deviation. It also explains <em>limited translation estimators</em> where we shrink less, which gives a higher risk but less biased estimator. A similar (but briefer) explanation is in Chapter 7 of <a href="https://web.stanford.edu/~hastie/CASI/">Computer Age of Statistical Inference</a> which also covers the connection with ridge regression. A great more general tutorial is Casella’s <a href="https://www.biostat.jhsph.edu/~fdominic/teaching/bio656/labs/labs09/Casella.EmpBayes.pdf">An Introduction to Empirical Bayes Data Analysis</a>.</p>
</section>
<section id="but-why-does-it-work" class="level1">
<h1>But why does it work?</h1>
<p>The connection to Empirical Bayesian methods gives useful applications, but it doesn’t indicate why it works. The best heuristic explanation I’ve seen is in <a href="https://projecteuclid.org/download/pdfview_1/euclid.ss/1331729980">A Geometrical Explanation of Stein Shrinkage</a> by Brown and Zhao (2012), which shows how shrinking allows reducing the variance in the other dimensions (<a href="https://joe-antognini.github.io/machine-learning/steins-paradox">Joe Antognini</a> has a good web article summarising this). Naftali Harris has a <a href="https://www.naftaliharris.com/blog/steinviz/">great visualisation</a> of the shrinkage, and the argument reminds me of a how volume increases quickly with dimension.</p>
</section>
<section id="but-really-why-does-it-work" class="level1">
<h1>But really, why does it work?</h1>
<p>The paper <a href="http://stat.wharton.upenn.edu/~lbrown/Papers/1971b%20Admissible%20estimators,%20recurrent%20diffusions,%20and%20insoluble%20boundary%20value%20problems.pdf">Admissable Estimators, Recurrent Diffusions and Insoluble Boundary Value Problems</a> by Brown (1971) connects the admissibility of estimators to recurrence of Brownian motion. I haven’t dug deep enough into the paper to understand it but it sounds mathematically deep and gives an idea as to why 3 is the critical dimension.</p>
</section>
<section id="how-did-it-all-start" class="level1">
<h1>How did it all start?</h1>
<p>The original paper showing inadmissibility is <a href="https://projecteuclid.org/download/pdf_1/euclid.bsmsp/1200501656">Inadmissibility of the usual estimator for the mean of a multivariate normal distribution</a> by Stein (1956). This was followed with the explicit estimator in <a href="https://projecteuclid.org/ebook/Download?urlId=bsmsp%2F1200512173&amp;isFullBook=False">Estimation with Quadratic Loss</a> by James and Stein (1961). The papers are certainly readable, but I found the earlier papers got to the point more succinctly. There was a lot of follow up papers at the time on improving the estimate, connecting it with Bayesian estimators and the like but they don’t strike me as deeply.</p>
</section>
<section id="where-next" class="level1">
<h1>Where next?</h1>
<p>Stein’s result really is still surprising to me; the best estimator in high dimensions are biased estimators <em>no matter where you bias it</em>, but it seems to have to do with removing some of the variance inherent in estimating multiple points in higher dimensional spaces. However for practical applications the biggest difference is when they are (unsurprisingly) biased towards their true values, which brings us back to things like hierarchical models and Empirical Bayesian methods.</p>
<p>However this seems like a far reaching result that should change the practice of analysts; in a sense it’s another kind of regression to the (grand) mean. Whenever I’m calculating averages for lots of groups to maximise predictive accuracy I should shrink the estimates, and the shrinkage should increase with the variance. I think this gives a better solution to Evan Miller’s <a href="https://www.evanmiller.org/how-not-to-sort-by-average-rating.html">How not to sort by average rating</a>; instead of using (arbitrary) confidence intervals we shrink towards the grand mean with more shrinkage the more ratings an item has. However I wouldn’t use the James-Stein estimator directly, but instead use an empirical Bayes method. It seems strange it’s not more widely advocated, especially as a step towards machine learning based methods.</p>
<p>I find it interesting that even though the theorem is for normally distributed variables, the most common example are binomials from baseball (after a suitable transformation). I wonder what an empirical Bayes method would look like, and whether it would have a lower risk than the proportion of true results.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>