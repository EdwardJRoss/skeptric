<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-04-06">

<title>skeptric - More Profitable A/B with Test and Roll</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">skeptric</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/EdwardJRoss"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">More Profitable A/B with Test and Roll</h1>
  <div class="quarto-categories">
    <div class="quarto-category">data</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 6, 2021</p>
    </div>
  </div>
    
  </div>
  

</header>

<p>When running an A/B test the sample sizes can seem insane. For example to observe a 2 percentage point uplift on a 60% conversion rate requires over 9,000 people in <em>each</em> group to get the standard 95% confidence level with 80% power. If you’ve only got less than 18,000 customers you can reach, which is very common in businesss to business settings, it’s impossible to conduct this test. But if you look in terms of the outcomes, doing an A/B test on a few hundred users may actually greatly increase your outcomes.</p>
<p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3274875">Test &amp; Roll: Profit-Maximizing A/B Tests</a> by Elea McDonnell Feit and Ron Berman tackles this problem giving estimates for small samples. In the context of a one-off opportunity (like advertising, promotional offers, campaign launches, products that will only be bought once) we actually don’t <em>care</em> if one version is significantly better than the other; all we care about is maximising our outcome. Standard practice is to run an A/B test to determine which alternative is better, and then roll it out to 100%. There’s a tradeoff in how long we explore to find the optimal alternative, and how long we have left to exploit this opportunity.</p>
<p>They tackle this problem with Bayesian Decision Theory. They run both A and B in parallel on a limited sample, until we get enough evidence to just pick one. But here enough evidence means “good enough” to run with; if they’re very similar then it doesn’t matter too much and instead of running a high fidelity statistical test to get evidence on which is better, just pick one. In particular they look to maximise the <em>expected</em> (average) return, which makes sense if you’re running lots of these processes. If you have a rough idea of how the data is distributed and the size of the difference between them (something you need for a classical statistical test), you can work out the optimal sample size for your A/B test, before rolling it out to 100%.</p>
<p>In particular they assume that the returns are normally distributed. In my experience if there are opportunities to make multiple purchases the returns tend to be long tailed; there’s a few big spenders and a lot of low spenders. But it’s a fine approximation for one-off purchases and conversions (since binomials can be approximated by normal distribution), and the framework can be extended to this case. They define variables for a symmetric A/B test: <span class="math inline">\(Y_{A} \sim \mathcal{N}(m_A, s^2)\)</span>, <span class="math inline">\(Y_{B} \sim \mathcal{N}(m_B, s^2)\)</span> where <span class="math inline">\(m_{A}, m_{B} \sim \mathcal{N}(\mu, \sigma^2)\)</span>. So in the case of a conversion rate:</p>
<ul>
<li><span class="math inline">\(Y_A\)</span> and <span class="math inline">\(Y_B\)</span> represent the results we get from alternative A and B respectively</li>
<li><span class="math inline">\(m_A\)</span> and <span class="math inline">\(m_B\)</span> are the true conversion rates of each alternative</li>
<li><span class="math inline">\(\mu\)</span> is the expected conversion rate</li>
<li>s is the standard deviation of the data; it’s approximately <span class="math inline">\(\sqrt{\mu(1-\mu)}\)</span></li>
<li><span class="math inline">\(\sigma\)</span> is the expected variation in the conversions between the conversion rate</li>
</ul>
<p>The hardest of these parameters to understand is <span class="math inline">\(\sigma\)</span>; one way to understand it is the expected difference of <span class="math inline">\(\vert m_A - m_B \vert\)</span> is <span class="math inline">\(\frac{2}{\sqrt{\pi}} \sigma\)</span> (note in the paper the square root in the numerator is a typo!). So if we expect the difference between A and B to be about 2 percentage points, then we should set <span class="math inline">\(\sigma\)</span> as <span class="math inline">\(0.02 \frac{\sqrt{\pi}}{2} \approx 0.018\)</span>. In general <span class="math inline">\(\sigma\)</span> is around 89% of the mean difference, and 95% of the median difference, so it’s pretty close to the expected effect size.</p>
<p>Under these conditions they find the optimum sample size for each of the A and B groups are:</p>
<p><span class="math display">\[\sqrt{\frac{N}{4} \left(\frac{s}{\sigma}\right)^2 + \left(\frac{3}{4} \left(\frac{s}{\sigma}\right)^2\right)^2} - \frac{3}{4} \left(\frac{s}{\sigma}\right)^2\]</span></p>
<p>It’s interesting to note the key variable is the ratio <span class="math inline">\(\left(\frac{s}{\sigma}\right)^2\)</span>. The smaller our effect size the larger the sample we need, the smaller the variability in the data the smaller sample size we need. In our conversion example above this ratio is around 600.</p>
<p>In the limit of very large populations, large effect sizes and small variation <span class="math inline">\(N \gg \left(\frac{s}{\sigma}\right)^2\)</span>, the sample size approaches <span class="math inline">\(\sqrt{N} \frac{s}{2 \sigma}\)</span> from below. In the limit of very small populations, small effect sizes and large variation <span class="math inline">\(N \ll \left(\frac{s}{\sigma}\right)^2\)</span> it approaches <span class="math inline">\(N/6\)</span>. Finally for <span class="math inline">\(N = \left(\frac{s}{\sigma}\right)^2\)</span> the optimal sample size is <span class="math inline">\(\frac{\sqrt{13} - 3}{4} N \approx 0.15 N\)</span>.</p>
<p>So for small and moderate population sizes (relative to <span class="math inline">\(\left(\frac{s}{\sigma}\right)^2\)</span> ) the optimum process is to run both A and B on about 1/6 of the population each, and then run the winner on the remaining 2/3 of the population. As the population increases, effect size increases, or variation decreases the size of the A/B tests decreases, and in the limit scales as <span class="math inline">\(\sqrt{N}\)</span>, and so we can run the test on a small sample.</p>
<p>The upshot of all this is on average we capture some percentage of the expected improvement. Indeed the expected profit with this optimum sample sizes in each group A and B, n* is</p>
<p><span class="math display">\[N \left(\mu + \frac{2}{\sqrt{\pi}} \sigma \left(1 - \frac{2n^*}{N} \right) \frac{1}{\sqrt{2 + \frac{4}{n^*} \left( \frac{s}{\sigma}\right)^2}}  \right)\]</span></p>
<p>As explained the term <span class="math inline">\(\frac{2}{\sqrt{\pi}} \sigma\)</span> is the optimum expected gain. This is then attenuated by the exploration cost <span class="math inline">\(\left(1 - \frac{2n^*}{N} \right)\)</span>, which is the percentage of cases not in the test phase. Finally it’s attenuated by the expected cost of picking the wrong alternative due to chance, <span class="math inline">\(\frac{1}{\sqrt{2 + \frac{4}{n^*} \left( \frac{s}{\sigma}\right)^2}}\)</span>. For very low populations or small effect sizes relative to the variation in the data, the gain over random choice <span class="math inline">\(N \mu\)</span> is small. But as the effect size increases and populations increase this procedure captures more of the gains.</p>
<p>There’s a good <a href="https://www.ron-berman.com/2020/01/26/test-and-roll/">blog post from co-author Ron Berman</a> that explains this further, and <a href="https://testandroll.com">an online sample size calculator</a>. In the paper they compare it to a Multi-Armed Bandit with a Thompson sampler, which does better, but is much more complex to implement and control. I really like the framework of Bayesian Decision analysis; it seems flexible enough that a different set of assumptions or goals could be easily implemented.</p>
<p>My biggest concern with this procedure is choosing priors, and the effect of choosing bad ones. If your prior deviation is too small you’ll test longer and gain less; there may be worse effects if you pick the wrong distribution. Because we’re not performing a whole test we also will never really know if we’ve chosen the better alternative, and so it’s hard to incorporate this feedback into updating priors. It’s going to be really hard to know if we’re optimising correctly.</p>
<p>Another consideration is what to do with a situation where there are repeat purchases on a long-lived website. The test-and-roll framework doesn’t really apply, but there are still opportunity costs with testing and rolling out. <a href="https://chris-said.io/2020/01/10/optimizing-sample-sizes-in-ab-testing-part-I/">Chris Said has a blog series</a> which comes to similar conclusions but frames it in terms of the <em>time</em> opportunity cost - I look forward to reading this more.</p>
<p>I’m also curious what happens if we’ve got multiple alternatives. There are a few scenarios where we could have many similar effect size alternatives, or quite risky alternatives, and I wonder what the best procedure is that maximises expected return. Also for uncommon opportunities we may be more conservative and consider the whole distribution; maybe we maximise the chance of hitting some revenue target, or maximising a percentile of returns. These should be straightforward extensions of the theory, and could be evaluated numerically through simulations.</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>