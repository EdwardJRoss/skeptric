{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1ea45912-3bef-48b0-b4b8-4ced16ddfe68",
   "metadata": {},
   "source": [
    "---\n",
    "categories:\n",
    "  - nlp\n",
    "  - makemore\n",
    "date: 2024-10-06T23:15+11:00\n",
    "image: ./arithmetic_coding_example.png\n",
    "title: Measuring a Language Model\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296ceae-18b1-4912-a888-3127314e06d7",
   "metadata": {},
   "source": [
    "Generative language models trained to predict what comes next have been shown to be a very useful foundation for models that can perform a wide variety of traditionally difficult language tasks.\n",
    "*Perplexity* is the standard measure of how well such a model can predict the next word on a given text, and it's very closely related to *cross-entropy* and *bits-per-byte*.\n",
    "It's a measure of how effective the language model is on the text, and in certain settings aligns with [how well the model performs downstream tasks](https://arxiv.org/pdf/2403.08540) (although [not in all settings](https://openreview.net/pdf?id=f2OYVDyfIB)) and can be used for [selecting data for training models](https://arxiv.org/abs/2409.05816).\n",
    "These metrics can be applied to any next token prediction model independent of its model architecture which makes it a broadly applicable tool.\n",
    "Note however that it can't be directly to masked language models like BERT or T5, although there [related pseudo-log likelihoods](https://arxiv.org/abs/2305.10588)).\n",
    "\n",
    "This article goes through in detail what perplexity is, how it relates to cross-entropy loss and compression, and how to compute it for the GPT 2 transformer model in PyTorch.\n",
    "If you just want an overview of what the various measures of language modelling are then read Chip Huyen's [what perplexity and related metrics mean](https://thegradient.pub/understanding-evaluation-metrics-for-language-models/).\n",
    "If you just want to compute some perplexities I recommend the [huggingface documentation on perplexity](https://huggingface.co/docs/transformers/perplexity) (though note that their perplexity score is wrong for WikiText-2 because they average over GPT-2 tokens rather than words!) or [lm_perplexity](https://github.com/asahi417/lmppl).\n",
    "If you want to understand why the calculation works, with examples in Python, and understand how to compare results in the literature then read on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd1c1fc-fc24-4f39-b7fc-2994aaf5db8c",
   "metadata": {},
   "source": [
    "# Language modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebb27c-c0e1-4ee1-b9ad-50702ce480ba",
   "metadata": {},
   "source": [
    "## GPT 2\n",
    "\n",
    "The 2019 Open AI paper [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) showed that scaling up language modelling on a diverse corpora could produce a model that could then be used for a variety of tasks without further fine-tuning including summarisation, translation, and question answering.\n",
    "This paper introduced prompt design by using `TL;DR:` to get a summary, and [in-context learning](https://ai.stanford.edu/blog/understanding-incontext/) (in this paper they refer to this as \"zero-shot\" because there is no training, but now it would be phrased as few-shot in-context learning, a term introduced in the [GPT 3 paper](https://arxiv.org/pdf/2005.14165)).\n",
    "\n",
    "Let's load in the largest language model Open AI have released the weights for to date, the 1.5 billion parameter GPT2 XL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8822d4d8-39a5-4954-bef2-d99121fe17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "from pathlib import Path\n",
    "import re\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1727672233025);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f6d597-cfa6-46ee-a3df-c778c214b920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gpt2-xl has 1557.6 million parameters\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2-xl'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          clean_up_tokenization_spaces=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map=\"auto\")\n",
    "\n",
    "print(f'Model {model.config.name_or_path} has ' +\n",
    "      f'{model.num_parameters()/ 1e6:0.1f} million parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6eb64-1b95-4030-bb6d-55e89e520dfc",
   "metadata": {},
   "source": [
    "If we start with some input text (one of the examples from the original GPT 2 paper and [blog post](https://openai.com/index/better-language-models)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfe21e9-bb19-4697-91f3-f66e2f1360db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"In a shocking finding, scientist discovered a herd of unicorns \" \\\n",
    "       \"living in a remote, previously unexplored valley, in the Andes \" \\\n",
    "       \"Mountains. Even more surprising to the researchers was the fact \" \\\n",
    "       \"that the unicorns spoke perfect English.\\n\"\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d79f0-fb11-4809-b001-dacf8fda17f2",
   "metadata": {},
   "source": [
    "We can convert it into numerical tokens for the model based on its vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01cbfcc4-9ef2-4e47-a8ae-05a8aa35a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(text, return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f950bf1d-c903-420b-a6bc-de57dc4d67e2",
   "metadata": {},
   "source": [
    "And then iteratively predict the next token to complete the story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42247db4-412b-4e96-9a44-7c3c85becc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "The scientists were researching the possibility that unicorns exist when they found a herd of the rare creatures, which they named the \"Prairie Unicorn\", in a narrow valley in the Aguas Calientes National Park in Peru, Peru.\n",
      "\n",
      "The group of five had been trekking through the mountain range, about 1,700m above sea level, when the locals informed them that the animals were near the valley's edge.\n",
      "\n",
      "Dr Rodrigo Estevez, of the University of Granada in Spain and a co-author of the new study, told El Mundo: \"In most mountain areas of the Andes Mountains, there are many species of animals, including birds and animals. However, we had never known that there were unicorns.\n",
      "\n",
      "\"Since the group had not encountered [unicorns] previously and they were very curious, they started to study the landscape and we realised that our knowledge might have been incomplete as well as that of people who were more familiar with things from high altitudes.\"\n",
      "\n",
      "According to the scientists, the unicorns are highly intelligent animals, which were probably domesticated for domestic purposes, possibly as workers.\n",
      "\n",
      "\"Since they are from the Andes Mountains, they are adapted to cold, and have very thick fur.\n",
      "\n",
      "\"They eat mainly grasses and roots growing on the dry tundra, but also live in the forest, since its trees have very nutritious foliage,\" he said.\n",
      "\n",
      "However, the unicorns were not able to communicate all that much with the others due to their limited hearing and the poor communication of their tongue.\n",
      "\n",
      "Nevertheless it is possible that the unicorns were able to communicate for some reason, or that they were even able to learn English.\n",
      "\n",
      "The study was published this week in the journal Quaternary Science Reviews.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "generation = model.generate(\n",
    "    tokens.to(model.device),\n",
    "    attention_mask=torch.ones_like(tokens).to(model.device),\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=1,\n",
    "    max_new_tokens = 512)\n",
    "\n",
    "print(tokenizer.decode(generation[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7fa44-07f7-4175-bfdf-ea82896e91bc",
   "metadata": {},
   "source": [
    "Note this is different to the example generation from the blog post because this process is random.\n",
    "I actually had to try a few different random seeds to get a result this good (although with more sophisticated search we could get better results with the same model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e625563-fc7e-4264-8093-b7f0bb93325e",
   "metadata": {},
   "source": [
    "## Predicting the next token\n",
    "\n",
    "Language modelling works by predicting the probability distribution for the next token out of all possible tokens.\n",
    "For example take our input text above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219c73b5-4498-485f-b277-4bd8d12c03a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e09b8-2b97-486c-be7d-38b83199bfd8",
   "metadata": {},
   "source": [
    "We converted that into numeric tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603a7cd7-f969-49e0-8c46-4205e06c9713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  818,   257, 14702,  4917,    11, 11444,  5071,   257, 27638,   286,\n",
       "         28000, 19942,  2877,   287,   257,  6569,    11,  4271, 31286,  1850,\n",
       "         19272,    11,   287,   262,   843,   274, 21124,    13,  3412,   517,\n",
       "          6452,   284,   262,  4837,   373,   262,  1109,   326,   262, 28000,\n",
       "         19942,  5158,  2818,  3594,    13,   198]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb53d2-52c1-4f95-a9aa-0b3471571b7a",
   "metadata": {},
   "source": [
    "Each token corresponds to part of a word via a learned Byte Pair Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6054489a-6d32-4ab9-b51b-1aaea5683afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In_ a_ shocking_ finding_,_ scientist_ discovered_ a_ herd_ of_ unic_orns_ living_ in_ a_ remote_,_ previously_ unexpl_ored_ valley_,_ in_ the_ And_es_ Mountains_._ Even_ more_ surprising_ to_ the_ researchers_ was_ the_ fact_ that_ the_ unic_orns_ spoke_ perfect_ English_._\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'_'.join([tokenizer.decode(t) for t in tokens[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8cb3f-bf8d-400b-98c7-b14562615e16",
   "metadata": {},
   "source": [
    "For each token input the model outputs 50257 values, that is one for each element of the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6ec143-54f1-45ac-8d78-94f210c4ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.shape=torch.Size([1, 46]), logits.shape=torch.Size([1, 46, 50257]), tokenizer.vocab_size=50257\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    logits = model(tokens.to(model.device)).logits.cpu()\n",
    "print(f'{tokens.shape=}, {logits.shape=}, {tokenizer.vocab_size=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa45ab1-5cd1-4581-8b1b-d9d868d42155",
   "metadata": {},
   "source": [
    "These are *multinomial logits*, which we denote $z_i$, to get probabilities we need to pass them through the softmax function:\n",
    "\n",
    "$$ p(z)_i = \\frac{\\exp(z_i)}{\\sum_{t \\in V} \\exp(z_t)}$$\n",
    "\n",
    "Where the sum is over all tokens $t$ in the vocabulary $V$.\n",
    "The probabilities can be very small and the sum of exponentials can result in underflow or overflow.\n",
    "However the probability is invariant under a shift of logits, so we translate them so the logits maximum value is zero to make it more numerically stable.\n",
    "\n",
    "$$ p(z)_i = \\frac{\\exp(z_i - \\max(z))}{\\sum_{t \\in V} \\exp(z_t - \\max(z))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b294d9-5c9e-4810-9805-cf4e5cdbb974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.2914e-05, 1.9333e-04, 3.6167e-06,  ..., 1.2496e-07,\n",
       "          3.1714e-08, 2.4391e-05],\n",
       "         [3.3396e-06, 9.7791e-06, 2.0923e-07,  ..., 2.0211e-08,\n",
       "          2.7631e-08, 8.2515e-06],\n",
       "         [1.9861e-05, 4.0516e-05, 4.5341e-07,  ..., 3.0855e-08,\n",
       "          1.5996e-09, 3.6109e-06],\n",
       "         ...,\n",
       "         [2.6970e-02, 1.4128e-04, 2.4664e-07,  ..., 2.3159e-09,\n",
       "          4.5612e-09, 2.3378e-04],\n",
       "         [5.7984e-06, 9.9157e-05, 9.3441e-07,  ..., 5.5791e-09,\n",
       "          1.3838e-08, 7.3431e-03],\n",
       "         [1.9724e-07, 1.1957e-04, 2.6362e-06,  ..., 4.0896e-10,\n",
       "          2.8109e-10, 8.8093e-06]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z - max(z)\n",
    "norm_logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "\n",
    "# exp(z - max(z))\n",
    "probs = norm_logits.exp()\n",
    "# exp(z - max(z)) / sum(exp(z) - max(z))\n",
    "probs /= probs.sum(axis=-1, keepdim=True)\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37201fe3-1e76-4ba7-ae19-07a59db7ca86",
   "metadata": {},
   "source": [
    "This is similar to what you get from calling Pytorch's `softmax` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41dae04-617f-493a-a62b-46cd3a8169b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(F.softmax(logits, dim=-1), probs, atol=5e-5)\n",
    "\n",
    "probs = F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5877f3e-35bf-420e-92d1-59142072c444",
   "metadata": {},
   "source": [
    "For example let's consider the token corresponding to perfect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3d29e1-43a9-48f8-b0be-eb0ba667b9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' perfect'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens[0,-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1d3c1-98e4-4d10-bb3c-69d9e2df270b",
   "metadata": {},
   "source": [
    "We can look at the probabilities of the next token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a692f6ce-51d7-47dc-9f0f-82d5d334152c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.7597e-06, 6.2952e-06, 1.5840e-07,  ..., 3.3299e-09, 6.6634e-10,\n",
       "        2.7599e-06])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_prob = probs[0,-4]\n",
    "next_token_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d06038-45e0-498b-8f6d-61a4e0248820",
   "metadata": {},
   "source": [
    "Which sum to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4841ab07-45f7-4f14-8f89-a3d0775d1d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_prob.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b78e034-1696-407f-88d9-81e906132be9",
   "metadata": {},
   "source": [
    "We can see the most likely next tokens, which are all reasonable guesses for the language the unicorns spoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54044c60-a95d-4bf3-af78-6e07d38a587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.57%\t  English\n",
      "17.82%\t  Spanish\n",
      "2.26%\t  Latin\n",
      "2.02%\t ,\n",
      "1.81%\t  human\n"
     ]
    }
   ],
   "source": [
    "for _idx in next_token_prob.argsort(descending=True)[:5]:\n",
    "    print(f'{next_token_prob[_idx]:0.2%}\\t', tokenizer.decode(_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a953d3-ac97-465f-88d4-266e32bf8a72",
   "metadata": {},
   "source": [
    "By picking a random token weighted by its probability we can sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f99facc7-a0a4-4e8e-a218-3d6e5402e316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([198]), '\\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token = torch.multinomial(probs[0,-1], 1)\n",
    "\n",
    "next_token, tokenizer.decode(next_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89cdb53-a24d-41fa-a89f-91f25b968dec",
   "metadata": {},
   "source": [
    "And by iterating this process we can generate text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294b858-ea18-4c23-ab43-c2bf282d8fd0",
   "metadata": {},
   "source": [
    "# Evaluating language models\n",
    "\n",
    "How do we say how *good* a language model is at predicting the next word in a corpus of text?\n",
    "We can use *accuracy* (acc), how well the most likely prediction matches the actual truth, but this is a very difficult goal for general datasets and is insensitive to small changes in the model.\n",
    "It is better to measure how likely the text is given the model, and *perplexity* (ppl) is a standard measure of this (normalised by the length of the text).\n",
    "It's also possible to view the likelihood through an information theory lens of compressibility, and the related measures of bits per byte (bpb) and bits per character (bpc).\n",
    "All of these measures were used in the GPT 2 paper:\n",
    "\n",
    "\n",
    " Model  | LAMBADA (PPL) | LAMBADA (ACC) | CBT-CN (ACC) | CBT-NE (ACC) | WikiText2 (PPL) | PTB (PPL) | enwik8 (BPB) | text8 (BPC) | WikiText103 (PPL) | 1BW (PPL) |\n",
    "|--------|---------------|---------------|--------------|--------------|----------------|-----------|--------------|-------------|------------------|-----------|\n",
    "| 117M   | 35.13         | 45.99         | 87.65        | 83.4         | 29.41          | 65.85     | 1.16         | 1.17        | 37.50            | 75.20     |\n",
    "| 345M   | 15.60         | 55.48         | 92.35        | 87.1         | 22.76          | 47.33     | 1.06         | 1.06        | 26.37            | 55.72     |\n",
    "| 762M   | 10.87         | 60.12         | 93.45        | 88.0         | 19.93          | 40.31     | 0.97         | 1.02        | 22.05            | 44.575    |\n",
    "| 1542M  | 8.63          | 63.24         | 93.30        | 89.05        | 18.34          | 35.76     | 0.93         | 0.98        | 17.48            | 42.16     |\n",
    "\n",
    "\n",
    "This section will go through these different measures and how they're connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8eb58c-7a25-4608-aebd-d10ec430641a",
   "metadata": {},
   "source": [
    "## Likelihood of a text\n",
    "\n",
    "We can use the model to predict the next token, but we can also use it to calculate how likely the input text itself is.\n",
    "\n",
    "Of all the possible sentences how likely is this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86556008-4936-4130-bad7-6c7086a749e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2995022-922e-4674-9b8f-88f3457a646d",
   "metadata": {},
   "source": [
    "The probability of a sequence of tokens can be rewritten as a chain of conditional probabilities, $P(A \\vert B) := P(A, B) / P(B)$, of increasing strings of tokens:\n",
    "\n",
    "$$\\begin{align}\n",
    "P(t_1, t_2, \\ldots, t_n) &= P(t_1, t_2, \\ldots, t_n) \\frac{P(t_1, \\ldots, t_{n-1})}{P(t_1, \\ldots, t_{n-1})} \\\\\n",
    "                         &= P(t_1, t_2, \\ldots, t_{n-1}) P(t_n \\vert t_1, t_2, \\ldots, t_{n-1}) \\\\\n",
    "                         & \\vdots \\\\\n",
    "                         &= P(t_1) P(t_2 \\vert t_1) \\cdots P(t_n \\vert t_1, t_2, \\ldots, t_{n-1}) \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "The number of previous tokens the probability is conditional on is called the *amount of context*.\n",
    "The language model we are using implements this with a *causal attention mask*; the prediction of any token only depends on the tokens before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e85e26a-f4fd-4cd5-bba5-bcfdfcce9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    first_logits = model(input_ids=tokens[:,:2].to(model.device)).logits.cpu()\n",
    "\n",
    "assert torch.allclose(first_logits, logits[:,:2], atol=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5bd71-3da8-4c5d-b8ad-81d70bc88f7c",
   "metadata": {},
   "source": [
    "We need to get the models predicted probability for each next token, the tokens shifted to the left.\n",
    "\n",
    "We need some way to represent the sequence is ended so we use a special `eos_token`.\n",
    "We also need some way to predict the first token, so we use a start of sequence token; since it's impossible for anything to follow and `eos_token` we can also use that for the initial token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87b00e3e-d7ca-4264-9180-fe6937b37092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|endoftext|>', 50256)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c52f2e65-ca1a-4ef1-89cc-96d5d652c428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50256,   818,   257, 14702,  4917,    11, 11444,  5071,   257, 27638,\n",
       "            286, 28000, 19942,  2877,   287,   257,  6569,    11,  4271, 31286,\n",
       "           1850, 19272,    11,   287,   262,   843,   274, 21124,    13,  3412,\n",
       "            517,  6452,   284,   262,  4837,   373,   262,  1109,   326,   262,\n",
       "          28000, 19942,  5158,  2818,  3594,    13,   198]]),\n",
       " tensor([[  818,   257, 14702,  4917,    11, 11444,  5071,   257, 27638,   286,\n",
       "          28000, 19942,  2877,   287,   257,  6569,    11,  4271, 31286,  1850,\n",
       "          19272,    11,   287,   262,   843,   274, 21124,    13,  3412,   517,\n",
       "           6452,   284,   262,  4837,   373,   262,  1109,   326,   262, 28000,\n",
       "          19942,  5158,  2818,  3594,    13,   198, 50256]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens = torch.cat([torch.tensor([[tokenizer.eos_token_id]]), tokens], axis=-1)\n",
    "target_tokens = torch.cat([tokens, torch.tensor([[tokenizer.eos_token_id]])], axis=-1)\n",
    "\n",
    "input_tokens, target_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d9ba7-f5e4-474d-9477-fdc04b73a874",
   "metadata": {},
   "source": [
    "We need to pluck the corresponding probability out of the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8f2529f-e574-442b-8845-6499013ad611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In \t 1.69%\n",
      " a \t 13.31%\n",
      " shocking \t 1.01%\n",
      " finding \t 0.13%\n",
      ", \t 72.20%\n",
      " scientist \t 0.01%\n",
      " discovered \t 0.74%\n",
      " a \t 8.28%\n",
      " herd \t 0.07%\n",
      " of \t 98.04%\n",
      " unic \t 0.04%\n",
      "orns \t 99.96%\n",
      " living \t 10.61%\n",
      " in \t 59.81%\n",
      " a \t 24.87%\n",
      " remote \t 11.17%\n",
      ", \t 1.29%\n",
      " previously \t 0.04%\n",
      " unexpl \t 12.41%\n",
      "ored \t 98.20%\n",
      " valley \t 5.93%\n",
      ", \t 2.23%\n",
      " in \t 18.94%\n",
      " the \t 34.40%\n",
      " And \t 1.28%\n",
      "es \t 87.94%\n",
      " Mountains \t 49.48%\n",
      ". \t 23.36%\n",
      " Even \t 0.08%\n",
      " more \t 63.09%\n",
      " surprising \t 9.20%\n",
      " to \t 0.72%\n",
      " the \t 23.89%\n",
      " researchers \t 12.51%\n",
      " was \t 34.60%\n",
      " the \t 38.75%\n",
      " fact \t 58.56%\n",
      " that \t 93.15%\n",
      " the \t 44.24%\n",
      " unic \t 31.00%\n",
      "orns \t 99.71%\n",
      " spoke \t 0.01%\n",
      " perfect \t 0.52%\n",
      " English \t 66.30%\n",
      ". \t 39.75%\n",
      "\n",
      " \t 61.35%\n",
      "<|endoftext|> \t 0.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    logits = model(input_tokens.to(model.device)).logits.cpu()\n",
    "    probs = logits.softmax(dim=-1)\n",
    "\n",
    "\n",
    "target_probs = probs[0, range(probs.size(1)), target_tokens]\n",
    "for token, prob in zip(target_tokens[0], target_probs[0]):\n",
    "    print(tokenizer.decode(token), '\\t', f'{prob.item():0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941dabc-677a-46bc-bb1f-868fcf2e0479",
   "metadata": {},
   "source": [
    "The probability of the total sequence is then all the individual (conditional) token probabilities multiplied together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ee7a894-b2bc-4adb-ab01-6f86d213500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_probability = target_probs.prod()\n",
    "sequence_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a195d-2771-43f4-8d0b-1a90e76f2ff7",
   "metadata": {},
   "source": [
    "It's not really zero since all the probabilities are positive; it's just so low that floating point multiplication underflowed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17181ae1-085b-4149-95a7-b674c03a986f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6854e-02, 1.3312e-01, 1.0072e-02, 1.2537e-03, 7.2201e-01, 1.0215e-04,\n",
       "         7.4406e-03, 8.2844e-02, 7.0714e-04, 9.8037e-01, 3.7324e-04, 9.9965e-01,\n",
       "         1.0614e-01, 5.9808e-01, 2.4874e-01, 1.1169e-01, 1.2856e-02, 3.6318e-04,\n",
       "         1.2413e-01, 9.8199e-01, 5.9272e-02, 2.2309e-02, 1.8944e-01, 3.4402e-01,\n",
       "         1.2849e-02, 8.7944e-01, 4.9478e-01, 2.3357e-01, 7.8674e-04, 6.3087e-01,\n",
       "         9.2005e-02, 7.1899e-03, 2.3888e-01, 1.2513e-01, 3.4598e-01, 3.8754e-01,\n",
       "         5.8557e-01, 9.3154e-01, 4.4239e-01, 3.1005e-01, 9.9709e-01, 1.0575e-04,\n",
       "         5.1902e-03, 6.6301e-01, 3.9747e-01, 6.1346e-01, 1.2886e-05]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c762e-183d-44f0-950f-315aa717bf32",
   "metadata": {},
   "source": [
    "We can get a better estimate by increasing the numerical precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87c098ed-22ce-43ff-8cb0-6f9d76c1c5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2240e-60, dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_probability = target_probs.to(torch.float64).prod()\n",
    "sequence_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda10180-1567-49e1-8411-47dd0a7ab8a3",
   "metadata": {},
   "source": [
    "It's worth pausing for a second to marvel at how terifically unlikely this is. If you had one million language models, each typing at one million tokens per second then the expected number of years for one of them to produce this sequence of tokens is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1265d507-127d-465c-8ef8-11aa20bb439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.51E+41'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_nodes = 1e6\n",
    "tokens_per_second = 1e4\n",
    "seconds_per_year = 60*60*24 * 365\n",
    "\n",
    "f'''{(1/sequence_probability).item() / \n",
    "  (number_of_nodes * \n",
    "   tokens_per_second * \n",
    "   seconds_per_year):0.2E}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184cceff-f059-4d61-abdd-d4fb3bab4cf2",
   "metadata": {},
   "source": [
    "The universe is only about $10^{10}$ years old, so this effectively would *never* be produced.\n",
    "That's because there are so many possible (and likely) sequences of text.\n",
    "\n",
    "Instead of working directly with these very small probabilities, the calculations are much more stable and simple after a logarithmic transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2dbcc2-c0bf-4c35-aa36-57d8ba54c4f1",
   "metadata": {},
   "source": [
    "## Log likelihood of a text\n",
    "\n",
    "The likelihood is very small (being a product of small numbers) and for long sequences the floating point multiplication can underflow.\n",
    "To reduce this problem we can take the logarithm (in some base) and write the log-likelihood of the sequence under the model as a sum of log-likelihood of tokens:\n",
    "\n",
    "$$ \\log P(t_1, t_2, \\ldots, t_n) = \\log P(t_1) + \\log P(t_2 \\vert t_1) + \\cdots + \\log P(t_n \\vert t_1, t_2, \\ldots, t_{n-1}) $$\n",
    "\n",
    "Working with quantities that add together is much simpler, both for humans and floating point arithmetic.\n",
    "We can calculate the log probabilities directly from the logits; before we had\n",
    "\n",
    "$$ p(z)_i = \\frac{\\exp(z_i - \\max(z))}{\\sum_w \\exp(z_w - \\max(z))}$$\n",
    "\n",
    "and so\n",
    "\n",
    "$$ \\log p(z)_i = (z_i - \\max(z)) - \\log\\left(\\sum_w \\exp(z_w - \\max(z))\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58e2a43f-8ad1-4f1b-8b3f-544541629c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "\n",
    "logprobs = norm_logits - norm_logits.exp().sum(axis=-1, keepdim=True).log()\n",
    "\n",
    "assert torch.allclose(logprobs.exp(), probs, atol=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acdb8d-73c8-402c-9eeb-6b60b3887771",
   "metadata": {},
   "source": [
    "We can simplify further by only calculating it for the next tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d98b9557-c8bf-4e70-a8b5-e51f9e1762ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-136.7151)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logprobs = (\n",
    "    norm_logits[:,range(norm_logits.size(1)), target_tokens] - \n",
    "    norm_logits.exp().sum(axis=-1).log()\n",
    ")\n",
    "log_likelihood = next_token_logprobs.sum()\n",
    "log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c280938-a01e-4606-a307-223c0707d39b",
   "metadata": {},
   "source": [
    "Exponentiating gives a similar answer to before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "471aa062-c83c-4deb-990f-04f4968170ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2205e-60, dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood.to(torch.float64).exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b7b81-e837-4aa8-9803-4487b897a3aa",
   "metadata": {},
   "source": [
    "However unlikely this is, we can compare it to a baseline model that just picks a random token uniformly from the vocabulary, which would assign a much lower probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc4b7a20-3038-4f96-9ba6-65cc39ce49b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-497.94563550629573"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_probability = len(tokens[0]) * math.log(1/tokenizer.vocab_size)\n",
    "random_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525df66e-ddc5-4d76-a6d0-d1713ce5750b",
   "metadata": {},
   "source": [
    "Which is *much* less likely, so the model really is capturing something about this being a valid sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f779f3-f8c2-460a-84fc-08250ad091a8",
   "metadata": {},
   "source": [
    "## Cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78a981-e4ad-4bc0-8d4c-804727e766a6",
   "metadata": {},
   "source": [
    "The negative log likelihood of each token is precisely the *sample cross-entropy* between the actual token distribution and the predicted token distribution.\n",
    "The cross-entropy between the true distribution $P^*$ and our estimated distribution $P$ for a given context $C$ is:\n",
    "\n",
    "$$ H_C(P^*, P) = - \\sum_{t \\in V} P^*(t \\vert C) \\log\\left(P(t \\vert C)\\right) $$\n",
    "\n",
    "We don't know the true probability distribution but can only estimate the empirical distribution over many examples, that is how often we see that token in the context.\n",
    "In practice we don't see the same context very often beyond several words (which is why long n-gram models don't work very well); with a single sample our best estimate is just the probability of the observed value: $- \\log\\left(P(t_i \\vert C)\\right)$.\n",
    "\n",
    "We can use [torch.nn.functional.cross_entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) function to calculate this if we reshape the logits to be $(B, C, ...)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19974f7f-3a8a-4733-b178-a831c4c8ac97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(136.7077)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = F.cross_entropy(logits.transpose(-1,-2),\n",
    "                                target_tokens,\n",
    "                                reduction='sum')\n",
    "cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccedec1-bb0b-4b97-ab46-1b21b09a044c",
   "metadata": {},
   "source": [
    "This is very close to the negative of the log likelihood we calculated above; adding them together gives something close to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ea23e18-3d1f-41cf-aa20-b47532fed639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0074)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy + log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fbfc4-8c35-4faf-b1b8-7ccea65fc5aa",
   "metadata": {},
   "source": [
    "## Compression and Arithmetic Coding\n",
    "\n",
    "The cross-entropy is closely related to Shannon's Information Theory and compression, and in particular gives a lower bound on how much the model can compress the text.\n",
    "\n",
    "We have used the natural logarithm which means we're measuring the cross entropy in terms of *nats*, but we can convert it into any other unit by dividing by the natural logarithm of that number, since $e^x = b^y$ implies $x = y \\log b$ and so $y = x / \\log b$.\n",
    "So for example the cross entropy in *bits* (base 2) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97a5fc27-f601-47c6-ac78-29004ec03052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(197.2275)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy / math.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcd9d1-f43a-46c2-90cf-86838f3168e0",
   "metadata": {},
   "source": [
    "So we need at least that many binary bits to uniquely represent this text.\n",
    "Or if we used decimal digits we would need at least:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29c7c60c-3f89-4447-a104-3f5c2a76c01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(59.3714)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy / math.log(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33588744-06fc-461c-8cf5-f9ef7cc2b337",
   "metadata": {},
   "source": [
    "This isn't just theoretical, we can practically achieve near optimal compression using [Arithmetic Coding](https://en.wikipedia.org/wiki/Arithmetic_coding).\n",
    "The essential idea is that every possible sequence (ending in a terminal token) has a probability, and they all add up to one.\n",
    "If we ordered the sequences we could then represent them as a subinterval of $[0,1]$, and represent them by any fractional sequence of digits that lies in that interval.\n",
    "In particular to compress the text more we could represent them by any shortest sequence of digits in that interval; more probable outcomes are more likely to have a shorter representation (since they span a greater space) and can be more compressed.\n",
    "\n",
    "![Example of Arithmetic Coding from [Wikimedia](https://en.wikipedia.org/wiki/File:Arithmetic_coding_example.svg)](./arithmetic_coding_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366e0fd-f586-48ad-8e02-10c947a17ab3",
   "metadata": {},
   "source": [
    "This compression can be done token by token. Consider the probability of the first token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fec5c228-948f-44ef-b730-00a045b40988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0992e-05, 2.3776e-02, 1.7652e-03,  ..., 4.1708e-09, 2.3309e-08,\n",
       "        5.8259e-05])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_token_prob = probs[0,0]\n",
    "first_token_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68661a3-cac0-49c2-85cc-bcbac96c67bc",
   "metadata": {},
   "source": [
    "This sums to 1 as it's a probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "975a1f8c-9247-4979-9b85-63a5c57b65af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_token_prob.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfc5bc-5a20-4fff-9ed8-2748f54896be",
   "metadata": {},
   "source": [
    "We can think of each probability being a segment of the line `[0,1]` with larger segments represented by more probable outcomes.\n",
    "\n",
    "We can get to this mapping by calculating the cumulative sums (and adding a 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57796abb-594e-4500-a606-638bb8ebc2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 5.0992e-05, 2.3827e-02,  ..., 9.9994e-01, 9.9994e-01,\n",
       "        1.0000e+00])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_token_cumprob = torch.cat([torch.tensor([0]),\n",
    "                                 first_token_prob.cumsum(-1)])\n",
    "first_token_cumprob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37988026-eb7b-45c3-9df6-4784a65563d6",
   "metadata": {},
   "source": [
    "Then for example the first token being:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c32415c7-3b53-424d-b8a9-740696c4f5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4bd24-d84c-49ee-bac0-8e1e9410775f",
   "metadata": {},
   "source": [
    "Is represented by the interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7c29bd6-b3ad-4e05-9ed6-a7bb8dd0d12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(5.0992e-05))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(first_token_cumprob[0], first_token_cumprob[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ee402-c8ab-4a09-a1d2-e5c1082be030",
   "metadata": {},
   "source": [
    "And so the actual token is given by the interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "909075ab-1456-4550-9f62-3b28e523de6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2803002893924713, 0.29715436697006226)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_interval = (first_token_cumprob[tokens[0,0]].item(),\n",
    "                  first_token_cumprob[tokens[0,0] + 1].item())\n",
    "first_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ae686-ad26-4e93-ae8e-aa63b70b0adb",
   "metadata": {},
   "source": [
    "Which has width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfa573d8-59ed-4c56-82c1-e0bf105c4b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016854077577590942"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_interval[1] - first_interval[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad99c5e-0ca5-4621-8e8f-a6f94675654e",
   "metadata": {},
   "source": [
    "The second token's probability distribution can be nested within this first interval by scaling and shifting it.\n",
    "This works because the probabilities combine multiplicatively, which is what the scaling does, so the size of the final interval is precisely the probability of those two tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec51633b-ae90-4d28-89f0-ecff4f5beed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2803003 , 0.2803004 , 0.28030068, ..., 0.29715434, 0.29715434,\n",
       "       0.29715443], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_token_cumprob = torch.cat([torch.tensor([0]), probs[0,1].cumsum(-1)])\n",
    "\n",
    "second_token_range = (\n",
    "    second_token_cumprob * \n",
    "    (first_interval[1] - first_interval[0]) + \n",
    "    first_interval[0]\n",
    ")\n",
    "second_token_range.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d90dde-05c4-443a-9153-6d94f9984dc0",
   "metadata": {},
   "source": [
    "And the actual second token corresponds to a new subinterval within this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ecdfbe4-463c-4d82-bd5e-8bae7df5c0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28042399883270264, 0.2826676368713379)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_interval = (second_token_range[tokens[0,1]].item(), second_token_range[tokens[0,1] + 1].item())\n",
    "second_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24859afb-dacc-4963-8c1d-c177513ff12a",
   "metadata": {},
   "source": [
    "We can continue to do this, but it underflows in floating point arithmetic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f60aaabb-ec1f-4bde-9362-658aebb93644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28239691257476807, 0.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval_start = 0.0\n",
    "interval_end = 1.0\n",
    "\n",
    "for (token, prob) in zip(target_tokens[0], probs[0]):\n",
    "    cumprob = torch.cat([torch.tensor([0]), prob.cumsum(-1)])\n",
    "    interval = cumprob * (interval_end - interval_start) + interval_start\n",
    "\n",
    "    interval_start = interval[token].item() \n",
    "    interval_end = interval[token+1].item()\n",
    "\n",
    "interval_start, interval_end - interval_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532c25c-65d9-4d51-9ab7-4116589a1001",
   "metadata": {},
   "source": [
    "We also need to be very careful that we get the same predictions at decoding time as encoding time.\n",
    "Even though adding tokens *shouldn't* change the logits of earlier tokens, they in fact do (likely due to internal numerical optimizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de3c3b06-bd97-443f-9c76-26f1cd0c6876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9563e-11, 8.1855e-11, 5.1728e-12,  ..., 2.0428e-13, 1.0481e-13,\n",
       "        2.7285e-11])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "        initial_prob = (\n",
    "            model(input_tokens[:,:2].to(model.device))\n",
    "            .logits\n",
    "            .softmax(axis=-1).cpu()\n",
    "        )\n",
    "\n",
    "probs[0,1] - initial_prob[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29861292-3285-4526-abcc-dcb10ac163c2",
   "metadata": {},
   "source": [
    "These small differences add up so we have to recalculate the probability for each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fe53f45-1c08-4a3c-9b49-0be7d9766d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Decimal('0.2823957792584107942411516971050169144494970488524710303979005644891815428996003512946854515522565131'),\n",
       " Decimal('4.2205713450432895501491773372034632259949E-60'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from decimal import Decimal, getcontext\n",
    "\n",
    "# Set a high enough precision\n",
    "# There are smarter ways to do this like rescaling\n",
    "getcontext().prec = 100\n",
    "\n",
    "with torch.inference_mode():\n",
    "    probs = (\n",
    "        model(input_tokens.to(model.device))\n",
    "        .logits\n",
    "        .softmax(axis=-1).cpu()\n",
    "    )\n",
    "\n",
    "interval_start = Decimal(0.0)\n",
    "interval_end = Decimal(1.0)\n",
    "\n",
    "for idx in range(len(input_tokens[0])):\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        prob = (\n",
    "            model(input_tokens[0,:idx+1].to(model.device))\n",
    "            .logits\n",
    "            .softmax(axis=-1)[-1].cpu()\n",
    "        )\n",
    "    token = target_tokens[0,idx]\n",
    "\n",
    "    \n",
    "    cumprob = [Decimal(0.0)]\n",
    "    for p in prob:    \n",
    "        cumprob.append(cumprob[-1] + Decimal(p.item()))\n",
    "    interval = [ cp * (interval_end - interval_start) +\n",
    "                interval_start for cp in cumprob]\n",
    "    interval_start, interval_end = interval[token], interval[token+1]\n",
    "    \n",
    "interval_start, interval_end - interval_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce962e-024c-4842-a239-9a45cc8ac3c6",
   "metadata": {},
   "source": [
    "Our final code should be the shortest decimal string in this interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f820c2c-1a9f-4e06-a078-16be3bfa0bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, '282395779258410794241151697105016914449497048852471030397902')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval_start_digits = interval_start.as_tuple().digits\n",
    "interval_end_digits = interval_end.as_tuple().digits\n",
    "\n",
    "digits = []\n",
    "\n",
    "for digit1, digit2 in zip(interval_start_digits, interval_end_digits):\n",
    "    if digit1 == digit2:\n",
    "        digits.append(digit1)\n",
    "    else:\n",
    "        digits.append((digit1 + digit2) // 2)\n",
    "        break\n",
    "\n",
    "digits = ''.join(map(str, digits))\n",
    "len(digits), digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0bdce-4245-4b05-8bc5-30a808b4b921",
   "metadata": {},
   "source": [
    "Note that the number of digits is just above the decimal cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b04cfe9-9d23-40d1-9f44-2ccf391523e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.37140751560547"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decimal_cross_entropy = cross_entropy.item() / math.log(10)\n",
    "\n",
    "assert decimal_cross_entropy < len(digits) < decimal_cross_entropy + 1\n",
    "\n",
    "decimal_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12063451-cc3e-4843-a4dc-bd4b5e0441da",
   "metadata": {},
   "source": [
    "Note that the above isn't a practical algorithm for arithmetic coding as it relies on slow high-precision arithmetic (and potentially the PyTorch calculations may be device dependent!), but there are practical variants that can be obtained by rescaling the interval.\n",
    "Transformer language models are surprisingly good compressors [even on image and audio data](https://arxiv.org/abs/2309.10668) that they weren't trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99158c-5867-4ec1-8cfc-46a2dfccdebf",
   "metadata": {},
   "source": [
    "## Decompression\n",
    "\n",
    "To make sure we've actually encoded the string we should check we can decode it by reversing the process.\n",
    "\n",
    "We start with the special initial token `eos_token_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ede0162-9d34-4820-8b80-4afeb69b2430",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_tokens = torch.tensor([tokenizer.eos_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfcf70-86ff-4e19-8b74-677df22c6759",
   "metadata": {},
   "source": [
    "And we want to find the interval containing the number given by the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c766d196-5541-4873-9d4c-ac0983f92da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('0.282395779258410794241151697105016914449497048852471030397902')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = Decimal('0.' + digits)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd6bdb-902f-4973-a87e-affe3d0d28b4",
   "metadata": {},
   "source": [
    "And use the model to get the corresponding intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "343f6115-ba85-4001-aac1-919041dc957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818,\n",
       " Decimal('0.28029916521467944795426659667895773352564066371872542049459298141300678253173828125'),\n",
       " Decimal('0.016854189336299896240234375'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model probabilities\n",
    "with torch.inference_mode():\n",
    "    next_prob = F.softmax(model(decoded_tokens.to(model.device)).logits, dim=-1).cpu()\n",
    "\n",
    "total = Decimal(0.0)\n",
    "\n",
    "# Find the interval containing target\n",
    "for i, p in enumerate(next_prob[-1]):\n",
    "    p = Decimal(p.item())\n",
    "    if total + p >= target:\n",
    "        break\n",
    "    total += p\n",
    "\n",
    "size = p\n",
    "\n",
    "i, total, size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7680668-c8ed-4de8-99b6-ff386a17e07c",
   "metadata": {},
   "source": [
    "Our target interval lies completely within this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36978b89-ebdb-4ddb-83a0-3192902ab06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total <= interval_start < interval_end < total + size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b5409-31a5-4ef0-a6a5-4aa383000541",
   "metadata": {},
   "source": [
    "We add our newly decoded token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c458d09c-e8fc-4023-a6d6-0b116a630934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50256,   818])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_tokens = torch.cat([decoded_tokens, torch.tensor([i])], 0)\n",
    "decoded_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4b35e-ff83-4520-9531-6b40bf895824",
   "metadata": {},
   "source": [
    "And repeat the process, rescaling the probabilities by `size`, the probability of the first decoded token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec2753a7-5d1f-41ec-96c2-1617f82231ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257,\n",
       " Decimal('0.280422870633518488482959359529116914118828604032719207985596687748852673394139856100082397460937500'),\n",
       " Decimal('0.00224367765963162657527618648600764572620391845703125'))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    next_prob = (\n",
    "        model(decoded_tokens.to(model.device))\n",
    "        .logits\n",
    "        .softmax(axis=-1).cpu()\n",
    "    )\n",
    "\n",
    "for i, p in enumerate(next_prob[-1]):\n",
    "    p = Decimal(p.item()) * size\n",
    "    if total + p > target:\n",
    "        break\n",
    "    total += p\n",
    "\n",
    "size = p\n",
    "\n",
    "i, total, size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe63459-1551-45e4-806f-33e95dae385a",
   "metadata": {},
   "source": [
    "The target interval still lies within this interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60abb114-1131-4b6f-a030-0b87235daca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total < interval_start < interval_end < total + size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dcf2a3-e565-4f5f-b718-86fcd4a151ef",
   "metadata": {},
   "source": [
    "We repeat this process iteratively until we get the terminal token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c13d1b1-91d1-4f83-9010-2a9b5fbc37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = Decimal(1.0)\n",
    "total = Decimal(0.0)\n",
    "decoded_tokens = torch.tensor([tokenizer.eos_token_id])\n",
    "\n",
    "for _ in range(100):\n",
    "    with torch.inference_mode():\n",
    "        next_prob = (\n",
    "            model(decoded_tokens.to(model.device))\n",
    "            .logits\n",
    "            .softmax(axis=-1).cpu()\n",
    "        )\n",
    "\n",
    "    for i, p in enumerate(next_prob[-1]):\n",
    "        p = Decimal(p.item()) * size\n",
    "        if total + p >= target:\n",
    "            break\n",
    "        total += p\n",
    "\n",
    "    size = p\n",
    "\n",
    "    if i == tokenizer.eos_token_id:\n",
    "        break\n",
    "    assert total <= interval_start < interval_end <= total + size, \"Interval does not contain target interval\"\n",
    "    decoded_tokens = torch.cat([decoded_tokens, torch.tensor([i])], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4d950-f328-44c5-b3c6-0c5dd6470074",
   "metadata": {},
   "source": [
    "And we recover our original tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3733b32f-0989-46c3-86b0-8079a091628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (decoded_tokens == input_tokens).all()\n",
    "\n",
    "tokenizer.decode(decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a1fe6-ef62-4bd2-8aa6-d6c23e4c9c91",
   "metadata": {},
   "source": [
    "So we've demonstrated, at least in this case, that the cross-entropy is a measure of how much the data can be compressed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2efba5a5-292d-493c-9562-7755674e6cc0",
   "metadata": {},
   "source": [
    "## Intensive Quantities and Perplexity\n",
    "\n",
    "\n",
    "One issue with our measure of cross-entropy is it's an *extensive quantitity*; the longer the text the larger the cross-entropy.\n",
    "That means a text could have a high cross entropy because the model does not have good predictions of the tokens, or just because it's very long.\n",
    "One way to mitigate this is to average the sample cross-entropy over the tokens (which is often done in practice for the loss):\n",
    "\n",
    "$$  -\\frac{1}{n} (\\log P(t_1) + \\log P(t_2 \\vert t_1) + \\cdots + \\log P(t_n \\vert t_1, t_2, \\ldots, t_{n-1})) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b647dbf0-eaf4-41cd-aded-ee14d87a0113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.908674955368042"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_cross_entropy =  F.cross_entropy(logits.transpose(-1,-2),\n",
    "                                         target_tokens,\n",
    "                                         reduction='mean').item()\n",
    "average_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a311027-20a4-4c57-ac22-8d70beec6642",
   "metadata": {},
   "source": [
    "One benefit of this is that we can easily compare any average cross entropy to that of a random model that assigns equal probability of $1/\\vert V \\vert$ to each token which is $\\log(\\vert V\\vert)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4705de47-5d78-4674-ac67-ff1d02b03888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.82490511970208"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_average_cross_entropy = math.log(tokenizer.vocab_size)\n",
    "random_average_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81476e5-f81b-4d01-8a06-6dabb8953c2c",
   "metadata": {},
   "source": [
    "Perplexity is just the exponential of the average cross entropy; this is equivalent to the geometric mean of the inverse probabilities of each token:\n",
    "\n",
    "$$ \\rm{Perplexity} = \\sqrt[n]{\\frac{1}{P(t_1)} \\frac{1}{P(t_2 \\vert t_1)} \\cdots \\frac{1}{P(t_n \\vert t_1, t_2, \\ldots, t_{n-1})}} $$\n",
    "\n",
    "Note that for a uniform random model over tokens the perplexity is exactly the vocabulary size.\n",
    "In this case our token level perplexity is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d7603d1-e3be-4c8f-90bd-46d55b3d1aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.33249109741429"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_token = math.exp(average_cross_entropy)\n",
    "perplexity_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4bb98e-a24b-427a-87ce-18a310a14537",
   "metadata": {},
   "source": [
    "One downside is that it *depends on the model's tokenization*; if we use a different model with a different tokenization scheme we would not be able to compare tokens.\n",
    "In a way tokenization is an extra layer of compression that we need to take into account.\n",
    "\n",
    "An alternative would be to average over the number of characters in the text; we can rescale this by looking at the average characters per token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a3e0b9b-240a-4d79-9a2d-790058010f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.021739130434782"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_per_token = len(text) / len(tokens[0])\n",
    "characters_per_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "988b1df2-e218-4be4-a079-6329d3e56816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5792166577789175"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_average_cross_entropy = average_cross_entropy / characters_per_token\n",
    "character_average_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d68c68-f2a7-49a3-bf8d-e4e86cea0a96",
   "metadata": {},
   "source": [
    "And we could have a corresponding perplexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5704438-d68f-4189-9f08-f082b75370f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7846398992746815"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_character = math.exp(character_average_cross_entropy)\n",
    "perplexity_character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc230f-cef8-4d23-9772-15c59e3623f7",
   "metadata": {},
   "source": [
    "If we convert the character cross-entropy to entropy in *bits* we get the *bits per character* (perplexity doesn't have a unit so it is unchanged):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d139b28-c00d-4b77-ae27-4ef4c0eefab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356329997779242"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits_per_character = character_average_cross_entropy / math.log(2)\n",
    "bits_per_character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ba48f-e5be-42f8-bea7-6f65717c187b",
   "metadata": {},
   "source": [
    "If we use a specific encoding for the text, like UTF-8, we can measure *bits per byte* which aligns with the compression point of view; 8 bits per byte is no compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bb822b3-9b15-49b7-825c-bc3e7aef631b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes_per_character = 8 * len(text.encode('utf-8')) / len(text)\n",
    "bytes_per_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df4feffa-52f6-42ec-855d-e85abb2cf773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10445412497224052"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits_per_byte = bits_per_character / bytes_per_character\n",
    "bits_per_byte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1769024-2e00-4d07-bcb6-f710ba5a1bed",
   "metadata": {},
   "source": [
    "Note however this does depend on an encoding; we would get a different result for UTF-16 encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44a06f97-a7f1-4bdd-9d51-230b84245679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.06926406926407"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes_per_utf16_character = 8 * len(text.encode('utf-16')) / len(text)\n",
    "bytes_per_utf16_character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42bf96d-cab3-4869-a58c-a5ed70cab940",
   "metadata": {},
   "source": [
    "So we now have a relationship between all the important quantities:\n",
    "\n",
    "* cross-entropy is the negative log-likelihood of the text under the model\n",
    "* bits-per-character is the cross-entropy per character measured in bits (that is the logarithm is base 2)\n",
    "* bits-per-byte is the cross-entropy per byte of encoded text measured in bits; this is a real measure of how well the model can compress the text\n",
    "* perplexity is the exponential of the negative log-likelihood per token; that is it's the inverse of the geometric mean of the token likelihoods\n",
    "\n",
    "When comparing these quantities between models it's really important to keep track of the units for cross-entropy, the encoding for bits-per-byte, and the tokenization used for perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e4539-89ae-4463-84a1-d6a47c9c0430",
   "metadata": {},
   "source": [
    "# Evaluating on large text\n",
    "\n",
    "Let's now try to reproduce some of the results from the GPT-2 paper by calculating Accuracy and Perplexity for Lambada, and the bits-per-byte for enwik8 with the 1.5 billion parameter version of GPT 2.\n",
    "We don't get the exact same numbers, but we get reasonably close.\n",
    "\n",
    "\n",
    "\n",
    " Model  | LAMBADA (PPL) | LAMBADA (ACC) | CBT-CN (ACC) | CBT-NE (ACC) | WikiText2 (PPL) | PTB (PPL) | enwik8 (BPB) | text8 (BPC) | WikiText103 (PPL) | 1BW (PPL) |\n",
    "|--------|---------------|---------------|--------------|--------------|----------------|-----------|--------------|-------------|------------------|-----------|\n",
    "| 117M   | 35.13         | 45.99         | 87.65        | 83.4         | 29.41          | 65.85     | 1.16         | 1.17        | 37.50            | 75.20     |\n",
    "| 345M   | 15.60         | 55.48         | 92.35        | 87.1         | 22.76          | 47.33     | 1.06         | 1.06        | 26.37            | 55.72     |\n",
    "| 762M   | 10.87         | 60.12         | 93.45        | 88.0         | 19.93          | 40.31     | 0.97         | 1.02        | 22.05            | 44.575    |\n",
    "| 1542M  | 8.63          | 63.24         | 93.30        | 89.05        | 18.34          | 35.76     | 0.93         | 0.98        | 17.48            | 42.16     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e50f5-a0fb-424f-a7fe-192983b48870",
   "metadata": {},
   "source": [
    "## Lambada Accuracy\n",
    "\n",
    "The [Lambada dataset](https://arxiv.org/abs/1606.06031) is sentences from Book Corpus selected such that to predict the last word requires a lot of context; you can't guess it just from the last sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "016a9208-3fda-4085-979f-f9fa0b4824ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "lambada_ds = load_dataset('cimec/lambada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75f79361-f94c-4891-8137-8393ae4ba277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her pay for the evening was almost double that of the wait staff and although that might not seem like a lot to some people , it was a small fortune to claire . after loading her final tray for a server , claire went to the restroom to freshen up and begin preparations for being loaded into the cake . pam had a couple of young men from college who assisted her into the cake . brian and max were a lot of fun and always made her laugh as they hoisted her up to the top of the cake\n"
     ]
    }
   ],
   "source": [
    "text = lambada_ds['validation']['text'][0]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ac430-9a99-4303-a2bb-0e05649a2113",
   "metadata": {},
   "source": [
    "Note that this has been pre-word tokenized and lowercased, which is quite different to the data GPT-2 was trained on.\n",
    "\n",
    "For the last word prediction task we can separate out the context from the answer.\n",
    "To work with the GPT-2 BPE tokenizer it is better to put the space with the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a37d3ce0-c09d-4b58-ac02-529ad8742aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('her pay for the evening was almost double that of the wait staff and although that might not seem like a lot to some people , it was a small fortune to claire . after loading her final tray for a server , claire went to the restroom to freshen up and begin preparations for being loaded into the cake . pam had a couple of young men from college who assisted her into the cake . brian and max were a lot of fun and always made her laugh as they hoisted her up to the top of the',\n",
       " ' cake')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context, answer = text.rsplit(' ', maxsplit=1)\n",
    "answer = ' ' + answer\n",
    "\n",
    "context, answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1afa1d-0042-485e-9e15-75a731885f58",
   "metadata": {},
   "source": [
    "We can convert the context and answer to tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0a8de4b-3b77-4f9f-b5c2-357e14a7c493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([12187], [' cake'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(context, return_tensors='pt')['input_ids']\n",
    "answer_tokens = tokenizer(answer)['input_ids']\n",
    "answer_tokens, [tokenizer.decode([t]) for t in answer_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b972a-ddd8-4bc9-b197-b8147cd3e619",
   "metadata": {},
   "source": [
    "And the model's most likely prediction for the last token is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3eb79bc-884a-4d31-8a83-5d60e93af4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' cake'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    logits = model(tokens.to(model.device)).logits.cpu()[0,-1]\n",
    "    probs = logits.softmax(axis=-1)\n",
    "\n",
    "tokenizer.decode([logits.argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81c49e-d820-4752-9138-de3d76c55e09",
   "metadata": {},
   "source": [
    "With high probabilitiy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0c078a6-253e-4c0b-9c17-c90cc40e8f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'86%'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{probs[answer_tokens[0]]:0.0%}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dcc21c9-5b15-4968-b18f-5faf6e1c28bd",
   "metadata": {},
   "source": [
    "Let's look at another example (which requires remembering the name \"rowan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1faa278e-3585-4a5f-81bf-a0911560715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`` nineteen , '' she said , and he loosed a breath that could have been sadness or relief or maybe both , and told her that made her magic even more impressive . she debated saying that he would be less impressed once he learned of her nickname for him , but winked at him instead . rowan was frowning when she caught up to him , but said nothing . as they walked away , gavriel murmured , `` good luck , rowan\n"
     ]
    }
   ],
   "source": [
    "text = lambada_ds['validation']['text'][1]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76926bf0-aaa3-4d39-940f-6c12439b3274",
   "metadata": {},
   "source": [
    "In this case the answer is two tokens; we have to keep extending until we get a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9344729a-72e5-4fdb-ac00-9e7b3836b0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5752, 272], [' row', 'an'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context, answer = text.rsplit(' ', maxsplit=1)\n",
    "answer = ' ' + answer\n",
    "\n",
    "\n",
    "tokens = tokenizer(context, return_tensors='pt')['input_ids']\n",
    "answer_tokens = tokenizer(answer)['input_ids']\n",
    "answer_tokens, [tokenizer.decode([t]) for t in answer_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a560d38-1510-4192-9c0f-a01b44d211cb",
   "metadata": {},
   "source": [
    "To do this we need to know which tokens start with a space.\n",
    "We can pull this out of the tokenizer dictionary, which for some reason represents a space with `Ġ`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0469ac7a-9a57-44f6-889c-21e7d40b61f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġrow']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v in tokenizer.vocab.items() if v == 5752]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3545ade3-b05a-482a-86fd-a3dcc9aca232",
   "metadata": {},
   "source": [
    "Ġ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6729c3e-a890-4ec2-9444-3782d7e6bd33",
   "metadata": {},
   "source": [
    "We can get all the tokens that do not start with a space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb8b7b7a-2e6d-4a42-b9f8-a4ccb0ac8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_space_tokens = [v for k,v in tokenizer.vocab.items()\n",
    "                   if not k.startswith('Ġ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563237d8-4000-486b-8575-16dcba662c35",
   "metadata": {},
   "source": [
    "We can also exclude all completions tokens except those that have lowercase English letters (in particular to exclude punctuation).\n",
    "This is a slight hack and it's not clear what tricks were used in the GPT-2 paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad30c2ab-be3f-48cc-b83e-15f173d0175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_tokens = [v for k,v in tokenizer.vocab.items()\n",
    "                  if not re.match('Ġ?([a-z]+)$', k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49d1f2-54a9-47e9-8411-b63dbe07e52e",
   "metadata": {},
   "source": [
    "Then we predict the first token (which much start with a space), and continue until we get another token starting with a space.\n",
    "We can prohibit invalid tokens by setting their logits to negative infinity.\n",
    "The probability accumulates multiplicatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e516ba1e-7f19-47fc-84df-fe58110052d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word(context, max_tokens=5, invalid_tokens=invalid_tokens):\n",
    "    tokens = tokenizer(context, return_tensors='pt')['input_ids']\n",
    "    word = \"\"\n",
    "\n",
    "    for _ in range(max_tokens):\n",
    "        with torch.inference_mode():\n",
    "            logits = (\n",
    "                model(tokens.to(model.device))\n",
    "                .logits.cpu()[-1, -1].clone()\n",
    "            )\n",
    "\n",
    "            logits[invalid_tokens] = float('-inf')\n",
    "\n",
    "            # Needs to start with a space\n",
    "            if not word:\n",
    "                logits[no_space_tokens] = float('-inf')\n",
    "        \n",
    "        next_token_id = torch.argmax(logits).item()\n",
    "        next_token = tokenizer.decode([next_token_id])\n",
    "\n",
    "        # End at space after first\n",
    "        if word and next_token.startswith(' '):\n",
    "            break\n",
    "        \n",
    "        word += next_token\n",
    "        tokens = torch.cat([tokens,\n",
    "                            torch.tensor([next_token_id]).unsqueeze(0)],\n",
    "                           dim=-1)\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9be327-3115-4f93-80e1-1aad75f39331",
   "metadata": {},
   "source": [
    "In this case the model correctly predicts the next word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f824a70-53fa-4058-8290-e77e344fde23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' rowan'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_word(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025979e1-3733-412e-9f91-cb651219cda5",
   "metadata": {},
   "source": [
    "We can now go through the whole validation to get the model predictions for the next word, and the answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e814e16-9b14-4d9e-bc6f-5afaafc3c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "predictions = []\n",
    "\n",
    "for text in lambada_ds['validation']['text']:\n",
    "    context, answer = text.rsplit(' ', maxsplit=1)\n",
    "    answers.append(' ' + answer)\n",
    "    predictions.append(get_next_word(context))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c549d9b-1329-4327-833d-4389c89c9cae",
   "metadata": {},
   "source": [
    "In the paper they mention they get the right answer 52.66% of the time, but I get a slightly lower accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6d4dafb-4cc6-4de0-8f96-65bf4ad6b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46.23%'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum([a==b for a,b in zip(answers, predictions)]) / len(predictions)\n",
    "f'{accuracy:0.2%}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec50bd4-6e54-4721-a21c-a1c7090ac304",
   "metadata": {},
   "source": [
    "Since they don't share many details and it's not in their [code release](https://github.com/openai/gpt-2) it's hard to know what I've done differently.\n",
    "This shows the importance of trying to replicate evaluations before comparing results on new systems.\n",
    "\n",
    "Let's have a look at some examples the model predicted incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "479eba74-cda1-430e-81e4-82350c20ecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, ' trouble', ' a'),\n",
       " (5, ' lucius', ' the'),\n",
       " (6, ' fetch', ' read'),\n",
       " (7, ' zeus', ' the'),\n",
       " (9, ' famine', ' ankou'),\n",
       " (10, ' michael', ' but'),\n",
       " (13, ' sheila', ' the'),\n",
       " (14, ' hunk', ' beauty'),\n",
       " (15, ' kaiden', ' unless'),\n",
       " (20, ' indio', ' right'),\n",
       " (23, ' anger', ' a'),\n",
       " (24, ' kristina', ' the'),\n",
       " (25, ' joanne', ' and'),\n",
       " (26, ' father', ' but'),\n",
       " (28, ' nate', ' the'),\n",
       " (31, ' tether', ' fire'),\n",
       " (33, ' broadcast', ' radio'),\n",
       " (34, ' rug', ' fireplace'),\n",
       " (37, ' bride', ' prey'),\n",
       " (39, ' dark', ' over')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, a,b) for  i, (a,b) in enumerate(zip(answers, predictions)) if a!= b][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a92cb-cd2a-4f2f-a408-2047203e5d89",
   "metadata": {},
   "source": [
    "In the paper they mention:\n",
    "\n",
    "> Investigating GPT-2’s errors showed most\n",
    "predictions are valid continuations of the sentence, but are\n",
    "not valid final words. This suggests that the LM is not\n",
    "using the additional useful constraint that the word must be\n",
    "the final of the sentence. Adding a stop-word filter as an\n",
    "approximation to this further increases accuracy to 63.24%\n",
    "\n",
    "Looking at the 30 most common incorrect predictions this seems about right (although some of these words *could* be valid continuations of sentences like \"her\" or \"him\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b455b3e-7ddd-4cf0-a5e4-f5de49179c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' the': 'Wrong 411/411 (1.0)',\n",
       " ' and': 'Wrong 108/108 (1.0)',\n",
       " ' a': 'Wrong 96/96 (1.0)',\n",
       " ' i': 'Wrong 96/96 (1.0)',\n",
       " ' her': 'Wrong 81/81 (1.0)',\n",
       " ' but': 'Wrong 75/75 (1.0)',\n",
       " ' you': 'Wrong 60/60 (1.0)',\n",
       " ' him': 'Wrong 45/45 (1.0)',\n",
       " ' me': 'Wrong 33/33 (1.0)',\n",
       " ' my': 'Wrong 32/32 (1.0)',\n",
       " ' he': 'Wrong 31/31 (1.0)',\n",
       " ' or': 'Wrong 26/26 (1.0)',\n",
       " ' to': 'Wrong 25/25 (1.0)',\n",
       " ' it': 'Wrong 25/25 (1.0)',\n",
       " ' she': 'Wrong 21/21 (1.0)',\n",
       " ' not': 'Wrong 15/15 (1.0)',\n",
       " ' going': 'Wrong 15/15 (1.0)',\n",
       " ' do': 'Wrong 15/15 (1.0)',\n",
       " ' in': 'Wrong 14/14 (1.0)',\n",
       " ' man': 'Wrong 14/14 (1.0)'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_predictions = Counter(predictions)\n",
    "count_wrong = Counter([b for  a,b in zip(answers, predictions) if a!= b])\n",
    "\n",
    "{word: (f'Wrong {n_wrong}/{count_predictions[word]} ' \\\n",
    "        f'({n_wrong / count_predictions[word]})')\n",
    " for word, n_wrong in count_wrong.most_common(20)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24854503-644d-4ec2-ba4f-60f0d6797c40",
   "metadata": {},
   "source": [
    "Let's try removing stopwords; we'll use the nltk stopwords corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b2e2964-9847-4d2b-8c64-996a487ced14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "', '.join(stopwords.words('english')[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c886f2-3599-4be1-a495-88cc458aa527",
   "metadata": {},
   "source": [
    "And convert this into stop tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b63816b4-bf48-407b-9c34-da96c70bd054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_sequences = [tokenizer(' ' + word)['input_ids'] for \n",
    "                  word in stopwords.words('english')]\n",
    "stop_tokens = [tokens[0] for tokens in stop_sequences\n",
    "               if len(tokens) == 1]\n",
    "len(stop_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af7bb-87f5-45b3-9417-f73b6c659c29",
   "metadata": {},
   "source": [
    "Which corresponds to the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba541e53-29a4-40d1-a57a-bb1bfc23882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' i, me, my, myself, we, our, ours, ourselves, you, your, yours, yourself, yourselves, he, him'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(tokenizer.batch_decode(stop_tokens[:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2391f498-68b6-4968-b7c7-4d51578e09cd",
   "metadata": {},
   "source": [
    "Let's now get the answers excluding these stop tokens, and evaluate on the test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e78d96a4-1ab7-4b67-95eb-e73a31483030",
   "metadata": {},
   "outputs": [],
   "source": [
    "nostopword_answers = []\n",
    "nostopword_predictions = []\n",
    "\n",
    "for text in lambada_ds['test']['text']:\n",
    "    context, answer = text.rsplit(' ', maxsplit=1)\n",
    "    nostopword_answers.append(' ' + answer)\n",
    "    nostopword_predictions.append(get_next_word(context,\n",
    "                                                invalid_tokens=invalid_tokens + stop_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8274dd5-9120-4345-998b-74476c14c168",
   "metadata": {},
   "source": [
    "We get a substantial boost, but still are substantially below 63.24% in the paper; but still seems pretty good for an unsupervised result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "150bba93-c456-4d13-849a-0242dc7116aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'52.73%'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (\n",
    "    sum([a==b for a,b in zip(nostopword_answers, nostopword_predictions)]) \n",
    "    / len(nostopword_answers)\n",
    ")\n",
    "f'{accuracy:0.2%}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf7658-9a48-4232-b7de-f2e175d0fec2",
   "metadata": {},
   "source": [
    "## Lambada Perplexity\n",
    "\n",
    "They also report a perplexity of 8.63 on the answers of the Lambada test set.\n",
    "\n",
    "Let's go through how we could calculate the cross-entropy for a single example.\n",
    "First we get the tokens of the text and find the index that the answer starts at (the last space in the text):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c0cdcce-f88d-4edb-92d6-b592ab344fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = lambada_ds['validation']['text'][1]\n",
    "tokens = tokenizer(text, return_tensors='pt')['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5feed402-bc15-4b4d-ac04-b7bd4ccc6c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_first_token_id = max(i for i, t in enumerate(tokens) if t.item() not in set(no_space_tokens))\n",
    "answer_first_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e2c0126-6d9e-4a1f-a52b-5ab5a23195f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' rowan'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens[answer_first_token_id:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e20284-2e38-4674-94b6-8c7fb346e64c",
   "metadata": {},
   "source": [
    "Then we calculate the cross-entropy (negative log-likelihood) of each token and add them together.\n",
    "If we were being careful we should also account for the fact that the next token starts with a space; we are going to slightly overestimate perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03801333-1329-48d1-8084-188f1a5d5bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5461)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    logits = model(tokens.to(model.device)).logits.cpu().clone()\n",
    "\n",
    "    cross_entropy = F.cross_entropy(\n",
    "        logits[answer_first_token_id - 1:-1],\n",
    "        tokens[answer_first_token_id:],\n",
    "        reduction='sum')    \n",
    "\n",
    "cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a498c-e973-49bc-b3ab-f2fe580dd33c",
   "metadata": {},
   "source": [
    "We can then do this for all the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a9599d42-1b79-4aec-8948-1fe309b557ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropies = []\n",
    "\n",
    "for text in lambada_ds['validation']['text']:\n",
    "    tokens = tokenizer(text, return_tensors='pt')['input_ids'][0]\n",
    "    answer_first_token_id = max(i for i, t in enumerate(tokens) if t.item() not in set(no_space_tokens))\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        logits = model(tokens.to(model.device)).logits.cpu().clone()\n",
    "    \n",
    "        cross_entropy = F.cross_entropy(\n",
    "            logits[answer_first_token_id - 1:-1],\n",
    "            tokens[answer_first_token_id:],\n",
    "            reduction='sum')\n",
    "        cross_entropies.append(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69190148-c9c2-4616-9175-280080aa0208",
   "metadata": {},
   "source": [
    "And get a final perplexity by exponentiating the average cross-entropy.\n",
    "Here we're getting 16.0 which is much higher than the paper's claimed 8.63 even though it's already an underestimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff6ea094-ac23-4442-b15a-25c601998bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.9732)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(cross_entropies) / len(cross_entropies)).exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c02d6-0e06-4fc3-9462-7b5e285d82c9",
   "metadata": {},
   "source": [
    "Again as there is no code it's hard to know what is being done differently; maybe excluding the probabilities of stop-word tokens by setting the logits to `-inf`.\n",
    "My stop-token list actually has occurances in the answers, so this gives me infinite loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b027a23b-e16f-4f8c-a112-41956da0af26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' michael', ' m'),\n",
       " (' bekah', ' be'),\n",
       " (' sheila', ' she'),\n",
       " (' becca', ' be'),\n",
       " (' howie', ' how')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(a, tokenizer.decode(tokenizer(a)['input_ids'][0]))\n",
    " for a in answers if tokenizer(a)['input_ids'][0] in stop_tokens][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22637e40-ec4b-402a-b5e7-52811fe85825",
   "metadata": {},
   "source": [
    "## Bits per byte with Enwik8\n",
    "\n",
    "The [Hutter Prize](http://prize.hutter1.net/) is a competition to compress a sample of English Wikipedia as much as possible, with the motivation that good compression is closely related to intelligence.\n",
    "The best systems as of the time of writing have a compression ratio of about 0.9 bits per byte, but that size *includes the decoder*, and the weights of our 1.5 billion parameter model are much larger than the uncompressed file.\n",
    "Nevertheless it's interesting that GPT 2 gets a similar perplexity, as 0.93 bits per byte, even though it was never directly trained on the data.\n",
    "\n",
    "Let's first download enwik8 which contains the first 100 MB of a dump from English Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c53aa039-9877-497e-85ad-243d308c6bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('enwik8.zip', <http.client.HTTPMessage at 0x79ec7c1e8a50>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve('http://mattmahoney.net/dc/enwik8.zip', filename='enwik8.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "162582c9-7adf-4c55-b7d1-f1a29109df51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<mediawiki xmlns=\"http://www.mediawiki.org/xml/export-0.3/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.mediawiki.org/xml/export-0.3/ http://www.mediawiki.org/xml/export-0.3.xsd\" version=\"0.3\" xml:lang=\"en\">\\n  <siteinfo>\\n    <sitename>Wikipedia</sitename>\\n    <base>http://en.wikipedia.org/wiki/Main_Page</base>\\n    <generator>MediaWiki 1.6alpha</generator>\\n    <case>first-letter</case>\\n      <namespaces>\\n      <namespace key=\"-2\">Media</namespace>\\n      <n'\n"
     ]
    }
   ],
   "source": [
    "with ZipFile('enwik8.zip').open('enwik8') as f:\n",
    "    enwik8_bytes = f.read()\n",
    "\n",
    "print(enwik8_bytes[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd8026c-9c38-465b-9705-691179014570",
   "metadata": {},
   "source": [
    "We indeed have 1 million bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e83622df-e2e5-4978-b284-143ef9f99107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enwik8_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6dc56-9135-4887-b493-3460949fcaca",
   "metadata": {},
   "source": [
    "Now we decode it into characters, which is slightly smaller due to some multi-byte characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "25a71aa5-b7d1-4515-8e82-b66a6ade610a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99621832"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enwik8 = enwik8_bytes.decode('utf-8')\n",
    "len(enwik8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c43c2-9084-416f-84c6-b005e9e70831",
   "metadata": {},
   "source": [
    "Then we pass them through the tokenizer (which takes a long time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91a589c9-e0e3-4ddd-9b8c-c82726230793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (29013572 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(enwik8, return_attention_mask=False)['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35663a99-a6c0-4d9e-8968-d67ec087a0c3",
   "metadata": {},
   "source": [
    "And pad the start and end with an End Of Sequence token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da2cf7da-01f2-4c23-b6dd-10efc3a0b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.tensor([tokenizer.eos_token_id] + tokens + [tokenizer.eos_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292b53b-a08c-4c44-b1fb-4d194cdbd1c5",
   "metadata": {},
   "source": [
    "We end up with much fewer tokens than bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f4ae5464-7fd1-4d2b-ae17-d6a53a7fda1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29013574"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_byte = len(tokens) / len(enwik8_bytes)\n",
    "\n",
    "tokens_per_byte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455141c4-5f2b-43c5-8c9d-28628ec347eb",
   "metadata": {},
   "source": [
    "This is real compression; even though representing the whole vocabulary requires 16 bits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "feb39fbd-0c13-4387-868d-a1038b2a4fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(math.log2(tokenizer.vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd238f-7253-47f4-86b0-4c6b75c8064f",
   "metadata": {},
   "source": [
    "A baseline tokenizer would only halve the tokens per byte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dca745cf-1db3-457c-bb88-440198dfe66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 / math.ceil(math.log2(tokenizer.vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9f2df-3dd0-4c4e-a56b-6e562be0b8b6",
   "metadata": {},
   "source": [
    "### Sampling the cross-entropy loss\n",
    "\n",
    "Transformer models can only take a finite sequence-length due to memory constraints, since attention is quadratic in length.\n",
    "When calculating the cross-entropy we can only do it over blocks at most the size of the maximum context length.\n",
    "We can get an approximation of the true value by sampling over random blocks of the text.\n",
    "\n",
    "Let's say we started with these 3 indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f08ccef5-ae8c-4794-a617-6dcf7af193ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.tensor([0,8,15]).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a9966-6279-46c5-8522-f287b6c560fe",
   "metadata": {},
   "source": [
    "If we could fit at most 5 tokens into the model then we would get all windows of length 5 starting at these indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33627402-4ec3-4905-ab2d-8ec727feb8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 8,  9, 10, 11, 12],\n",
       "        [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 5\n",
    "\n",
    "offsets = torch.arange(sequence_length)\n",
    "input_positions = idxs + offsets\n",
    "input_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866840f3-006a-4594-ba74-0993b7fc89f2",
   "metadata": {},
   "source": [
    "And try to predict the tokens at the next position along:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b8793d2b-34eb-463c-8ae4-fb16fee4c826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 9, 10, 11, 12, 13],\n",
       "        [16, 17, 18, 19, 20]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_positions = idxs + offsets + 1\n",
    "target_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50612cff-bfd4-439c-8709-a1d4566c306b",
   "metadata": {},
   "source": [
    "The tokens at the input positions are given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85c195f7-e585-465f-91ca-2c19f14fe776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256,    27, 11431, 15466, 35555],\n",
       "        [ 1378,  2503,    13, 11431, 15466],\n",
       "        [   14, 19875,    14, 39344,    12]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokens[input_positions]\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ecc42e-fc53-46f5-8d78-563303ce9267",
   "metadata": {},
   "source": [
    "And the target tokens are shifted along by one position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "036ed293-2e3c-41bb-8808-10fa6d14557c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   27, 11431, 15466, 35555,  5907],\n",
       "        [ 2503,    13, 11431, 15466,    13],\n",
       "        [19875,    14, 39344,    12,    15]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ids = tokens[target_positions]\n",
    "target_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052acadb-7a12-49ae-afe3-a3dd354e8bc1",
   "metadata": {},
   "source": [
    "We can then calculate the cross-entropy loss of the batch, getting a value for every input token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "81d73da5-1a76-4b07-875c-dba112af04ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.1655e+00, 8.8852e+00, 9.3616e+00, 5.3536e+00, 1.1329e-02],\n",
       "        [7.0595e-01, 2.3947e-03, 6.1137e+00, 5.3579e+00, 1.8865e-03],\n",
       "        [9.1390e+00, 1.1836e+00, 6.4103e+00, 2.5620e+00, 6.3928e+00]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = input_ids.to(model.device)\n",
    "target_ids = target_ids.to(model.device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    logits = model(input_ids=input_ids).logits\n",
    "    cross_entropy = F.cross_entropy(logits.transpose(-1,-2),\n",
    "                                    target_ids,\n",
    "                                    reduction='none')    \n",
    "\n",
    "cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c67f4-d435-46cf-b438-2f80757f3380",
   "metadata": {},
   "source": [
    "To aggregate we can take the average over all of these to get a cross-entropy per token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "18c0173c-8b77-4f64-9aff-907b83283c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5764, device='cuda:0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f22e5-76cb-484e-a9c7-c829e15ab5bd",
   "metadata": {},
   "source": [
    "We can scale this up to a large number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f04cc223-15ed-4695-80d2-12abe74c0785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1024])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 1024\n",
    "num_samples = 512\n",
    "batch_size = 4\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(2147483647)\n",
    "\n",
    "sample_idx = torch.randint(tokens.size(-1) - (context_length + 1),\n",
    "                           size=(num_samples,1),\n",
    "                           generator=g)\n",
    "\n",
    "offsets = torch.arange(context_length)\n",
    "\n",
    "sample_cross_entropies = []\n",
    "\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    idxs = sample_idx[i:i+batch_size]\n",
    "\n",
    "    input_ids = tokens[idxs + offsets].to(model.device)\n",
    "    target_ids = tokens[idxs + offsets+1].to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        logits = model(input_ids=input_ids).logits\n",
    "        cross_entropy = F.cross_entropy(logits.transpose(-1,-2),\n",
    "                                        target_ids,\n",
    "                                        reduction='none')\n",
    "\n",
    "        sample_cross_entropies.append(cross_entropy.cpu())\n",
    "\n",
    "sample_cross_entropies = torch.cat(sample_cross_entropies, axis=0)\n",
    "sample_cross_entropies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ab1e5-4936-4af0-9d84-6cfd75cb4d43",
   "metadata": {},
   "source": [
    "This gives a cross-entropy of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bfa6606f-44f3-45b6-8f38-84a9c5023e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.428089141845703"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = sample_cross_entropies.mean().item()\n",
    "cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a515e0-a615-4097-b3f2-0fbf9b97092b",
   "metadata": {},
   "source": [
    "Or in bits-per-byte we get something a little bigger than the 0.93:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0a650cf1-2c58-43de-a17f-5edccd5d4ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.01634322365168"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_byte * cross_entropy / math.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea804b-23cb-4ddc-a88f-5d3fce460405",
   "metadata": {},
   "source": [
    "### Dependence of log-likelihood on amount of context\n",
    "\n",
    "Notice that the cross-entropy is much higher for the first few tokens than the later tokens.\n",
    "The average over all the tokens (dashed line) is slightly higher than the average over the later tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d21083a1-a19f-4ace-92b0-0dfda109d9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at 1 token of context: 6.65 nats/token\n",
      "Loss at 20 tokens of context: 3.39 nats/token\n",
      "Loss at 1024 tokens of context: 2.31 nats/token\n",
      "\n",
      "Average over all context windows: 2.43 nats/token\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACXh0lEQVR4nO3dd3wT9RsH8E9Gk+6WQhe0tFBWS9kglL2nDEVQRJniD2WDiqjsjTKUJSKiIgrIFGTvIRvKLrPsMkt3aZvk+/uj5HqXXMa1SRPgeb9eviSXby5Prpe7J98pY4wxEEIIIYQ4IbmjAyCEEEIIMYUSFUIIIYQ4LUpUCCGEEOK0KFEhhBBCiNOiRIUQQgghTosSFUIIIYQ4LUpUCCGEEOK0KFEhhBBCiNOiRIUQQgghTosSFUIK4Ndff4VMJsPNmzcLvK/GjRujcePGBd7Py2rcuHGQyWR48uSJo0Ox6GWKtVevXggPD3d0GITkGyUqheD69ev43//+h9KlS8PV1RXe3t6oV68evv/+e2RmZjo6PIe5f/8+xo0bh9jYWEeHQoioKVOmYP369Y4Og7zkCus82rx5M8aNG2f39ylslKjY2b///otKlSph1apVaN++PebOnYupU6eiZMmS+PzzzzFkyBBHh+gw9+/fx/jx41/qROXDDz9EZmYmwsLCHB0KsYNXIVFZvHgxLl++7OgwXmuFmaiMHz/e7u9T2JSODuBVFh8fj/feew9hYWHYvXs3goODuecGDBiAa9eu4d9//zX5ep1Oh+zsbLi6uhZGuE4vIyMD7u7ujg5DQKFQQKFQODqMQvf8+XOoVCrI5fRbx55scc67uLjYKBrHcsbvPykcdJWxoxkzZiAtLQ1LliwRJCl6ZcqUEdSoyGQyDBw4EMuXL0fFihWhVquxdetWAMDp06fRpk0beHt7w9PTE82aNcORI0cE+8vJycH48eNRtmxZuLq6omjRoqhfvz527NjBlXnw4AF69+6NkJAQqNVqBAcHo2PHjlb3sfjjjz9Qo0YNuLm5wc/PD++99x7u3LkjKNO4cWNER0fj4sWLaNKkCdzd3VGiRAnMmDGDK7N3717UqlULANC7d2/IZDLIZDL8+uuvgn2cPHkSDRs2hLu7O7766isAwKNHj9C3b18EBgbC1dUVVapUwW+//SaI4ebNm5DJZPjuu+8we/ZshIWFwc3NDY0aNcL58+e5ckuXLoVMJsPp06eNPuuUKVOgUChw7949k8dDrI/KiRMn0KpVKxQrVgxubm4oVaoU+vTpY9XxNWTNZ61evTrefvttwbZKlSpBJpPh7Nmz3LaVK1dCJpPh0qVL3LZ79+6hT58+CAwMhFqtRsWKFfHLL78I9rV3717IZDKsWLEC33zzDUqUKAF3d3ekpKSIxlyQeAAgKSkJvXr1gq+vL3x8fNC7d29kZGQYvY+tzkVTZDIZ0tPT8dtvv3HnZ69eveweq9g5n5WVhbFjx6JMmTJQq9UIDQ3FF198gaysLIufQ6yPyooVK1CjRg14eXnB29sblSpVwvfff292P/zv1Pz581G6dGm4u7ujZcuWuHPnDhhjmDhxIkJCQuDm5oaOHTsiMTHRaD8LFizgrm/FixfHgAEDkJSUVCjHAgCOHj2Ktm3bokiRIvDw8EDlypWNPvvu3bvRoEEDeHh4wNfXFx07djQ6T/X9lK5du2b2HLB0Hln6DmZmZqJChQqoUKGCoKtAYmIigoODUbduXWi1WvTq1Qvz58/n3lP/3yuBEbspUaIEK126tNXlAbDIyEjm7+/Pxo8fz+bPn89Onz7Nzp8/zzw8PFhwcDCbOHEimzZtGitVqhRTq9XsyJEj3Ou/+uorJpPJWL9+/djixYvZzJkzWbdu3di0adO4MnXr1mU+Pj7sm2++YT///DObMmUKa9KkCdu3b5/F+CZNmsRkMhl799132YIFC9j48eNZsWLFWHh4OHv27BlXrlGjRqx48eIsNDSUDRkyhC1YsIA1bdqUAWCbN29mjDH24MEDNmHCBAaAffzxx2zZsmVs2bJl7Pr169w+goKCmL+/Pxs0aBBbtGgRW79+PcvIyGCRkZHMxcWFDRs2jP3www+sQYMGDACbM2cOF0N8fDwDwCpVqsTCw8PZ9OnT2fjx45mfnx/z9/dnDx48YIwxlpKSwtzc3NiIESOMPm9UVBRr2rSp2WOydOlSBoDFx8czxhh7+PAhK1KkCCtXrhz79ttv2eLFi9nXX3/NIiMjLR7fRo0asUaNGnGPrf2sgwcPZv7+/tzjp0+fMplMxuRyOZs3bx63fcCAAYJyDx48YCEhISw0NJRNmDCBLVy4kHXo0IEBYLNnz+bK7dmzhwFgUVFRrGrVqmzWrFls6tSpLD09XfRz5DeesWPHMgCsWrVq7O2332YLFixgH330EQPAvvjiC8F72PJcNGXZsmVMrVazBg0acOfnf//9Z9dYxc55rVbLWrZsydzd3dnQoUPZokWL2MCBA5lSqWQdO3Y0+xkYY6xnz54sLCyMe7x9+3YGgDVr1ozNnz+fzZ8/nw0cOJB16dLF7H7036mqVauyqKgoNmvWLPbNN98wlUrF6tSpw7766itWt25d9sMPP7DBgwczmUzGevfuLdiH/rg1b96czZ07lw0cOJApFApWq1Ytlp2dbfdjsX37dqZSqVhYWBgbO3YsW7hwIRs8eDBr3rw5V2bHjh1MqVSycuXKsRkzZnB/ryJFinDfc/5nsXQOmDuPrP0OHjlyhCkUCjZs2DBu23vvvcfc3NzY5cuXGWOM/ffff6xFixYMAPc+y5Yts3hMXgaUqNhJcnIyA2DVl0cPAJPL5ezChQuC7Z06dWIqlYq7iTPG2P3795mXlxdr2LAht61KlSqsXbt2Jvf/7NkzBoB9++231n+QF27evMkUCgWbPHmyYPu5c+eYUqkUbG/UqBEDwH7//XduW1ZWFgsKCmKdO3fmth0/fpwBYEuXLjV6P/0+fvzxR8H2OXPmMADsjz/+4LZlZ2ezmJgY5unpyVJSUhhjeRdVNzc3dvfuXa7s0aNHGQDBF75bt26sePHiTKvVcttOnTplMjY+w0Rl3bp1DAA7fvy42deJMUxUrP2sf//9NwPALl68yBhj7J9//mFqtZp16NCBvfvuu9xrK1euzN566y3ucd++fVlwcDB78uSJII733nuP+fj4sIyMDMZYXqJSunRpbps5+Y1Hf+Hv06ePYH9vvfUWK1q0KPfYHueiKR4eHqxnz55G2+0Zq+E5v2zZMiaXy9mBAwcE23/88UcGgB06dMjsZzBMVIYMGcK8vb2ZRqMx+zpD+u+Uv78/S0pK4raPGjWKAWBVqlRhOTk53PZu3boxlUrFnj9/zhhj7NGjR0ylUrGWLVsKvmvz5s1jANgvv/zCbbPHsdBoNKxUqVIsLCxMkCAyxphOp+P+XbVqVRYQEMCePn3KbTtz5gyTy+WsR48e3DZrzwHGTJ9H1n4HGcs9znK5nO3fv5/7jvF/sDCWm/y/ivUP1PRjJ/pqcS8vL0mva9SoEaKiorjHWq0W27dvR6dOnVC6dGlue3BwMN5//30cPHiQey9fX19cuHABV69eFd23m5sbVCoV9u7di2fPnkmKa+3atdDpdOjatSuePHnC/RcUFISyZctiz549gvKenp744IMPuMcqlQpvvPEGbty4YfV7qtVq9O7dW7Bt8+bNCAoKQrdu3bhtLi4uGDx4MNLS0rBv3z5B+U6dOqFEiRLc4zfeeAO1a9fG5s2buW09evTA/fv3BZ9h+fLlcHNzQ+fOna2OF8j9GwDApk2bkJOTI+m1hqz9rA0aNAAA7N+/HwBw4MAB1KpVCy1atMCBAwcA5DZRnD9/nivLGMOaNWvQvn17MMYEf9NWrVohOTkZp06dEsTTs2dPuLm5WYw7P/Hw9e/f32h/T58+5c5zR5yLptg6VrFz/u+//0ZkZCQqVKgg2EfTpk0BwGgflvj6+iI9PV3QJCxFly5d4OPjwz2uXbs2AOCDDz6AUqkUbM/OzuaaTnfu3Ins7GwMHTpU0LepX79+8Pb2NuqvZ+tjcfr0acTHx2Po0KHc91RP30SSkJCA2NhY9OrVC35+ftzzlStXRosWLQTXDT1L54ApUr+D48aNQ8WKFdGzZ098+umnaNSoEQYPHmz2PV4VlKjYibe3NwAgNTVV0utKlSolePz48WNkZGSgfPnyRmUjIyOh0+m4tu4JEyYgKSkJ5cqVQ6VKlfD5558L+gSo1WpMnz4dW7ZsQWBgIBo2bIgZM2bgwYMHXJnk5GQ8ePCA+0/fxnz16lUwxlC2bFn4+/sL/rt06RIePXokiC0kJMSofbRIkSKSEqQSJUpApVIJtt26dQtly5Y16sQZGRnJPc9XtmxZo/2WK1dO0KekRYsWCA4OxvLlywHkdmL+66+/0LFjx3wlmp07d8b48eNRrFgxdOzYEUuXLrW6/ZzP2s8aGBiIsmXLcknAgQMH0KBBAzRs2BD379/HjRs3cOjQIeh0Oi4xePz4MZKSkvDTTz8Z/T31NwfDv6nhuWlKfuLhK1mypOBxkSJFAIA7dxxxLppi61jFzvmrV6/iwoULRq8vV64cAOO/kyWffvopypUrhzZt2iAkJAR9+vTh+sLl5zPrk5bQ0FDR7fpjoT9fDa9lKpUKpUuXNvru2vpYXL9+HQAQHR1tsoypGIHc792TJ0+Qnp4u2G7pHDBF6ndQpVLhl19+QXx8PFJTU7n+da8DGvVjJ97e3ihevLig46Y1rPnFakrDhg1x/fp1bNiwAdu3b8fPP/+M2bNn48cff8RHH30EABg6dCjat2+P9evXY9u2bRg9ejSmTp2K3bt3o1q1ahgyZIigs2ajRo2wd+9e6HQ6yGQybNmyRXSUi6enp+CxqZEwjDGrP09BjoUUCoUC77//PhYvXowFCxbg0KFDuH//vuBXuLVkMhlWr16NI0eOYOPGjdi2bRv69OmDmTNn4siRI0bHyVbq16+PXbt2ITMzEydPnsSYMWMQHR0NX19fHDhwAJcuXYKnpyeqVasGIDcZA3J/Bffs2VN0n5UrVxY8lvL3kBoPn6VzxxHnoim2jlXsGOt0OlSqVAmzZs0SfS/DBMGSgIAAxMbGYtu2bdiyZQu2bNmCpUuXokePHkYdtcWY+sy2Ps6FcSxsIb+fOz/fwW3btgHIHXV39epVq388vOwoUbGjN998Ez/99BMOHz6MmJiYfO3D398f7u7uovMgxMXFQS6XC76cfn5+6N27N3r37o20tDQ0bNgQ48aN4xIVAIiIiMCIESMwYsQIXL16FVWrVsXMmTPxxx9/4IsvvhDcoPW/DiIiIsAYQ6lSpbhfLwWVn18DYWFhOHv2LHQ6naCmIS4ujnueT6wZ7MqVK0ajIHr06IGZM2di48aN2LJlC/z9/dGqVSvJ8enVqVMHderUweTJk/Hnn3+ie/fuWLFiheDvYImUz9qgQQMsXboUK1asgFarRd26dSGXy1G/fn0uMahbty53UfX394eXlxe0Wi2aN2+e789pitR4pLDHuWhKQX+x2iLWiIgInDlzBs2aNbPZL2iVSoX27dujffv20Ol0+PTTT7Fo0SKMHj0aZcqUscl7GNKfr5cvXxY0Y2dnZyM+Pt6q87AgxyIiIgIAcP78eZPvxY/RUFxcHIoVKwYPDw9J7wuIn0dSv4Nnz57FhAkT0Lt3b8TGxuKjjz7CuXPnBM1wr2oNCzX92NEXX3wBDw8PfPTRR3j48KHR89evX7c4JFChUKBly5bYsGGDoLni4cOH+PPPP1G/fn2umenp06eC13p6eqJMmTJcs0NGRgaeP38uKBMREQEvLy+uTFRUFJo3b879V6NGDQDA22+/DYVCgfHjxxv9UmCMGb23NfRfeMOhiea0bdsWDx48wMqVK7ltGo0Gc+fOhaenJxo1aiQov379esHw4mPHjuHo0aNo06aNoFzlypVRuXJl/Pzzz1izZg3ee+89QXu7tZ49e2Z0fKpWrQoAkpt/pHxWfRPK9OnTUblyZe7i1aBBA+zatQsnTpwQNLMoFAp07twZa9asEa31e/z4saRYDUmNRwp7nIumeHh4SDo/Ddki1q5du+LevXtYvHix0XOZmZlGTRGWGL6nXC7nfrnnp4nSWs2bN4dKpcIPP/wgOBZLlixBcnIy2rVrZ3EfBTkW1atXR6lSpTBnzhyjv6k+nuDgYFStWhW//faboMz58+exfft2tG3b1mKMYsTOIynfwZycHPTq1QvFixfH999/j19//RUPHz7EsGHDjN4HkHZNfRlQjYodRURE4M8//8S7776LyMhI9OjRA9HR0cjOzsZ///2Hv//+22heBjGTJk3Cjh07UL9+fXz66adQKpVYtGgRsrKyBPNBREVFoXHjxqhRowb8/Pxw4sQJrF69GgMHDgSQW5PQrFkzdO3aFVFRUVAqlVi3bh0ePnyI9957z+JnmTRpEkaNGoWbN2+iU6dO8PLyQnx8PNatW4ePP/4Yn332meTj4+vrix9//BFeXl7w8PBA7dq1zVZnfvzxx1i0aBF69eqFkydPIjw8HKtXr8ahQ4cwZ84coz4lZcqUQf369fHJJ58gKysLc+bMQdGiRfHFF18Y7btHjx7cZ8hPsw8A/Pbbb1iwYAHeeustREREIDU1FYsXL4a3t7fki5yUz1qmTBkEBQXh8uXLGDRoELe9YcOGGDlyJAAYJQbTpk3Dnj17ULt2bfTr1w9RUVFITEzEqVOnsHPnTtE5MKyVn3isZY9z0ZQaNWpg586dmDVrFooXL45SpUpxnUcLK9YPP/wQq1atQv/+/bFnzx7Uq1cPWq0WcXFxWLVqFbZt24aaNWtaHdNHH32ExMRENG3aFCEhIbh16xbmzp2LqlWrcv2f7MHf3x+jRo3C+PHj0bp1a3To0AGXL1/GggULUKtWLau+cwU5FnK5HAsXLkT79u1RtWpV9O7dG8HBwYiLi8OFCxe4ZpVvv/0Wbdq0QUxMDPr27YvMzEzMnTsXPj4++Z6e3tR5ZO13cNKkSYiNjcWuXbvg5eWFypUrY8yYMfjmm2/wzjvvcNcW/Q/LwYMHo1WrVlAoFBav7S+FQhtf9Bq7cuUK69evHwsPD2cqlYp5eXmxevXqsblz53JD9xjLHZ48YMAA0X2cOnWKtWrVinl6ejJ3d3fWpEkTbiy+3qRJk9gbb7zBfH19mZubG6tQoQKbPHkyNz/BkydP2IABA1iFChWYh4cH8/HxYbVr12arVq2y+rOsWbOG1a9fn3l4eDAPDw9WoUIFNmDAAG4sP2O5QwsrVqxo9FrDYZKMMbZhwwYWFRXFlEqlYDiwqX0wljtXSe/evVmxYsWYSqVilSpVMhpGrB9K+e2337KZM2ey0NBQbi6DM2fOiO43ISGBKRQKVq5cOauPh+Hw5FOnTrFu3bqxkiVLMrVazQICAtibb77JTpw4YXFfhsOTrf2sel26dGEA2MqVK7lt2dnZzN3dnalUKpaZmWn0mocPH7IBAwaw0NBQ5uLiwoKCglizZs3YTz/9xJXRD0/++++/LR+QAsSjH+75+PFjwXbDY6xn63NRTFxcHGvYsCFzc3NjALghpoUZK2O5x2369OmsYsWKTK1WsyJFirAaNWqw8ePHs+TkZLOfwfCzrl69mrVs2ZIFBAQwlUrFSpYsyf73v/+xhIQEs/vhf6f4TJ0f+mNhOFR/3rx5rEKFCszFxYUFBgayTz75xGi4sL2OBWOMHTx4kLVo0YJ5eXkxDw8PVrlyZTZ37lxBmZ07d7J69eoxNzc35u3tzdq3b88Nt9eTcg6YOo8Ys/wdPHnyJFMqlWzQoEGC99FoNKxWrVqsePHi3PHTaDRs0KBBzN/fn8lksldmqLKMMRv0KCPEydy8eROlSpXCt99+a/Wv6ydPniA4OBhjxozB6NGj7RwhIYQQa1AfFUJe+PXXX6HVavHhhx86OhRCCCEvUB8V8trbvXs3Ll68iMmTJ6NTp05GI4IIIYQ4DiUq5LU3YcIE/Pfff6hXrx7mzp3r6HAIIYTwUB8VQgghhDgt6qNCCCGEEKdFiQohhBBCnNZL3UdFp9Ph/v378PLyemWnDiaEEEJeNYwxpKamonjx4kYLrxp6qROV+/fvO2QRKkIIIYQU3J07dxASEmK2zEudqOinEL9z5w633g0hhBBCnFtKSgpCQ0ONlj0R81InKvrmHm9vb0pUCCGEkJeMNd02qDMtIYQQQpwWJSqEEEIIcVqUqBBCCCHEaVGiQgghhBCnRYkKIYQQQpwWJSqEEEIIcVqUqBBCCCHEaVGiQgghhBCnRYkKIYQQQpwWJSqEEEIIcVqUqBBCCCHEaVGiQgghhBCn9VIvSmgvGdkaJKZnQ6WUI8DL1dHhEEIIIa8tqlERsePiQ9SfvgfDVsY6OhRCCCHktUaJigj5i2WntTrm4EgIIYSQ1xslKiL0iQrlKYQQQohjUaIiQvHiqDBGmQohhBDiSJSoiJBR0w8hhBDiFChREaGgph9CCCHEKVCiIkJOTT+EEEKIU6BERQTX9EOJCiGEEOJQlKiI4Jp+dA4OhBBCCHnNUaIiIm94MtWoEEIIIY5EiYoIeW6eQokKIYQQ4mCUqIiQy2nUDyGEEOIMKFERQU0/hBBCiHOgREUE1/RDVSqEEEKIQ1GiIoKafgghhBDnQImKCGr6IYQQQpwDJSoiqOmHEEIIcQ6UqIiQ01o/hBBCiFOgREWEnKbQJ4QQQpwCJSoiFC/afmhRQkIIIcSxKFERkTczrWPjIIQQQl53lKiI4FZPpkyFEEIIcShKVEQo5DQ8mRBCCHEGlKiI0Df9UJ5CCCGEOBYlKiLk1PRDCCGEOAVKVETIqemHEEIIcQqUqIigph9CCCHEOVCiIoImfCOEEEKcAyUqImhRQkIIIcQ5UKIigt/0Q7PTEkIIIY5DiYoIfY0KQLPTEkIIIY5EiYoI/agfgJp/CCGEEEeiREUEL0+huVQIIYQQB6JERQS/6YcqVAghhBDHKVCikpWVZas4nIqCmn4IIYQQpyApUdmyZQt69uyJ0qVLw8XFBe7u7vD29kajRo0wefJk3L9/315xFioZv+mHEhVCCCHEYaxKVNatW4dy5cqhT58+UCqVGDlyJNauXYtt27bh559/RqNGjbBz506ULl0a/fv3x+PHj+0dt10p+E0/OgcGQgghhLzmlNYUmjFjBmbPno02bdpALjfObbp27QoAuHfvHubOnYs//vgDw4YNs22khUg4PJlqVAghhBBHsSpROXz4sFU7K1GiBKZNm1aggJwBNf0QQgghzqHAo360Wi1iY2Px7NkzW8TjFGQyGTdEmWpUCCGEEMeRnKgMHToUS5YsAZCbpDRq1AjVq1dHaGgo9u7da+v4HEbf/EN5CiGEEOI4khOV1atXo0qVKgCAjRs3Ij4+HnFxcRg2bBi+/vprmwfoKNwKyjThGyGEEOIwkhOVJ0+eICgoCACwefNmdOnShRsRdO7cOZsH6Cj6PsPU9EMIIYQ4juREJTAwEBcvXoRWq8XWrVvRokULAEBGRgYUCoXkAO7du4cPPvgARYsWhZubGypVqoQTJ05I3o+tUdMPIYQQ4nhWjfrh6927N7p27Yrg4GDIZDI0b94cAHD06FFUqFBB0r6ePXuGevXqoUmTJtiyZQv8/f1x9epVFClSRGpYNkdNP4QQQojjSU5Uxo0bh+joaNy5cwddunSBWq0GACgUCnz55ZeS9jV9+nSEhoZi6dKl3LZSpUpJDckuaNQPIYQQ4niSm35+//13tG/fHsOGDUNISAi3vVu3bkhOTpa0r3/++Qc1a9ZEly5dEBAQgGrVqmHx4sVSQ7IL+YtMhRIVQgghxHEkJyq9e/cWTUhSU1PRu3dvSfu6ceMGFi5ciLJly2Lbtm345JNPMHjwYPz222+i5bOyspCSkiL4z170TT/U8kMIIYQ4juSmH8YYZPypW1+4e/cufHx8JO1Lp9OhZs2amDJlCgCgWrVqOH/+PH788Uf07NnTqPzUqVMxfvx4qSHnC/VRIYQQQhzP6kSlWrVqkMlkkMlkaNasGZTKvJdqtVrEx8ejdevWkt48ODgYUVFRgm2RkZFYs2aNaPlRo0Zh+PDh3OOUlBSEhoZKek9r6fuoUMsPIYQQ4jhWJyqdOnUCAMTGxqJVq1bw9PTknlOpVAgPD0fnzp0lvXm9evVw+fJlwbYrV64gLCxMtLxareY679pbXtMPZSqEEEKIo1idqIwdOxYAEB4ejnfffReurq4FfvNhw4ahbt26mDJlCrp27Ypjx47hp59+wk8//VTgfRcU1agQQgghjie5M23Pnj1tkqQAQK1atbBu3Tr89ddfiI6OxsSJEzFnzhx0797dJvsvCBnVqBBCCCEOJ7kzrVarxezZs7Fq1Srcvn0b2dnZgucTExMl7e/NN9/Em2++KTUMu5PRPCqEEEKIw0muURk/fjxmzZqFd999F8nJyRg+fDjefvttyOVyjBs3zg4hOgYNTyaEEEIcT3Kisnz5cixevBgjRoyAUqlEt27d8PPPP2PMmDE4cuSIPWJ0CDk3ApsyFUIIIcRRJCcqDx48QKVKlQAAnp6e3ORvb775Jv7991/bRudAVKNCCCGEOJ7kRCUkJAQJCQkAgIiICGzfvh0AcPz48UIbOlwYuD4qlKkQQgghDiM5UXnrrbewa9cuAMCgQYMwevRolC1bFj169ECfPn1sHqCjUI0KIYQQ4niSR/1MmzaN+/e7776LkiVL4vDhwyhbtizat29v0+AcSZ+oMBr1QwghhDiM5ETFUExMDGJiYmwRi1PJG57s2DgIIYSQ11m+EpWrV69iz549ePToEXQ6neC5MWPG2CQwR6Mp9AkhhBDHk5yoLF68GJ988gmKFSuGoKAgwUrKMpnslUlUaMI3QgghxPEkJyqTJk3C5MmTMXLkSHvE4zS4PioOjoMQQgh5nUke9fPs2TN06dLFHrE4lbxFCSlVIYQQQhxFcqLSpUsXbu6UVxm3KKHOQkFCCCGE2I3kpp8yZcpg9OjROHLkCCpVqgQXFxfB84MHD7ZZcI4kpz4qhBBCiMNJTlR++ukneHp6Yt++fdi3b5/gOZlM9golKjThGyGEEOJokhOV+Ph4e8ThdGjCN0IIIcTxJPdReV3QhG+EEEKI41mVqEybNg2ZmZlW7fDo0aOvxCrKNI8KIYQQ4nhWJSoXL15EyZIl8emnn2LLli14/Pgx95xGo8HZs2exYMEC1K1bF++++y68vLzsFnBhoZlpCSGEEMezqo/K77//jjNnzmDevHl4//33kZKSAoVCAbVajYyMDABAtWrV8NFHH6FXr15wdXW1a9CFQc6bcZcQQgghjmF1Z9oqVapg8eLFWLRoEc6ePYtbt24hMzMTxYoVQ9WqVVGsWDF7xlnoqOmHEEIIcTzJo37kcjmqVq2KqlWr2iEc5yGnCd8IIYQQh6NRPybQhG+EEEKI41GiYkLePCoODoQQQgh5jVGiYoKMRv0QQgghDkeJiglymvCNEEIIcThKVEygUT+EEEKI40ke9ZOeno5p06Zh165dePToEXQGw2Ju3Lhhs+Acidb6IYQQQhxPcqLy0UcfYd++ffjwww8RHBzM9eV41XCJioPjIIQQQl5nkhOVLVu24N9//0W9evXsEY/T4Jp+qJMKIYQQ4jCS+6gUKVIEfn5+9ojFqeSt9ePgQAghhJDXmOREZeLEiRgzZgy3xs+riiZ8I4QQQhxPctPPzJkzcf36dQQGBiI8PBwuLi6C50+dOmWz4ByJJnwjhBBCHE9yotKpUyc7hOF8aMI3QgghxPEkJypjx461RxxOR0YTvhFCCCEOl68J35KSkvDzzz9j1KhRSExMBJDb5HPv3j2bBudI1EeFEEIIcTzJNSpnz55F8+bN4ePjg5s3b6Jfv37w8/PD2rVrcfv2bfz+++/2iLPQ0YRvhBBCiONJrlEZPnw4evXqhatXr8LV1ZXb3rZtW+zfv9+mwTmSjDrTEkIIIQ4nOVE5fvw4/ve//xltL1GiBB48eGCToJwBLUpICCGEOJ7kREWtViMlJcVo+5UrV+Dv72+ToJyBnEb9EEIIIQ4nOVHp0KEDJkyYgJycHAC5TSS3b9/GyJEj0blzZ5sH6Cj6GhXqo0IIIYQ4juREZebMmUhLS0NAQAAyMzPRqFEjlClTBl5eXpg8ebI9YnQIGU2hTwghhDic5FE/Pj4+2LFjBw4dOoQzZ84gLS0N1atXR/PmzV+p2gdq+iGEEEIcT3Ki8u233+Lzzz9HvXr1BCsoa7VafPDBB/jrr79sGqCj0IRvhBBCiONJbvr59ttvsWTJEsE2rVaL9957D7GxsbaKy+GojwohhBDieJJrVP7991+0bNkSPj4+eOedd6DRaNC1a1fExcVhz5499ojRIbgJ3xwcByGEEPI6k5yo1KpVC2vWrEGnTp2gUqmwZMkSXLt2DXv27EFgYKA9YnQIrjMttf0QQgghDpOvtX6aNm2K33//HZ07d0Z8fDz27dv3SiUpAE34RgghhDgDq2pU3n77bdHt/v7+8PX1xccff8xtW7t2rW0iczAa9UMIIYQ4nlWJio+Pj+j2Vq1a2TQYZ0KdaQkhhBDHsypRWbp0qb3jcDo04RshhBDieJI70+o9fvwYly9fBgCUL1/+lVrnB6CmH0IIIcQZSO5Mm56ejj59+iA4OBgNGzZEw4YNUbx4cfTt2xcZGRn2iNEhaMI3QgghxPEkJyrDhw/Hvn37sHHjRiQlJSEpKQkbNmzAvn37MGLECHvE6BDUR4UQQghxPMlNP2vWrMHq1avRuHFjblvbtm3h5uaGrl27YuHChbaMz2H0fVQoTyGEEEIcR3KNSkZGhuicKQEBAa9U04/iRZWKhtp+CCGEEIeRnKjExMRg7NixeP78ObctMzMT48ePR0xMjE2DcyQfNxcAQHJmtoMjIYQQQl5fkpt+5syZg9atWyMkJARVqlQBAJw5cwaurq7Ytm2bzQN0FD8PFQDgSRolKoQQQoijSE5UKlWqhKtXr2L58uWIi4sDAHTr1g3du3eHm5ubzQN0lGKeuYlK7J0kXHuUijIBXg6OiBBCCHn9SE5U9u/fj7p166Jfv36C7RqNBvv370fDhg1tFpwjFfVQc/+etiUOP/es5cBoCCGEkNeT5D4qTZo0QWJiotH25ORkNGnSxCZBOYOiL2pUACAtS+PASAghhJDXl+REhTHGDd3le/r0KTw8PGwSlDPwcnXh/l0+kJp9CCGEEEewuulHv4KyTCZDr169oFbnNY1otVqcPXsWdevWlfTm48aNw/jx4wXbypcvz/V9cbTPWpbDd9uvIFurc3QohBBCyGvJ6kRFv4IyYwxeXl6CjrMqlQp16tQx6rdijYoVK2Lnzp15ASnzvfyQzamVCgDA8xxKVAghhBBHsDor0K+gHB4ejs8++8xmzTxKpRJBQUE22ZetqV1yW8ayNFoHR0IIIYS8niT3URk7dqxN+6JcvXoVxYsXR+nSpdG9e3fcvn3bZvsuKLXyRaJCNSqEEEKIQzi0naV27dr49ddfUb58eSQkJGD8+PFo0KABzp8/Dy8v4w6sWVlZyMrK4h6npKTYNT5Xl9ymnywNJSqEEEKIIzg0UWnTpg3378qVK6N27doICwvDqlWr0LdvX6PyU6dONep8a09cjQo1/RBCCCEOIbnpx558fX1Rrlw5XLt2TfT5UaNGITk5mfvvzp07do2HOtMSQgghjiUpUcnJyUGzZs1w9epVuwSTlpaG69evIzg4WPR5tVoNb29vwX/2RDUqhBBCiGNJSlRcXFxw9uxZm735Z599hn379uHmzZv477//8NZbb0GhUKBbt242e4+CyBv1QzUqhBBCiCNIbvr54IMPsGTJEpu8+d27d9GtWzeUL18eXbt2RdGiRXHkyBH4+/vbZP8FpW/6oVE/hBBCiGNI7kyr0Wjwyy+/YOfOnahRo4bRUOVZs2ZZva8VK1ZIfftC5UrzqBBCCCEOJTlROX/+PKpXrw4AuHLliuA5sTWAXmZKeW6ikk1NP4QQQohDSE5U9uzZY484nJJCnpt4aRlzcCSEEELI6ynfw5OvXbuGbdu2ITMzE0DuGkCvGvmLREVHFSqEEEKIQ0hOVJ4+fYpmzZqhXLlyaNu2LRISEgAAffv2xYgRI2weoCMpqUaFEEIIcSjJicqwYcPg4uKC27dvw93dndv+7rvvYuvWrTYNztHkL/rcaHWUqBBCCCGOILmPyvbt27Ft2zaEhIQItpctWxa3bt2yWWDOQN9HBQB0OsY1BRFCCCGkcEiuUUlPTxfUpOglJiZCrVbbJChnoeCNYqLmH0IIIaTwSU5UGjRogN9//517LJPJoNPpMGPGDDRp0sSmwTmanHd0qPmHEEIIKXySm35mzJiBZs2a4cSJE8jOzsYXX3yBCxcuIDExEYcOHbJHjA4jaPqhGhVCCCGk0EmuUYmOjsaVK1dQv359dOzYEenp6Xj77bdx+vRpRERE2CNGh5Hzm36oRoUQQggpdJJrVADAx8cHX3/9ta1jcTrCzrQODIQQQgh5TeUrUXn27BmWLFmCS5cuAQCioqLQu3dv+Pn52TQ4R6POtIQQQohjSW762b9/P8LDw/HDDz/g2bNnePbsGX744QeUKlUK+/fvt0eMDsMfjkxNP4QQQkjhk1yjMmDAALz77rtYuHAhFAoFAECr1eLTTz/FgAEDcO7cOZsH6UgKuQxaHaNEhRBCCHEAyTUq165dw4gRI7gkBQAUCgWGDx+Oa9eu2TQ4Z6Bv/qGmH0IIIaTwSU5UqlevzvVN4bt06RKqVKlik6CciX4uFR3VqBBCCCGFTnLTz+DBgzFkyBBcu3YNderUAQAcOXIE8+fPx7Rp03D27FmubOXKlW0XqYMoaL0fQgghxGEkJyrdunUDAHzxxReiz8lkMjDGIJPJoNVqCx6hg8lpBWVCCCHEYSQnKvHx8faIw2np51Khph9CCCGk8ElOVMLCwuwRh9OizrSEEEKI40juTPu60deoUB8VQgghpPBRomJBXtOPgwMhhBBCXkOUqFggp6YfQgghxGEoUbGAmn4IIYQQx5GcqPTs2fOVW9PHHK7ph2pUCCGEkEInOVFJTk5G8+bNUbZsWUyZMgX37t2zR1xOQ78uoUZLiQohhBBS2CQnKuvXr8e9e/fwySefYOXKlQgPD0ebNm2wevVq5OTk2CNGh6IaFUIIIcRx8tVHxd/fH8OHD8eZM2dw9OhRlClTBh9++CGKFy+OYcOG4erVq7aO02HkNIU+IYQQ4jAF6kybkJCAHTt2YMeOHVAoFGjbti3OnTuHqKgozJ4921YxOpSCptAnhBBCHEZyopKTk4M1a9bgzTffRFhYGP7++28MHToU9+/fx2+//YadO3di1apVmDBhgj3iLXQ0hT4hhBDiOJKn0A8ODoZOp0O3bt1w7NgxVK1a1ahMkyZN4Ovra4PwHE/f9BP/JN3BkRBCCCGvH8mJyuzZs9GlSxe4urqaLOPr6/vKLF4YeycJADDp30v4qEFpxwZDCCGEvGYkJyoffvgh9+87d+4AAEJDQ20XESGEEELIC5L7qGg0GowePRo+Pj4IDw9HeHg4fHx88M0337ySw5MJIYQQ4jiSa1QGDRqEtWvXYsaMGYiJiQEAHD58GOPGjcPTp0+xcOFCmwdJCCGEkNeT5ETlzz//xIoVK9CmTRtuW+XKlREaGopu3bpRokIIIYQQm5Hc9KNWqxEeHm60vVSpUlCpVLaIiRBCCCEEQD4SlYEDB2LixInIysritmVlZWHy5MkYOHCgTYNzBuPaRwEAPFQKB0dCCCGEvH4kN/2cPn0au3btQkhICKpUqQIAOHPmDLKzs9GsWTO8/fbbXNm1a9faLlIHqVXKDwDgoZZ8qAghhBBSQJLvvr6+vujcubNg26s8PJkWJSSEEEIcR3KisnTpUnvE4bT0M9PSDPqEEEJI4ct3e8bjx49x+fJlAED58uXh7+9vs6CcCa2eTAghhDiO5M606enp6NOnD4KDg9GwYUM0bNgQxYsXR9++fZGRkWGPGB2KFiUkhBBCHEdyojJ8+HDs27cPGzduRFJSEpKSkrBhwwbs27cPI0aMsEeMDqXQ16hQHxVCCCGk0Elu+lmzZg1Wr16Nxo0bc9vatm0LNzc3dO3a9ZWb8E3+IpWjph9CCCGk8EmuUcnIyEBgYKDR9oCAgFe76YdqVAghhJBCJzlRiYmJwdixY/H8+XNuW2ZmJsaPH8+t/fMqUdCoH0IIIcRhJDf9zJkzB61btzaa8M3V1RXbtm2zeYCOJqNRP4QQQojDSE5UKlWqhKtXr2L58uWIi4sDAHTr1g3du3eHm5ubzQN0NH3TD5A78kfOe0wIIYQQ+5KUqOTk5KBChQrYtGkT+vXrZ6+YnIq+6QfIHfkjByUqhBBCSGGR1EfFxcVF0DfldSDnHSFq/iGEEEIKl+TOtAMGDMD06dOh0WjsEY/T4Tf9UKJCCCGEFC7JfVSOHz+OXbt2Yfv27ahUqRI8PDwEz78KKybzyXlNP4P+Oo1fetVyYDSEEELI68Umqye/yvg1KrvjHjkwEkIIIeT1Q6snW8CvUSGEEEJI4ZLcR6Vp06ZISkoy2p6SkoKmTZvaIianQqORCSGEEMeRnKjs3bsX2dnZRtufP3+OAwcO2CQoZyKjGhVCCCHEYaxu+jl79iz374sXL+LBgwfcY61Wi61bt6JEiRK2jY4QQgghrzWrE5WqVatCJpNBJpOJNvG4ublh7ty5Ng2OEEIIIa83qxOV+Ph4MMZQunRpHDt2DP7+/txzKpUKAQEBUCgUdgmSEEIIIa8nqxOVsLAwAIBOp7NbMIQQQgghfJKHJwPA1atXsWfPHjx69MgocRkzZky+Apk2bRpGjRqFIUOGYM6cOfnaByGEEEJeLZITlcWLF+OTTz5BsWLFEBQUJBgVI5PJ8pWoHD9+HIsWLULlypUlv5YQQgghry7JicqkSZMwefJkjBw50iYBpKWloXv37li8eDEmTZpkk30SQggh5NUgeR6VZ8+eoUuXLjYLYMCAAWjXrh2aN29usWxWVhZSUlIE/xU2jZb66BBCCCGFRXKi0qVLF2zfvt0mb75ixQqcOnUKU6dOtar81KlT4ePjw/0XGhpqkzikyKZEhRBCCCk0kpt+ypQpg9GjR+PIkSOoVKkSXFxcBM8PHjzYqv3cuXMHQ4YMwY4dO+Dq6mrVa0aNGoXhw4dzj1NSUgo9WcnRMEBVqG9JCCGEvLZkjDEm5QWlSpUyvTOZDDdu3LBqP+vXr8dbb70lmHtFq9VCJpNBLpcjKyvL4rwsKSkp8PHxQXJyMry9va37APkQ/uW/3L+Pfd0MAV7WJVaEEEIIMSbl/i25RiU+Pj7fgfE1a9YM586dE2zr3bs3KlSogJEjRzrt5HHZGmr6IYQQQgpLvuZRAYDs7GzEx8cjIiICSqX03Xh5eSE6OlqwzcPDA0WLFjXa7kwoUSGEEEIKj+TOtBkZGejbty/c3d1RsWJF3L59GwAwaNAgTJs2zeYBOhvqTEsIIYQUHsmJyqhRo3DmzBns3btX0Am2efPmWLlyZYGC2bt3r1POSlshyIv7N9WoEEIIIYVHcqKyfv16zJs3D/Xr1xfMSluxYkVcv37dpsE5iw0D60GtzD1UOVSjQgghhBQayYnK48ePERAQYLQ9PT1dkLi8StRKBUr6uQMAsqhGhRBCCCk0khOVmjVr4t9/84br6pOTn3/+GTExMbaLzMmoXtSoUNMPIYQQUngkD9eZMmUK2rRpg4sXL0Kj0eD777/HxYsX8d9//2Hfvn32iNEpUKJCCCGEFD7JNSr169dHbGwsNBoNKlWqhO3btyMgIACHDx9GjRo17BGjU3BRvEhUqI8KIYQQUmjyNY9KREQEFi9ebOtYnJq+M+2ZO0l4s3JxB0dDCCGEvB4k16jwtWvXDgkJCbaKxanpO9EuPhBPKygTQgghhaRAicr+/fuRmZlpq1icWmJ6NvfvHK2k5ZEIIYQQkk8FSlReJ/xalKoTtiP+SboDoyGEEEJeDwVKVMLCwuDi4mKrWJwavxYlS6PDd9svOzAaQggh5PWQ70UJAeD8+fO2isPpGc5IK39FJ7cjhBBCnInkGpWtW7fi4MGD3OP58+ejatWqeP/99/Hs2TObBudMDIcluygoUSGEEELsTXKi8vnnnyMlJQUAcO7cOYwYMQJt27ZFfHw8hg8fbvMAncXzHK3gsUpB3XsIIYQQe5Pc9BMfH4+oqCgAwJo1a/Dmm29iypQpOHXqFNq2bWvzAJ1FkLcrbj7N4B4rqUaFEEIIsTvJ1QIqlQoZGbk37J07d6Jly5YAAD8/P66m5VX044fCWXddqEaFEEIIsTvJNSr169fH8OHDUa9ePRw7dgwrV64EAFy5cgUhISE2D9BZVAjyhlIug0aXO/qHmn4IIYQQ+5N8t503bx6USiVWr16NhQsXokSJEgCALVu2oHXr1jYP0JnokxQAkMup6YcQQgixN8k1KiVLlsSmTZuMts+ePdsmAb0saBp9QgghxP4k16icOnUK586d4x5v2LABnTp1wldffYXs7Gwzr3y10DT6hBBCiP1JTlT+97//4cqVKwCAGzdu4L333oO7uzv+/vtvfPHFFzYP0FnpFykkhBBCiP1ITlSuXLmCqlWrAgD+/vtvNGzYEH/++Sd+/fVXrFmzxtbxOS3DmWoJIYQQYnuSExXGGHS63Jv0zp07ublTQkND8eTJE9tG58QoUSGEEELsT3KiUrNmTUyaNAnLli3Dvn370K5dOwC5E8EFBgbaPEBnRYkKIYQQYn+SE5U5c+bg1KlTGDhwIL7++muUKVMGALB69WrUrVvX5gE6q7QsLQ5de4IsjdZyYUIIIYTki4wxZpPhK8+fP4dCoYCLi4stdmeVlJQU+Pj4IDk5Gd7e3nZ/v/Av/zXa9m7NUEx/p7Ld35sQQgh5VUi5f0ueR0Xv5MmTuHTpEgAgKioK1atXz++uXmorT9yhRIUQQgixE8mJyqNHj/Duu+9i37598PX1BQAkJSWhSZMmWLFiBfz9/W0dIyGEEEJeU5L7qAwaNAhpaWm4cOECEhMTkZiYiPPnzyMlJQWDBw+2R4yEEEIIeU1JrlHZunUrdu7cicjISG5bVFQU5s+fz62kTAghhBBiC5JrVHQ6nWiHWRcXF25+FUIIIYQQW5CcqDRt2hRDhgzB/fv3uW337t3DsGHD0KxZM5sG97JIz9I4OgRCCCHklSQ5UZk3bx5SUlIQHh6OiIgIREREoFSpUkhJScHcuXPtEaPTm7rlkqNDIIQQQl5JkvuohIaG4tSpU9i5cyfi4uIAAJGRkWjevLnNg3tZHL7+1NEhEEIIIa8kSYlKTk4O3NzcEBsbixYtWqBFixb2iuulIpPJHB0CIYQQ8kqS1PTj4uKCkiVLQqulaeP55JSnEEIIIXYhuY/K119/ja+++gqJiYn2iOelJKcaFUIIIcQuJPdRmTdvHq5du4bixYsjLCwMHh4egudPnTpls+BeFpSoEEIIIfYhOVHp1KmTHcJ4ObStFITN5x4YbZdLrpcihBBCiDVstnqyIxT26slZGi1ibyfh3Z+OCLZXDvHBPwPr2/39CSGEkFeBlPu35LqA48eP4+jRo0bbjx49ihMnTkjd3UtFrVSgVrif0XYa9UMIIYTYh+REZcCAAbhz547R9nv37mHAgAE2CcqZyUWG+NCoH0IIIcQ+JCcqFy9eRPXq1Y22V6tWDRcvXrRJUC8b6kxLCCGE2IfkREWtVuPhw4dG2xMSEqBUSu6b+0qgGhVCCCHEPiQnKi1btsSoUaOQnJzMbUtKSsJXX3312s5US31UCCGEEPuQnKh89913uHPnDsLCwtCkSRM0adIEpUqVwoMHDzBz5kx7xOj0jsUnYt7uq44OgxBCCHnlSE5USpQogbNnz2LGjBmIiopCjRo18P333+PcuXMIDQ21R4wvhe+2X3F0CIQQQsgrJ1+dSjw8PPDxxx/bOpaXxp8f1cbKE3ewIfa+o0MhhBBCXmmvZ+/XAqpbphiKeKiMEhXGGPVXIYQQQmyIJn/PJ7H5fNOyNIUfCCGEEPIKo0Qln3QimcqTtGwHREIIIYS8uihRsaFbT9MdHQIhhBDySslXopKUlISff/4Zo0aNQmJiIgDg1KlTuHfvnk2Dc2aB3q5G2+IepDogEkIIIeTVJTlROXv2LMqVK4fp06fju+++Q1JSEgBg7dq1GDVqlK3jc1r+Xmq8V0s4HDsuIcVB0RBCCCGvJsmJyvDhw9GrVy9cvXoVrq55tQpt27bF/v37bRqcs4uJKCp4zK9R2Xr+AbZfeFDYIRFCCCGvFMnDk48fP45FixYZbS9RogQePHi9bswKg0V+rj1KQ7ZGh8wcLfr/cRIAEDexNVxdFI4IjxBCCHnp5WtRwpQU4yaOK1euwN/f3yZBvSwUBnOmaHQMSRnZSMnM4bZlaXSFHRYhhBDyypCcqHTo0AETJkxATk7uzVgmk+H27dsYOXIkOnfubPMAnZlhjQoA1J22G9cep3GPsylRIYQQQvJNcqIyc+ZMpKWlISAgAJmZmWjUqBHKlCkDLy8vTJ482R4xOi2lwjhR0egYBi4/xT3O1lKiQgghhOSX5D4qPj4+2LFjBw4ePIizZ88iLS0N1atXR/Pmze0Rn1PjT5dfxN0FzzJya5nSs7XcdqpRIYQQQvIv32v91K9fH/Xr17dlLC+drJy8JCTQ25VLVPgoUSGEEELyT3Ki8sMPP4hul8lkcHV1RZkyZdCwYUMoFK/+SJcsTV7NSTFPNQDjCd/4ZQghhBAijeREZfbs2Xj8+DEyMjJQpEgRAMCzZ8/g7u4OT09PPHr0CKVLl8aePXsQGhpqdl8LFy7EwoULcfPmTQBAxYoVMWbMGLRp00b6J3GA5zl5SYiHWjwxM6xRSXmeg+SMHIT6uds1NkIIIeRVILkz7ZQpU1CrVi1cvXoVT58+xdOnT3HlyhXUrl0b33//PW7fvo2goCAMGzbM4r5CQkIwbdo0nDx5EidOnEDTpk3RsWNHXLhwIV8fprBpdHkLE3qoxXM+w0Sl7tTdaDBjD+4kZtg1NkIIIeRVILlG5ZtvvsGaNWsQERHBbStTpgy+++47dO7cGTdu3MCMGTOsGqrcvn17wePJkydj4cKFOHLkCCpWrCg1tELXoUpxLNp3A43Lm54/5mHqc2h1jBvKnJalAQCcvPWMalUIIYQQCyQnKgkJCdBoNEbbNRoNNzNt8eLFkZoqbYE+rVaLv//+G+np6YiJiREtk5WVhaysLO6x2MRzhcnL1QX7Pm8MmUyGSZsuipYZtvIMdsc9xtxu1QT9Vbxc892PmRBCCHltSG76adKkCf73v//h9OnT3LbTp0/jk08+QdOmTQEA586dQ6lSpaza37lz5+Dp6Qm1Wo3+/ftj3bp1iIqKEi07depU+Pj4cP9Z6gNTGPRDlF2Upg/lxjP3AQBJvFFBbjStPiGEEGKR5ERlyZIl8PPzQ40aNaBWq6FWq1GzZk34+flhyZIlAABPT0/MnDnTqv2VL18esbGxOHr0KD755BP07NkTFy+K106MGjUKycnJ3H937tyRGr7duCgsH8q1p+5x/+b3byGEEEKIOMntD0FBQdixYwfi4uJw5coVALnJRvny5bkyTZo0sXp/KpUKZcqUAQDUqFEDx48fx/fffy+68KE+MXJGKpFZavl0OobpW+O4x+fuJaN+mWKQi0zDTwghhJBc+e4oUaFCBVSoUMGWsQAAdDqdoB/Ky8JSjUrKc+FkcN9uu4ysHC2Gtyxv4hWEEEIIyVeicvfuXfzzzz+4ffs2srOzBc/NmjXL6v2MGjUKbdq0QcmSJZGamoo///wTe/fuxbZt2/ITlkNZSlSeZeQgpIgb7j7L5Lb9sPsaJSqEEEKIGZITlV27dqFDhw4oXbo04uLiEB0djZs3b4IxhurVq0va16NHj9CjRw8kJCTAx8cHlStXxrZt29CiRQupYTmcuc60AJCYno3nOdKm07+XlIkHyZmoEeZXkNAIIYSQl5bkRGXUqFH47LPPMH78eHh5eWHNmjUICAhA9+7d0bp1a0n70ne+fRWoeTUqez9rjI1n7mPmjivctiUHb+BJmvkmrcsPUhH3IAUdqhSHTCZDvWm7AQD/Dq6PisV97BM4IYQQ4sQkj/q5dOkSevToAQBQKpXIzMyEp6cnJkyYgOnTp9s8wJeFi1LG+7ccvu4uguc3n3tgcR+t5uzHkBWx2B33SLD91O0km8RICCGEvGwkJyoeHh5cv5Tg4GBcv36de+7Jkye2i+wlw++j4iKXQa20PE+KzMSAn/+uP7VVWIQQQshLTXLTT506dXDw4EFERkaibdu2GDFiBM6dO4e1a9eiTp069ojxpaDkDTNWyGUIL+Zh8TVyE5lKcmaO6HZCCCHkdSM5UZk1axbS0tIAAOPHj0daWhpWrlyJsmXLShrx86qR8ZIOpUKON0r54Zt2kfjlYDzuJz8XfY2pKVT4M9gSQgghrzNJiYpWq8Xdu3dRuXJlALnNQD/++KNdAnvZ8GtHXF5M/vZRg9J4nJqFRftvWHwNY3kz1RrOuVLQKeGepmVhzD8X0K1WSdQvW6yAeyOEEEIKj6Q+KgqFAi1btsSzZ8/sFc9Li59MKHhVJZ5q07kgv1yWJm/osgzCxKWgJm66iH/PJuCDJUdttk9CCCGkMEhu+omOjsaNGzesXnTwdSHnpXwuvAeeZlZJzsjW4q0Fh1AhyBvhRd257Qq5DDla2yUqtxMzuH/H3klC1VBfm+2bEEIIsSfJo34mTZqEzz77DJs2bUJCQgJSUlIE/72u+H1U5FbWqADA6dtJ+OvYbUzdkrcOkEbHkKPl1bAUsO2Hn/J0mn8IGq20iefs5XmOljoOE0IIMUtyotK2bVucOXMGHTp0QEhICIoUKYIiRYrA19cXRYoUsUeMLwVTI3i8zNSomJKt0UFjwxoVw1akbAckKk/TsvDx7yew69JDblvM1F2oMn67UZ8cR7n7LAPv/XRYEOPr7ll6tuVChBBiR5Lvonv27LFHHC89FxOrJ3uqXUS3m3M7MQMJKXlrAtmwuwoAIEfDAJVt92nJtC1x2H7xIbZffIib09oByF3/CAAu3U9B7dJFCzcgEaPWnsORG4k4ciORi/F1NmfnFczZeRXfvlMZXWqGOjocQshrSnKi0qhRI3vE8dKrXaoo6kYURYS/p2C7uT4qpiSmZ6P1nAPcY63OtplKllYLQHoCZa07iRnYePY+PqwTBi/X3Pd5kCIcos1v2lKaSPIK26OUl2/Vbnuas/MqAODr9efRpWYoxv1zAe4qBb5obftV0wkhxBTJTT8AcODAAXzwwQeoW7cu7t27BwBYtmwZDh48aNPgXiYKuQx/9quDiZ2iBdst9VGxRo6ZphqdjuHW03SJ+7NxFY2BHr8cw4ytl/HN+vMmyzzP0XL/VsrzdRraHIN9j8vLSobcBTJ//e8mFuy9jmyNbZsO5+66igV7r9l0n4SQV4fkO8SaNWvQqlUruLm54dSpU8jKyv0VmpycjClTptg8wJedYaLioVKgd71wSfswl1iMWnsOjb7di+VHb5ksY/hqW9xo0rM0Jp+Lf5KbOG2Ivc9tkxn04eGvJK0wNfMdcQpymQw5vHNGo7NdovI0LQszd1zBjK2XzZ5ThJDXV75G/fz4449YvHgxXFzymg/q1auHU6dO2TS4V4Fh04+bSol3aoRI2oe5UTorT9wBAMzmrdRsiVgNzYX7yfjkj5O4/jjN4uuXHbmFimO3Yc3Ju1a/pyF+jYrGxk1b+WXrvkCvCrlM2Fk8R2O7A8Xv2O0s5wEhxLlITlQuX76Mhg0bGm338fFBUlKSLWJ6pbi7CBcnVMiFCxhaI8eKCzhjwJWHqRiw/BSuPkw1fpJHrEal88L/sOX8A7Ses190//uvPMbJW4kAgNEvmnRG/H1GtKyHyvKCjPxERWvDX+gFQbdJcXKZTNAsZstRYzKIz85srZtP0nEvKdNyQULIS0tyohIUFIRr14zbkw8ePIjSpUvbJKhXiVwuQ7c38kZMKOVyyYmKNfOe6BhD10WH8e854Qy0yZk5gmYWQDgLrlbHsO70Xa5MjpZh24UH3PPxT9IRM3UXevxyDJ0XHraqY6+fp+UhRZm8RMXefWbEnLubjEmbLtp0HpfHqVk2nVG4sKw7fRfvLz5iciiyTCb8G9k0UeG1+kntNJ7yPAeNv9uLetN2v5THnRBiHcmJSr9+/TBkyBAcPXoUMpkM9+/fx/Lly/HZZ5/hk08+sUeML72pb1dGlRAfAEDn6iWgVoof9pldqohu11eJ8y/G/11/gh92XeUeM+QtZvjwxeiVp2lZqDJ+Oy4b1LDkaHVc7cvETRcxbKWwZuTnA3lrEw1bGYsE3qKKzzIsz6vhxRuSbermw0+ebD2qyRrt5x3EzwfjBU1mUm92Wh1DliY34dp09j5qTd6Jsf9csGmchWHYyjP47/pTzN4p3nwol8sE/VJybNiZVsc75lLPgwe885JajQh5dUkekvLll19Cp9OhWbNmyMjIQMOGDaFWq/HZZ59h0KBB9ojxlfB7n9o4Gv8UjcsH4LlGK1rG2018yHCOVodrj9LQddFh/K9habStFIz3FwvX7RG7x26/KD5xWbZGh/d+OoJEE7+gFXIZJmy8CDeVHJcfCJOcx6mWh/B6qPOaflIyc1DEQ2W0sCK/6eeL1Wex7tO6CPB2xb4rj7HkYDymvl0JJXzdLL5XQfGXF5B6r+sw7yBuPc3A8a+bY9qLmYV/P3wLEzpGm3zN8xwtpmy+hJZRQU63QOQzE6t2y2UywQSE5kahScVPTgrSR0WrYwXqlH0sPhFaHUNMhOPn8yGECEmuUZHJZPj666+RmJiI8+fP48iRI3j8+DEmTpxoj/heGT7uLmhZMQgqpRweKvH80NvEnCsaLUPzWfuQmJ6NqVvi0GzWPqMyOpFM5dC1J6L7y9HqTCYpQO56QL8cisf8PdcFTTQA8MiKRIXf7yDJRNMKf7/3kjIxau05AEDPX45h/5XH+HLNWaPXZGt06P7zEcwy6DjMGMOD5OeiNSJP0rIwcvVZnL4tvpBmEff8z3x34X4K0rI0OHM3yerXLDkYj98P33LKBSJN1SjJZcIkIsuWNSq8XRVkNmax899aWRotui46jG6LjyCNRh6RV9Svh+KxugADIBxJcqLyxx9/ICMjAyqVClFRUXjjjTfg6elp+YWEY+qXn6kalWPxiYLHosOLDa7TWh3DprMJ3OMgb1fzr+cx7NPC99Bg4jYx/GaCpBdNRYYrDDw3SIAu3BeuE8Wv6dDbcj4Bh649FTR5AcDfJ++iztRdWLD3utFrxv1zAStP3MFbC/7jtul4N90i7rnHnDGGG4+lzUfDZ+16TLefGn8uW0vP0qDl7H2YsPGipNeZvtfLBP2kbFqjwvg1KtL2yz/kBamN4Z/vqU6ynIM9pGVp8NW6c/jvuvgPGPLquvssA+M2XsRnf595KftzSU5Uhg0bhoCAALz//vvYvHkztFrxZgwinanJ4Qz7mIgx/EWZZdC8VMRDhbovqrUL0hnyi9XGNR2G+NX5SSaaEwwTFcMbvVg/iIxs8XNNH9O32y4bPXddJPngd6At4pFbo8LvQGwNncGNUWbUuCXOUkLDGMPF+ylGx0eKtafu4srDNPxyKF7S60zVSsgNOtPasvMz/1z58+htk0mQVsfwNM10bV5B+jnxk7CX8Bpute93XsGfR28bNRuTVx//mvcy9ueSnKgkJCRgxYoVkMlk6Nq1K4KDgzFgwAD8999/ll9MzDLVydYahief2M1EP9po/el7+X4fa/B/3aaaqErPNojPcFFHw+cN9ytGJXL8VCLT8/Nrb/Tve/KWeNOQKfxYZLC+RsVw4jtD/5y5j7Y/HECvpcckxcNn2FxnLVM3ablM2JnWljPT8pOjnw/G49dDN0XLdVt8BDUm7UTcg7y/XUFGDPEJ5nIxOO8u3E/Ghlj7fV+OxSfirISmw4IQq6UkzuH8vWSraqvzi//ddsTghYKSfGdUKpV48803sXz5cjx69AizZ8/GzZs30aRJE0RERNgjxtdGQToDGt6cDIc0ywDsv/oYALDn8uN8v481+F+EzGzxRMUoPhmMmheepmVh+dFbXHW81kJNUHGfvOat9CwNnudooRQZCn6IV/Wtn8PFzcXy3C+C+PM59wv/5ipWBbv8yG0AwJEbiUbPWSu/NR6mlhCQy1AonWkB4ICJflX65s/VJ/La2HU2uvjyE69sgxridj8cxJAVsTh8/Wm+929KYno2ui46jA7zDtm8Ov7c3WRcShA2p9IM0LbxPEeLR6m2SyquP07Dm3MPovaUXTbbpyH+D4KC9OdylAItsuLu7o5WrVqhTZs2KFu2LG7evGmjsF5Pfh62W9LYsPZBLi+8am3+jSwzWwudjmEvLznS6pjRL1e5TIbOPx7mHmdrdOj963F8ve48vl6XO8Gctf0QNFodmny3F7Um7wT/2rzs8E2cuJmIVcfv5JV9sU+1SKLCGMPVh6mi89gYJgPW3gL45WpM2om/jt0WPG9q2aMfdl3FH0dML5PAl9/OrqbOjwcpz7HvSt7fz5bzqBgmGNZM/ncnMQPJGTmCc6ggiQr/fDV17NaeuovR68+bbX6y5OL9FPy0/zp3k+Pf7Gx5TJMzc9B+3kG0+f6AoInSeBkLLRbvv4EbVsxG7SjJmTmYuf0yrj3KjTEhOROf/30GF+4nC8qlZ2kw+K/T2HpeWhNufjSbuQ9vTN6FOzaqoTp9O8km+zHHVkm9o+QrUcnIyMDy5cvRtm1blChRAnPmzMFbb72FCxdevjkkHCWmtHAY5I8fVLfYLGCt3Am6DGtUCu/XFP+LkJGjxb/nEgTP52h1yDG4IekYw5k7SYIyZ+/mXoz0Fx+xRIW/Poz+2aTMHDxKzULqcw2O38xr0hm94QLe+fEwnvJGPOkv5GI1Kn8cvY0Ws/fjM5EZeA2/7Nb+7fjFEtOzMWrtOWw6m7cmkmETGJB7cZ614wq+WX8emSb66egxxpCVz6YfU9cvHQN+/e8m99iWTT+GxzFHy8zW2DxIeY4GM/ag2sTtwjlYCjTqx3Kz1t8n72LZkVuY9O8lq/aZYtAp98iNp2j7wwFM2RyHoStiAQi/k7YcScW/gfLnxlEYnFvz91zD5M2X0HSm8ShCRzGsWRr3zwXM3X0NrV7MmD1kRSz+PnkX7X4QLoD7477r+OfMffT/46TdY9TPhLz38iO7v5et6ASd1l+DROW9995DQEAAhg0bhtKlS2Pv3r24du0aJk6ciAoVaPl3ay3uWRN/flTbLvs2nPdC78cPatj8vQwvLP9de4KbvJEtmdlaJCQLpzjP0eqM4jO8OfG/TEqFDFodw3He6KcPfj6KVSfuoOLYbdw2/ZdRyjBX/fu4iiQq83bnji5az1tckTGG208zBPGa+t5fe5SKKwYdocUSEf6kc2LV81m8USmW1mL6YMlRLNqfN2GftCYF68ryP3u2Rof5e64ZNTNYyzDBOBafiHrTdpvsTKwfCq5jwiTHsHOzFNkmEhXDDumA5eMPADO2xqHyuO3YE5d3I1t+NK/m7L8XzUj8m0dBOk8bSn2el7zP3Z03i7jhuXXKxJB9ezlzJwnDV8YKJurjW7z/BqpN3CH4zpx4sWyH/m996b74eXb3WeEvo/Ay3fD514GCfFccRXKiolAosGrVKiQkJGDevHmIiYnhnjt//rxNg3uVeaqVBpNLGd+g+jUohVA/6ZOeaXUM8U+Fo11kMqB1dBD8vdSS92fOlYdpOHz9Kd5ffARXH6bi/Z+FIwoys7VQK4VJgEbLjJpTzA2JVspl+P3wTeziXfgPXntiNAJJ/10Uu8GYor9RKg063ep0TDQB+XHfDTT8dg+WHMwbUZOj1XErRutlabRoPms/Ws7eL7gJidW78N9GLJHhNwvoq8DF6HQMh64J+1Lwb+a3n2ZgwJ+ncO5usuFLc+Ow8vrFT1R+2HUV3267jDbfH0CDGbux7PBNzN9zDcNXxppNkrI1ucfslEgn5kepWTh/TzxGFa/PEb+fkDU3jWyNDufuJhtdqE0tD5CeZXwenb2bjKmbL5n9bPph8r1/Pc6dixH+HqLx6GWZOf+lMjUXjOGppTKxlIdOxzB1yyWbN6N0nH8Ia0/fwxcicyQBwOTNl5CUkYOxG/Jq5q09J23RdJaYno3lR28Z1YaZ8jI1ofAPT0FqHx1FcqKib/JRKHJvPqmpqfjpp5/wxhtvoEoV8SngiTix5oKfPqwBtVKOH7pVw9ftouDtKj63iiW9lx4XvteL//uamKvFHA+VAv8Ori/6XKs5+9Ft8RH8d/0pvllvnKhm5GiNRjPl6HRGCy2aW3PHRSHHon03TD6vl5eoWH/R0r64SRndvHQ60ZvR9K25M9D+xKu1WHPKeBKllMy8m0W6pUnEeG9j+Ks3OTNH8Kv4qZmJ+tJFOi7zb+D/++Mk/j2bgPbzDhqVMwjDLP4NditvWPedxEyM3nAB3267jLWn72GHiZmRAWDAn6fQ5Lu9JptStDqGhynPjUbE8NfJ4h9ja24aw1bGov28g/jpgPBcMlWjkvZc/O+2aP8N7LvyGBqtDv+eTRD0NVl2+Kag7G8vmsz4TYvVSvoCEJ6n5pLr5Udv4aPfjovWuoido2lZ4t8lw6Yfwx8QepvOJWDRvhvo/8dJSUm/ta6bSbYBYdJh+PFM/ZVtsazDF6vP4ut15zF8ZaxV5e2RqNhrjhN+Uv9a1Kjo7d+/Hz179kRwcDC+++47NG3aFEeOHLFlbK+llhWDcGF8K3SoUhyAeJNEvry4SPnkI1FJzzZONsSIJRuZ2VqjRRjFalTMUSpkqPRirSRz9F/yhSITv5miv5Eb/iLXaMVrVIJ5I4v0+FX8etkmmobEhl2bqlG5/CAVVcZvx8YzeU1P5o6b2C9pfhyXH5hvnrF2NAD/M9x9ZrpD4cfLTuLkrUTRi6+5JAbI/dVXe8oudJh3CN9uixMtwz/frLlp6PtKTdsSJ2jC4Y/04ScqqSZu+ADwNC0bv/53EwP+PIU3Ju/iYhm9QdhPb/6e60jOzBEkJS4KOSZtuoiui/I6jz/P0eFJWpZos8jX685j56VHGLoiFuW+3sJN5LfsyC3UnLTTqPbJ1NxFhkmw2HB+AILOtY2/3WvzSfAsjT4yd47zz6VPl5/E2hc/EmxRo7Lz0sMX/7eu74k9mn7ERuwdi0/EtUeW59Kydr/malQYYzh/L9kuCWpBSEpUHjx4gGnTpqFs2bLo0qULvL29kZWVhfXr12PatGmoVauWveJ8rfCH1Lq6FGhgFkd/aXA3MamcJQpTw1F4iouszZOZrTW6iWi0TNIQ2ocpWUZ9PcTo97hOwjwx+puzYYxZGp3ojdtXZMp9w2JaHRN0aLQ0Bwn/4su/hv+4zzjhMtfRVKzmht9fx9J1lf85zP2y48dgrskOADovPIwtvCaEcf9cQLsfDpgPxCCW+XvyjgP/vflV9FJ/3erXZgIMhyebb/rh09/YAGDgn6dEyyRn5hjVhjzP0eJnXtMhkDu9QM1JO1Fn6i6THaa3XniAbK2Om8hv9PrzeJqebVSTaap20rAG11Siwj+PEpKfF2jGZjGWEhVrrw2bzz3A8FVnXrym4ImKqSVMTLFHzcRP+69ztbZAbsforosOo/ms/aLlM7O1OHrjqcVY+Mmfue/K6pN38ebcgxj452mJkduX1XfB9u3bo3z58jh79izmzJmD+/fvY+7cufaM7bVQvaQvVEo56pYRXwzNVPWsoRZRgWaf11+jXPM5qZxhtbEYd5VxrBk5WmQZXESytTrJ85DcsmLq+fzUmup/FRl+eZvN3Gv05X+SliXaadQwoen963G891Ne7WKORrwPRN7r8/597GZeh2GxUQViNTJ6qSJNFVIu4NaODJA66ufvE7nDwVOf5+DX/24aLZcgxtTFlH/8UiTUqIw06M/ETwb4xzRLo8OCvdcwcvVZszUJWRqdYNTOgaump6U/fvOZoEZFLBG5x+sM+iQtCwnJuetfWZOgG/49DJs+9ceGX7Gp0zGTiUqaQYKW3wkEgdwV3A2brCzWqORjjiKx5OZhynN8ueas0VBmMQ9TniOF9/25k5iB4StjcdHMuWqPGpXvtl/Bwr3XuZFFhn3f+Bhj6LroMN796Qg28kYOiuEfH3OHV18bbanGs7BZfdfasmUL+vbti/Hjx6Ndu3ZcHxVSMKv718XZsS1N9kXhf6X7NzI9oV5DCyvx6veT36YkhcgMr4bEftFnZGmMLqRXHqbijyO3jcoWlKkJy8zR91ExvNE9y8gxuuCLDVMGjGsq9l8RTqjHH4otNnRYH/fRG08F1fZiqxmbSzzEmn52vajG3mlw4RFb74Wfb5lLRvgxWDMqW38cT0mYL8JU9TQ/ru+2542WMled/SjlOVaeuCPYlsHrz8Pf57zd1zBj62WsPHEH2y+Yvlh/te4cDt+wfhI4flW62FIQ/BuSVsfQecF/+OvYbbScLf5Lml/jpZDLkJyZg+SMHK7qnk//9+L/2MjW6gSdaflJueF5ZGlIvClP0rJQY9JO1Ju2W7Bd7EcPvwlRo2VIz9Kg7fcHuBu2Jfxz8tbTdPy47zr+t+wkVhy/YzSUWcxIgw6+nyw/ibWn7+HthYcE2/nH3fCakZGtwf+WncDaU3eRlJGNbRce5Hsov/7voeQldU2+2ytYTPZBynOce/G3PmqwHpwhfvJn7rtiaiZxR7O6ruvgwYNYsmQJatSogcjISHz44Yd477337Bmbw6Wnm85mFQoFXF1drSorl8vh5uZmtqz+/DMse+vhM+iyc9utBzYIwYIdeW3gNcP9cOp+7he8Y7USuHb/KZaamIJcm5M7UZW+r4kuJ8tsFYRclffZFnWLRlZmBhdHqJ8b7iRmGpVNy9KAabLBeF+Kp0kpSEn15F4rV7ni0+W51eSGZQ3JXNRcdTXT5IDpTF8wZS5q6FjuF9xyWRVkstzjkJ2TjfT0dKSnp3Mx6mVmC8sev/4IumzjCb9ydHLoNDrIlC6QyXMTQabNAXvR9yE5NRXp7rmfIz0j9334ZbUaDdLT07E19qZRDAAEZbOyskyea0+fpYDptHkx6LT4cuVxRBRRos/PhwVl35u/D9end4BCoeTK3nv8jNv3w+TnglhkCiVkL8o+z87hyik02Ua1RDKFAjKFC7ff9PR0PEtOxdV7T4w+n6As04Hl5H4R0lLTRMvmaFVGZQEgLS0V6em5+5m/+xr+OfcA6wc3RjFPNY7FJxrtKyU1jfsM6Rl55/Ktp+lgL74rf/0nXPwSAGRyOWTKvOY//n4NzyF+2awcHffcs2QNdAYdn6/ez0t6dsU9wt3HSUbvnbdjmSCJ1mRnotLX/wAAJnWKxr4LvM7dvJWv5XIZdDnPAQYkpaRCpsn7Gz9JSoGnqwvc3d25Hxz6a8Sz5FSkpxuPWvLwyNuWmZkJHe+7fOJmIn47nHs+PzY49kybjf/9cghJmdn4uUctaHQMdSduz/s8OndsOnsfFxNSBNeI9PR0aLOfQ8dLnGQuuaMYszU67nvf9rudRjfc9PR0uLu7I1urw7uLjuDsrSdY0a8WKhbP7ft26bbwu33urg4ymRzPc3TIzs5GTk7ujwaNNu/vmJGRjruPnuFBhg41w4ti6aGb2Hr2LracvoUAbxUepWRjYqeKeKdGKLdfV1dX7ke+fr9pacbnempqGrQ+ajx4Ma0+02pw/f5TzNlyFiPbROb+zZ7lve5qQhL32pycHGRnCzvdp/LeIys77weQRqNBVlbe505OSYUuJ+94q1QquLjkb0CHTTGJ0tLS2JIlS1i9evWYi4sLk8vlbM6cOSwlJUXqrgosOTmZAWDJycl22T9yuz2I/te2bVtBWXd3d5NlGzVqJChbrFgxk2Vr1qwpKKv0CTBZtmz5SBY2chMLG7mJZWu0LKJcBZNl3f2CGGOMffH3GRY2chNTBZU1WVbu5s3tN2zkJtawYSOTZWUuakFZt9I1zR43fln38vXMlg0dtpor6xHdzGzZkEHLWY2JO9jzHA3zrNbObNkS/Zdw+63W7kOzZYP7zGdhIzcxxhgLavyB2bJBPWZx+/Vt3Nts2cBuU7iypToMMlvW/52xXNmOgyeZLVus45dc2WIdvzRbdunSpSwrR8vCRm5i/u+MNVvWr0V/br+9Ji81W9a3cW+ubFCPWWbL+tTrxpUN7jPfbFnvN95mFcdsZWEjN7ES/ZeYLetZrR2b/O9Fxhhjs/45ZrZsvTaduRhCh602W9a9fD3BOWyurFvpmly5/stOMJmL2mRZdWg0V7bK+G1M7uZtsqwqqCx7nPqcK+9aJNBkWZeiJVliWhbL0WjZhI0XmEvRkqbP3xKhTKfTsW4/HbZ4jShWrJjgOtWokflrBGOMi9c/qo7Z4xYzZSebt/uq1dcIxhhrMWuvxWvEuWu32Ldb41jYyE2SrhGfffaZ2bLBfeazfZcfsUmbLjCfet3Mlj127Bh3zGbMmGG27OiFK7gY/Fr0N1u27IeTuP0uXWr++znxh58ZY4wlpmWxP/5cYbbs0qVL83PrtIqU+7fkDgseHh7o06cPDh48iHPnzmHEiBGYNm0aAgIC0KFDB6m7IxaYa891UcjwTo0Q9KobbjSyxpZsNGGu3Wl1Osnr3IitrmyK0k5rpZgbmm3I1u3i+Rlimd91jmxByugO/WfjD2MWY+tRLWK2SJiTRGvFOcwfHWTpnP/nzH1Ej9tmcV6Ux6lZWB97zy5LbTAJO815MTRdCmu+922+P4h5e65ZLGfoxE3zzSpA7jG21cziesusXDIDyO2vZe1Iyu93XUPK8xxUm7jDaC4qZyVjUs4gE7RaLTZu3IhffvkF//zzjy3iskpKSgp8fHyQnJwMb29vm++/MJt+TJU9fi0BP+y6imEtyqJ8oDc2n0vApH8vYlbXKoiJ8Ie7uztX9tzNhybbY2uG+2Ht4CYYufosVp64Y7Lp5/z4Vjh64ykqhPqj66LDqBLii9nvRCEpIwu1J+cumtUmOkhw4eU3E4k157xdvQTWnronWnZ02/KYsClvLo2inio8TcuttpTa9OPt6oIDI5ugypjNVjf98JtozJW9Oa0dGk7djpuPTXduNNX0s6zvG6gZ7gcAaP/DAVx7nG5QVoO6pX1x7k6SoEOf2H7frhKIiR0iuecYY6g1aSfSX1SHC/ar04JpcjC+Y0XBJFp616d3wHMtUGncdq7sTz1qoEFZf+y78gj9l+WNZOE3/ZQu6oprvKpmo3gNmn6YxnQiYKrpZ8ybkYLzwlxZAFjSsyZqhBeBWqlA5OitkMkV+F/T8viqbSRGrz+H3/ZfgSkl/DyQkKZ9sV/GNf2Ixmum6cddpRD0PzFX1njHMshfNGO4uSjMXiMgk2FJ33ro9/uJ3P2+aM4BAH8vFR6n8qr9ZYDcJe87py+7bWgDrDpxB0sO3jRTVniNaFLBHwu6581uzW/6ORP/CMV91Ri9/gI2GyyZAQBXpndChdFbAQDli6lx6UUH1xUf18bzHB168eZ9KurrhYbl/LEh9r7genJpYmtUm7BdMNJM5qLGrelvot603bj7JMXk9/7SxNaImrDH6HpyaWJrAEC77/fjxpMM3n6NrxGXJrZGyvMc7jrYvXYolh+9A5mLCq2jgxFW1AOL9lwWXE8qhfhg1f/yJkU1bPppNH0H7j0zPi9WfxKDXr+dRsaLywHTasC0edeGSxNb48DVx/j499wlA2RKFxz5ugWCfdxEm37+PHoLE198n2RKF6zsXw/v/XQETKfFxbHNuHKRL/5G+vewZ9OPlPt3/saqGlAoFOjUqRM6depki905Df4X0VFla5UJxrIywdzjLnXK4J3aEaLZu5enpyAR4Pu4aaTgsf6iaMjbyxMtqngCAA6ObAq5LHdYI1O4cPt2cXXj/h0Z7I0tQxpg5vbLmLv7GmRKFddxVyHPnfo+MVsuGpdMqYKXlzDmZ9kwUdYFMpj/wqRmafD2wv+sKsvtV+HC3fwsUavVkKus+/XN369S7cb9zZ/DxejzyRRKHL6VBkAJhVqJ/o0iTM4Fw+RKeHh4QKtjSEjOxLYLj5AJF8hVxp9BJldAplJA7eouekyVSiU0L9qr9WVd3dzh4eGBHJnK5Ll04+lzk8+ZisGqsjI5ZC/2myNXm30PflkAOHE/A5+svICv20Vyr9PPSZOcqTG7r6eZeTdjmUwm2C8ADG9RDj5uLhj7j3Gyx9/vc0D07yBW1hwtYxbL3ud1MuUnF1qFC+Qq07Wr+rIurm5QqNzMvo/hNeJplkz02rXvymP0/CUv0RDbJz+Bk7uoedcSdyTlZAlekzvPUu7fhH898fDwgMzFFXKZ8IdQ0+/24l5SptnvvYeHh+CaqS+r/zxqNw/IVeI1EvrvsoeHB7KRzcWqUOcdv20XHuJ/jUobXU8STRwzAFCpVEhIFz9eLmo3aCEHoHsRQ94PBf3ngTJF8Nom3+3FmbEtoXZxMUouZC6ugrL6IyGTK+Du7o4f992AzuC8k3Kfsjf7tRcQuzFVxWiqmWjf543ROjrI5P6Kmli1WSGXce/Fn4hM8IV/8f8PY8KMXl/MM3e/+lEwYvMUKK2Yn0UKW8/5wGdqOKcl95Iy0ffX49h7+ZHJ6c31ArzUKOnnbvJ5fdPHZ3+fQf3pezBx00WL729qNNTuuEeoNnGHcP8vOmmK1ewUpjtmJpITs2jfDWh0DOM35h0PuSy3hsRS05ql5iQfNxe4WZls2YI1Q8rvJ4uPhrF2lMm1R2mSmxG1utyRPIYrSK85aTwzsyF+8wl/iL9Gy/AsQ/jrP0enM/k3EWuqvGFmCK/eb7xFNfn0Q+ctDZnW4x8z/rQDgPi1x9ys1Ob+zlodszgBo+Hosec5Oq55b8fFh/hp/3WuOcjwb82/ht9OzMD0rXH4dttlQRlnmsHWJjUqxDmEFHFDx6rFEeTtKliYLqyoeGbcIioQgd5q7LxoeSZGU/0z9HlGUQ/jGppinmo8TMm7qBXxUBndAA3X2HFWGq0u34nKN+vPI1ujw664RxYviCql3Gx/I/1U4VImtTN1vev72wmjbT/uu47nGp3REOvC9ufRgg9f33r+AVYcvyMY0pkfnmql1TcyW7CmMd7UkhLWJiqGa0JZ41JCCmpO2gkXhQyXJrTmJqa05th8vEx8VWONTodnBn8frU585uolB+Pz3UdLrDYMAD5ffRa1wv2s/vvyEyXD2VvFkhLDOWgu3k/BF2vOYETL8qgeWsTk+zzLyLHYf0xsfpscLUPsnSSuWTAxPQdftqlgdDz5v3VNLU75MPU5Rq09h05VS6BTtRJmY7E3qlF5hchkMnz/XjWMahtpuTCAxT1qYlKnSlZ9+flfZP5XOtDL1eh5APiyTQV4GMyCW0RkVlfDGpUv2zjnCtzZWl2+Oyzzbx6WLj5qpQIuBslbCV83vFMjBEDur7A/JHSyA2CiPkXcqdtJGPzXaRy3ogOhs7vxJL3ASQoAeLkqbdZZPdC7YIuCVixuvi3f2ht56vOcfC9Ol6MV1lIVJIn7cMkxwXw4+v2LfQ5rag/z4/PVZyTUqPAm7jNIFPSrYvPlaJmg5mTgX6dw/l4Kei89jjSRtbn0+v1+wuxM0lodw9frjNdWk8uATvPz5n7Rf48NJ/Hjf9oTN8UTlQV7rmPv5ccYauXaR/ZEicorSsoIlaqhvgBgdj0fw+amxT1qok5pP0zoFM1taxMdBE+1EluHNkD/RhFGk5uFijRp8GtUaoQVMTupnSNl5ehMrjZrS2ql3Oh9YiKKon6Z3An9MnO0oos/miM2yZwlKRJGIr3q/DxUNqn5i/D3gLvKuBLbMDE15cAXTVDrRafsgsrRMatGF5nCn4zQmlmrpZKysGhBHb/5TDABoCmrTtwR/NDIyNZadZ3VJzTpWRpB81BGASZXO2didXHD1df1zUOGy3Hw//L/nBGf1TbJia4BlKi8okxdWN+pmfvLvFIJH27btM6V8FH9UiZXSBbTIioQKz6OQQne+j7z36+Ow6OaokJQ7q8+wzZU/UKLfPwoPfO5DpEpP35QA00rBNhkX/eSMgtlmLZY089nLctz28RmNbXEUr8YMU7UPO1wvu4qyUPTv3+vqtE2uUwmOjO0tcNaQ/3cUSHIS1IcpuRodAUa6t7hxQrcW84lGM36awsWVxy3sasWVnQGcldXjr2TxD1Oy9JYdQw3nL6H5Iwc9P5VuKJ9fr6XemIjqwDj/mjPc7RYftS4BpZfyyO29AYAuPPOVSlTKNgDJSqvqHoRub/ADTvK1gr3w77PG+Pv/nlD5op5qvHNm1EoE2DdRdDUdVUul8GLtxTAc14b7p7PGsPfy7jam181b+t+AK2jg/BLr1o22W/H+YesXl24INRKOVx4NVt/9auDIB9XLvHMzwU8zcEdY22tSohPvhLQhuX80bl6iOTXFXF3kZwgto4OwrfvVBZsk8mE62H5urtgcY+akqZZL+ZZsKYjPY0VnTXNycjW4tC1J/hkufhijAWVUghz2/BZeyi+257X4fS0lUtCjN5wAVUmbMcxg2nu8/OjQ+8ob/mGsgGe3L8N+3ZlZmtFm4iyLCwmCgiv3/y1qByBEpVX1LddqmBAkwis+aSu0XNhRT3yveaPFFPeqgSZDPi8VXmUKuYBD5GRE/w4DKstbWX5R7UR4V+woXZaHeM6IE7oWBHXp7S1RWgAgK95fYoM+6iolLn/VhVyjUph2DRIvAbPUmL544c18nWT/b3PG5jZtYrk1/m4uZj81WmKSiFHw3L+gm1ymQxuvPN93af1LC4masglnx26DeVoC1ajAgDdfz5qk1jEJIusc+UM+EuHFFRBvpdnXzT9NCznjwj/vETluEF/E1MLShqOtBLD/xFZGD/SzKFE5RXl56HC560qILyY7cfCW5tONCjrj7NjW2JAkzIAYNS5tmVUINpVzpsjxlLFRxH3/E08VKd0Uewa0ThfrxWjkMugkMsw7/1qgu1da4agTmnpfQjq8xaUVBn0UVG9mBxK3/STnxoVU+3Z1tjzWWNEBRd8MsUAkdq0IiaGxVvqcBzo5VqoTVNKhdxkojv7XePER6WUQyaTGTXhyQyafqztmwKAS3AMX5Pf2ZKzNTpuBJk5YlMKFAZHD48vDLN3mJ6E0BJ93lDcx/x8O6aabIavEl9glU+fzPSqG45oXlcBR6BEhdgVvynI3aBGZVrnyoKLuakalegS3pjYKRobeb/ApVzk9VZ8XAfv1gy1XNAC/c3hzcrCPjduLgos7lFT8KtZ77OW5Uzuz4t3M1Ab9FFxeVGjov+86fmoUblgZql6S0r6uSOkiJvlgmbcnNYOHzcsbbTdU6RjqZ6XmRukXC6TNCW7oZ971JT8mtqli2Le+9Uwi1cjU8LXDW9VM25KUr/4+xkOZ5fLIJiPRcpw91C/3L+BYUfr0lbUFJYPNG7SPRqfiK0XLE/r379xBHzcbDszqdj3AwBWflzHaNuYN6Os3q+5c8YZ6Tust6sUjN0jGuVrH8E+bnbrO5f4Yobwwqh9t4QSFSJZfte08HYVXvAMO/yWedHWqv+RWCbAE7tGNML6T+vhwzphCCmSN2ooP/1O6pQuivEdK5otU4bX3muKwsQkddlaBi9XF9FaFf6XPdjgVxC/E7FSLvwlrr8x6eesMKxtGNDENqOkSonUvMllucd5bIeKeKOUH1rymikalC0megM09FH9UkbblvV9A0t61oSPmRoyw3PFkNQ1ivry4miSzw7Wb1Yujrd5fVxMTdilUAiTSz25TCZINNQvasuaR1qORz/lAP/caFC2GAK8LM92O6R5WbPPlzZR6zqqTQV83KA0jn7VDM0jrW+ialC2mKAPnCFTPzJqly6KcoHC71/Vkr5Wvy//+vAyuP9ivaav20WK9t+zRrCvq03WZtJPf8CX+KJGxVRiWZgoUSGFRi6XYSIvUdBftFd+XAe964VzTUQHRzbFzz1qYsewhojw9+Ru0nz5ndHW1UWBD+qUNNmcUSvcD4s+rCH6XN57511o53bLa/4xtSjYqDYVBIlKWd4N/ss2FQRDVrM0Oq5fCpB3YzI1dLxDFdtMxCTWB0P/i7+ErxtW/S8GM7tWQZC3KzpVLY5lfWtb1cz1RWvjeXEalPVHMws3Pm8Lv+Kltpl/xesHJCXJ/aqt6Xl99H08DC/k+r2rFHI0Lp/XT0Vu0JlWf3wnv1XJbAw7hzdEk/K5yQw/Ualdys9ibVdRD5VRTaYhwyZZvf81ioBSIYeriwLjO1ZE1VBf0dFMhnzcXFDcVxjXrK5V4K5SYN771cz+0DFMvKRMCeDnYZ81afKjfZXiGNveutogfy91vkc8FvcpWG2nHr+fi55+TSU3M0syFBbHR0BeK/zqbv1Ft3bpohjbviJXLV7c1w3NowLNXtCiS3gjvGj+fkFN6lQJm4c0wMaBxp05M7M1Fi8a/Btde96Qa7HOibtGNMLHDUsLEpUyvItC2+hgwTF5lJolrFF58Zyri/hX1dzcN1KIjbIw7GPh5eqCQ182xZz3cpMza2rWLDVv6GuwZDLhDd9SNb6UBZzfqxWarxq4TYPq46P6xk1WevoalY2D6gn6sOjPAplMhl97v4FWFXOTso8bRgiSAn3Ngtj0/ME+rljzSQxW948RjMYzTGJHiiSChixNVmdNE1QJXzesH1APHataTowN+1l1r10Sb1cPwblxrfBm5eKiTRXVX9ScBBnUNkqZaM/WTVQF4aqUo3e9UthlRZOOi0Ke71rqIh4uVjX9WOq0rZ+nSQw1/ZCXUkGaRPnNJgUZNqxWKrBzeCO8UYAJsMoFGf+KyMzRWvwFahh3dInc2hn9NNP62gI/DxUi/D0hMxjtUcxLhaHNy+KDOiW5vgd6D5KfC/rqqLgaFfGYpIwCaVDW9MVIrM+H2K9ZwQzFEv58ptbK+blHTbStFISNA+vDk5ec+BsMw905vCGKuLtg1IuZi62tUZn/fnVM61zZckER0SV8IDdzjuoXzisT4IWdw/NuSIahzX+/OvZ+1hjtKgfDU513HPQ1he4iN4KFH9RAjTA/btVtPf6NW6mQo4iHymyy6uPmYvFmL/Y95NcUGvpfI9PJGwCEFnEXJD/6w6F/H8N3G9S0DH7t8wYA42ZRKRPtWWouLEz676WHmX5YgLB21lJS82njCHzVtgJ8eU2mXmrrPvMMC98BbzfTcdp6Pbb8eLl6HxHnUIBMJb+jFAzJZbkX6oIsFid2828dHWSyKlzP8MK+un9d3EnM4Jp0ur1REv5ealR7MeMvIKwR8XZ1wQd1jBdxBIDivuIXarVIjcrwFuVE/xS5v8I9MWXzJaw6kbdg3JS3KmHbhQeY9O8lo9dMeasSpm2Jw+BmZbl1URItDGGUMpy8c/UQbDh93yhZCi/mgQXdc5vawvzc8Tg1d22or9pF4t8Xk1oF+7iiTIAXTo1uwf3ytDZRMXUTn9W1CkauOYucAszOyu+jYu4XsVIh50bfic1MK9a0KTZKChAmKvoaGXN/hvndqwuGqH7aOAILDFbmNuwzMvXtSoKaQkOj2kSKrjU0s0sVPMvIxjs1QgRTERiOVDM8Vn3qleKSDKMaFQk3SUvNhYVJn+S7q81fn5Z/VJv7t1jzi16wjyvXjLri2B0kvRi+7WllB2Jzx8ZFYTxCjc+aWXvtjRIVUqhstQihPlnoVS8c+648Rp3SfvBUu6CEryt83FVoY2a1aHM6VilhcmVaPcNky9VFIeh3opDL0KpikFEZPbGLxqZB9bFw73V81qq8IPnSX0DEql8HNimDDN5NqFpJX3SpEcr9Cp/xThWcup2Eay9m3fRUK/FRg9KiiUqtcD+c+KY5ZDIZl6hYygWk5JyuLgqsMtPBEgBmda2K4ati8b9GESjh64YL41thzam7aBmVeyz5Nzhr8wtTzRpvVw9Bu8rBKP/NVut2JCI/57KHhRuXnqmJ3QQ1Ki9u4jITvxz+/Kg2IoO9cZ43PF2s06bhL+b8NidGl/BBeZGZcx+lCFdb5kfb7Y2SgmHqQd7GifpPH9YwuaghnzM1/ejPO7HaMr6iFibwKxvgiauP0gRLi/CvD9aeT+Zqrz3USpPfk8ohPuhig5GSBUWJCpHM1IXRGuZ+NUiK4cVNq0n5AOz5rDFK+Lrla3XjjQPro/2L6cCDfVwhl8ssVtfmp8lKWKNivP/oEj6Y37069/ibdpFQK+VcgiJ285DLZfBUK/F3/xjIZUCNMONmMH5SZa6myEWZ106uVsqtWmtFrEbl0oTWiByTv5t/yaLuWM2boNBDrUSPmHDRsvymqobl/E2u9mzupmtYo3Z6dAt0XXTY4nTqiz6sgdHrz+P798SbR8wNnbZmrZ6WUYEmz2V+c5ylCi19FPyESuzGaFijImVAlUop52bWNRXzw9Tngsf8uKe+LexILNZHpWXFIAxoEoH5e4Q1QYb436sOVYrDQ61EndJ+GLIi1tLHAAB4qZVIzcc8RW4uCgR6q3HzaQYv7twPqVTIUcLXDfeSxH/8WOoPN/2dylAr5YgMyuv8z78+qZUKjGhZHlvOWx5qboqHSrjoZp3Sfiju6wZ/LzVGtbFugVt7c3zjE3mtRAZ748cPqmPDgHoF2k+NsCLcv0sV88hXkgIAlUJ88OMHNRBW1B0LP8htgrBUXZufNltLNSqGPmpQGh/ybtLmRj/UCvcTTVIAYfOEuWPkwktorB6BIHKjdFMpuGHMlew4SRS/6acBryPguPZR+KZd3sXV2vPijXA/FPFQIdjX8iiKVhWDcOzr5oiJKCr6vLn7fGl/T2wcWB//fdlUsP3AF02w4uM6iJ/aFj+ZmefFRWl80E0lLPqbPv98LSYyyZ7h+ay1oqdylxohKOLugoEvRuoBppPCYh7WD70NNhjFor/hW7PwIf971aFKcUx9u5KgluVDE82tQO7s0NuHN8QffWubLKMX5O0qmIvH1UUu6KMEADGl887JGe+Y7h9iqUbEU61ExeLCvlKG16cyAZ4mO8O6uSjw24v+P6b4ursIri/uKiVmda3qNEkKQDUqxAFaRwdbLmTCzuENceDqE3SvbfqiIz2eILTmNRVZGhKZvxoVXqKSj05/+R0VcJ23WqtehyrFjVZM5f+i8nRV4mm65Sm2TfVR+bZLFdSPvYe2lfL/d7akeskiOH8vdyK7XvXCoWMMDcr6I6q4N/ZcfsSVs3bUiL937s10ylvRGPTXabOjfSyxNN1+pRDjBC7Uz110dXFD/M9jquLmr3518Dgti6u95Cd1YjUqCoMaFWv67cx4pzK0OoZ1p+9x2wyTwjWf1MX8PdcEiWMu0+ey4ezTXP8diYmKWFOpWCL1Uf1S6N84gmtqC/Zxw+S3orHs8C3EPUgVfZ9571cTdHJWKxWCfkYuCpnRbNOmGPZZeqdGCFafzOtX5irSj06sxpffD6lOaT8cuZG7rtDFCa0sXjtmdq2Srwk0CxPVqBCrhb0YDvxmFfvdgCwpE+CF3vVK5bsGxRqWvtj56ZvAv0ia62Fva/97MSPs+7VLcttmda2Cd2uGCkYi8UcPWVujYipf83FzQY+YcJstoCfmi9YVMKx5Oewc3hAuCjn+1ygCUcVzq8cblCmG0v4e8FIrrbr5A3k3hJAi7lj3aT3B0g7WiimdW8NiOHLFlvhNefqVcg3ncYmJKCpYqZx/s/MVmWRPrTCsUbGcqMhkMigVckHtkWEiUCOsCH7pVQulDZp7zX29ZDIZhvImqNPfQK35bcD/ASB2fTDstNy0QgC+eTPK6DztXjsMv/c1XQthuB/D92pQVrjGE/+HzUJe867hcwAwqVO04IeSq8gcJgHext+rVBOLOFq6lnmqlagQ5G3zBWFtjWpUiNX+HdwAt56m22Ttl5eFTGb8yzU/X2p+9XphDqMc1qIc6kQURV1eM4VSIcf0dyrjowal0GL2fgDCfgqWRj3p2WsRSWt4qpUmZ1xVKuT4d1ADaHQ6wRIO5tQ10YwjxYLu1TFj22V0e8N+nQ/Fbjw/96yJtxb8BwBYLNJsVLKoO75pF4minirR2sKwosKZaaUsVsjvj2PtjwdLZ02f+qUwZ+dVAHmjfqw51/hz7+h/DOiTV8C4E7y5PRZxF1+HSmw/hrUR5hK9xuUDoJDLTJZxdVGgQdli2BX3iHtsaFDTsjh56xneqlZC8DpLaoUXMbloIf+8KsjyFPZCiQqxmr699HXi5qIwWrHYmvZyQ0E+ruhbvxTcVYpCnUDJ1UXBzWpqiN9+zx8GOrBJGfSIP4Z2Fppu8tscVRhyR0ZYPs67RzTCqdtJgot+fhXxUBl1DrUn/f2kWskiuDmtHbI1OpPJwkcNcmvWxH55N48KwOydeQvkVeUNq7eEf7+1dhZZS6eNt6sLtg5tAKVczvXNsOa3gVopx2cty+Fxaha3vEOAlyv2f94EHmqFYKg+AAxqZnppAReFHOfGtUSlcdtFn+MzrLUzHDrPf6hSyi3WWPH3L9b04+ehwj8Gk1XOeKcyhq6IxfAW5bD00E3R/S7t/Qaix24TbJO6FIWjUKJCiBnuKpFEJZ/VpKMlLLBmyaCmZSwXsiDA25Wb2pzfWa9hOX/892VTBHqbb8IwPAr5nSnYkUr7exo1TbysrKnRMLzJtqsUjIrFffBbnzeg0zGolHJBR3VL+DdhaxNXa0YNVggS1tpas2+1UoGBTY2Tj5IvzsuWFQMxfWscAODMmJZm15oChAuqhhV1x60Xo3r0Tb9Le9XCL4fiMeXFEgjFPNV4kpaFZgZrSfGbUq25dojNXmxJhSBvbB3aMDcuE4mKp8F+tTrGzWHE54ypCyUqhIjoXrsklh+9jYFNymDcxouC52w1F0x+NY8MxIiW5W2yL/4ie3yGa7WI4VfHj20fhTYF6CRNpMvPDcXVRYHBTcsgS6vDkGZluf4tjcr5W3ilOKlrLgHSZjTWs6bpx9L8LxH+nljSsyYUcpnFJEXvxw+qY/nR2+gRE45+v58AkFf72KRCgGCBy81D6uPUrSSjRSbLB3nhk8YRRnPEmMIfCZSfWsv+jSNw+MZT0RrR8R0q4q9jt/F73zfg4+ZicsZrZ0OJCiEiJnWKxqi2kTh3N9noOUd9ubvWDMGqE3cxsrVtkpSC4v847F2vlOMCeU1FikyuZo3hNkpygfz1Z8hPmq9fpsIca5aTsLQYpqHW0cFoHR0smDTP1A+VAC9XwehBPmvWZNKzto+YKY3K+ePYV81EO7P3rBuOnnXDzb7eCbuoOHbUz9SpU1GrVi14eXkhICAAnTp1wuXLlx0ZEiEAcn/JeKqVqBrqazQKpqin6Y529jS9c2VcnNBKMAuuI5lbB4fYz9ahDbCwe3WjdYAcwU/CHCl6Y9rnrqBuac0gvgZl/fFDt2rYOrSBYPuPH+SNorHVAp1i+MmJvWtUbTHDboC36yv1/XRojcq+ffswYMAA1KpVCxqNBl999RVatmyJixcvwsPDw/IOCLEzN5UCJ0c3x7h/LuKvY7cB5M5g6QgymUx0rRjyeqkQ5G3Uh8NRWkcHoWdMGKpL6NfSOjrIqj4ihjoYrD8kk+XWeKz5pK7F9WoKit/0JGX9ofzoVqsk/jhyC00riHeCfx059Kq3datwqu1ff/0VAQEBOHnyJBo2bOigqAgRUisVyOQtzOXMo10KEx0GopDLML5jtOTXSU1SxOibKKR0/i3oewGFUKPi7oIDXzRx2HXGCVt+nKuPSnJybjugn594lWZWVhaysvIWuEpJSSmUuAhJy8caIK+6MD+q9SSvn4LW3KgUcmRrdYjwN/39oR9DQk4zM61Op8PQoUNRr149REeLZ+hTp06Fj48P919oqONXdSSvh48b5q5ealj9/DprEx2EYc3L4XcLa4kQYkvdX8yyPKJFOYe8v+GEb1Kt+aQu2kQH4eeetWwUkW0544RvMuYkUX3yySfYsmULDh48iJAQ8SGTYjUqoaGhSE5Ohre3c7TZklfXo9TnKOahfqU6qRHystHqGK4/TkPZAM9Cq3nIyNYgakzuZGnxU9u+kjUe4V/+CyB3+oOfe5peGNNWUlJS4OPjY9X92ykSlYEDB2LDhg3Yv38/SpWyfpijlA9KCCGE5NfTtCy4KOWFugRGYVp+9BZ+PhCP33q/wU2SZ08vTaLCGMOgQYOwbt067N27F2XLmp7SWAwlKoQQQsjLR8r926GdaQcMGIA///wTGzZsgJeXFx48eAAA8PHxgZub5ZkxCSGEEPJqc2iNiql2vqVLl6JXr14WX081KoQQQsjL56WpUXGC7jGEEEIIcWJOMzyZEEIIIcQQJSqEEEIIcVqUqBBCCCHEaVGiQgghhBCnRYkKIYQQQpwWJSqEEEIIcVqUqBBCCCHEaVGiQgghhBCnRYkKIYQQQpwWJSqEEEIIcVqUqBBCCCHEaTl0rZ+C0q8VlJKS4uBICCGEEGIt/X3bmjX/XupEJTU1FQAQGhrq4EgIIYQQIlVqaip8fHzMlpGxl3gJY51Oh/v378PLywsymcym+05JSUFoaCju3LljcQlqIh0dX/ui42tfdHzti46vfTnD8WWMITU1FcWLF4dcbr4XyktdoyKXyxESEmLX9/D29qYvih3R8bUvOr72RcfXvuj42pejj6+lmhQ96kxLCCGEEKdFiQohhBBCnBYlKiao1WqMHTsWarXa0aG8kuj42hcdX/ui42tfdHzt62U7vi91Z1pCCCGEvNqoRoUQQgghTosSFUIIIYQ4LUpUCCGEEOK0KFEhhBBCiNOiREXE/PnzER4eDldXV9SuXRvHjh1zdEgvhalTp6JWrVrw8vJCQEAAOnXqhMuXLwvKPH/+HAMGDEDRokXh6emJzp074+HDh4Iyt2/fRrt27eDu7o6AgAB8/vnn0Gg0hflRnN60adMgk8kwdOhQbhsd24K7d+8ePvjgAxQtWhRubm6oVKkSTpw4wT3PGMOYMWMQHBwMNzc3NG/eHFevXhXsIzExEd27d4e3tzd8fX3Rt29fpKWlFfZHcTparRajR49GqVKl4ObmhoiICEycOFGw1gsdX+vt378f7du3R/HixSGTybB+/XrB87Y6lmfPnkWDBg3g6uqK0NBQzJgxw94fzRgjAitWrGAqlYr98ssv7MKFC6xfv37M19eXPXz40NGhOb1WrVqxpUuXsvPnz7PY2FjWtm1bVrJkSZaWlsaV6d+/PwsNDWW7du1iJ06cYHXq1GF169blntdoNCw6Opo1b96cnT59mm3evJkVK1aMjRo1yhEfySkdO3aMhYeHs8qVK7MhQ4Zw2+nYFkxiYiILCwtjvXr1YkePHmU3btxg27ZtY9euXePKTJs2jfn4+LD169ezM2fOsA4dOrBSpUqxzMxMrkzr1q1ZlSpV2JEjR9iBAwdYmTJlWLdu3RzxkZzK5MmTWdGiRdmmTZtYfHw8+/vvv5mnpyf7/vvvuTJ0fK23efNm9vXXX7O1a9cyAGzdunWC521xLJOTk1lgYCDr3r07O3/+PPvrr7+Ym5sbW7RoUWF9TMYYY5SoGHjjjTfYgAEDuMdarZYVL16cTZ061YFRvZwePXrEALB9+/YxxhhLSkpiLi4u7O+//+bKXLp0iQFghw8fZozlfvnkcjl78OABV2bhwoXM29ubZWVlFe4HcEKpqamsbNmybMeOHaxRo0ZcokLHtuBGjhzJ6tevb/J5nU7HgoKC2LfffsttS0pKYmq1mv3111+MMcYuXrzIALDjx49zZbZs2cJkMhm7d++e/YJ/CbRr14716dNHsO3tt99m3bt3Z4zR8S0Iw0TFVsdywYIFrEiRIoLrw8iRI1n58uXt/ImEqOmHJzs7GydPnkTz5s25bXK5HM2bN8fhw4cdGNnLKTk5GQDg5+cHADh58iRycnIEx7dChQooWbIkd3wPHz6MSpUqITAwkCvTqlUrpKSk4MKFC4UYvXMaMGAA2rVrJziGAB1bW/jnn39Qs2ZNdOnSBQEBAahWrRoWL17MPR8fH48HDx4IjrGPjw9q164tOMa+vr6oWbMmV6Z58+aQy+U4evRo4X0YJ1S3bl3s2rULV65cAQCcOXMGBw8eRJs2bQDQ8bUlWx3Lw4cPo2HDhlCpVFyZVq1a4fLly3j27FkhfZqXfFFCW3vy5Am0Wq3gQg4AgYGBiIuLc1BULyedToehQ4eiXr16iI6OBgA8ePAAKpUKvr6+grKBgYF48OABV0bs+Oufe52tWLECp06dwvHjx42eo2NbcDdu3MDChQsxfPhwfPXVVzh+/DgGDx4MlUqFnj17csdI7Bjyj3FAQIDgeaVSCT8/v9f+GH/55ZdISUlBhQoVoFAooNVqMXnyZHTv3h0A6PjakK2O5YMHD1CqVCmjfeifK1KkiF3iN0SJCrGLAQMG4Pz58zh48KCjQ3kl3LlzB0OGDMGOHTvg6urq6HBeSTqdDjVr1sSUKVMAANWqVcP58+fx448/omfPng6O7uW3atUqLF++HH/++ScqVqyI2NhYDB06FMWLF6fjS8yiph+eYsWKQaFQGI2UePjwIYKCghwU1ctn4MCB2LRpE/bs2YOQkBBue1BQELKzs5GUlCQozz++QUFBosdf/9zr6uTJk3j06BGqV68OpVIJpVKJffv24YcffoBSqURgYCAd2wIKDg5GVFSUYFtkZCRu374NIO8Ymbs+BAUF4dGjR4LnNRoNEhMTX/tj/Pnnn+PLL7/Ee++9h0qVKuHDDz/EsGHDMHXqVAB0fG3JVsfSWa4ZlKjwqFQq1KhRA7t27eK26XQ67Nq1CzExMQ6M7OXAGMPAgQOxbt067N6926jKsEaNGnBxcREc38uXL+P27dvc8Y2JicG5c+cEX6AdO3bA29vb6CbyOmnWrBnOnTuH2NhY7r+aNWuie/fu3L/p2BZMvXr1jIbTX7lyBWFhYQCAUqVKISgoSHCMU1JScPToUcExTkpKwsmTJ7kyu3fvhk6nQ+3atQvhUzivjIwMyOXCW45CoYBOpwNAx9eWbHUsY2JisH//fuTk5HBlduzYgfLlyxdasw8AGp5saMWKFUytVrNff/2VXbx4kX388cfM19dXMFKCiPvkk0+Yj48P27t3L0tISOD+y8jI4Mr079+flSxZku3evZudOHGCxcTEsJiYGO55/RDali1bstjYWLZ161bm7+9PQ2hF8Ef9MEbHtqCOHTvGlEolmzx5Mrt69Spbvnw5c3d3Z3/88QdXZtq0aczX15dt2LCBnT17lnXs2FF0yGe1atXY0aNH2cGDB1nZsmVfy+Gzhnr27MlKlCjBDU9eu3YtK1asGPviiy+4MnR8rZeamspOnz7NTp8+zQCwWbNmsdOnT7Nbt24xxmxzLJOSklhgYCD78MMP2fnz59mKFSuYu7s7DU92BnPnzmUlS5ZkKpWKvfHGG+zIkSOODumlAED0v6VLl3JlMjMz2aeffsqKFCnC3N3d2VtvvcUSEhIE+7l58yZr06YNc3NzY8WKFWMjRoxgOTk5hfxpnJ9hokLHtuA2btzIoqOjmVqtZhUqVGA//fST4HmdTsdGjx7NAgMDmVqtZs2aNWOXL18WlHn69Cnr1q0b8/T0ZN7e3qx3794sNTW1MD+GU0pJSWFDhgxhJUuWZK6urqx06dLs66+/Fgx9peNrvT179oheb3v27MkYs92xPHPmDKtfvz5Tq9WsRIkSbNq0aYX1ETkyxnjTAhJCCCGEOBHqo0IIIYQQp0WJCiGEEEKcFiUqhBBCCHFalKgQQgghxGlRokIIIYQQp0WJCiGEEEKcFiUqhBBCCHFalKgQ4oRu3rwJmUyG2NhYR4fCiYuLQ506deDq6oqqVavadN+NGzfG0KFDbbpPe8vIyEDnzp3h7e0NmUxmtM4SIcQ2KFEhRESvXr0gk8kwbdo0wfb169dDJpM5KCrHGjt2LDw8PHD58mXBGiJ8L2PCkV+//fYbDhw4gP/++w8JCQnw8fFxSBy9evVCp06dXpr9EiIVJSqEmODq6orp06fj2bNnjg7FZrKzs/P92uvXr6N+/foICwtD0aJFbRjVy+n69euIjIxEdHQ0goKCXtsElhB7o0SFEBOaN2+OoKAgbhl6MePGjTNqBpkzZw7Cw8O5x/pfplOmTEFgYCB8fX0xYcIEaDQafP755/Dz80NISAiWLl1qtP+4uDjUrVsXrq6uiI6Oxr59+wTPnz9/Hm3atIGnpycCAwPx4Ycf4smTJ9zzjRs3xsCBAzF06FAUK1YMrVq1Ev0cOp0OEyZMQEhICNRqNapWrYqtW7dyz8tkMpw8eRITJkyATCbDuHHjjPbRq1cv7Nu3D99//z1kMhlkMhlu3rwJANi3bx/eeOMNqNVqBAcH48svv4RGozF5XP/991/4+Phg+fLlAIA7d+6ga9eu8PX1hZ+fHzp27Mjtm3+Mv/vuOwQHB6No0aIYMGCAYNXXBQsWoGzZsnB1dUVgYCDeeecdk+8PAGvWrEHFihWhVqsRHh6OmTNnCo7rzJkzsX//fshkMjRu3NjkfjZu3IhatWrB1dUVxYoVw1tvvcU99+zZM/To0QNFihSBu7s72rRpg6tXr3LP//rrr/D19cW2bdsQGRkJT09PtG7dGgkJCQByz7/ffvsNGzZs4I753r17LR6zuLg4uLu7488//+Tea9WqVXBzc8PFixfN7peQQlfoqwsR8hLo2bMn69ixI1u7di1zdXVld+7cYYwxtm7dOsb/2owdO5ZVqVJF8NrZs2ezsLAwwb68vLzYgAEDWFxcHFuyZAkDwFq1asUmT57Mrly5wiZOnMhcXFy494mPj2cAWEhICFu9ejW7ePEi++ijj5iXlxd78uQJY4yxZ8+ecasfX7p0iZ06dYq1aNGCNWnShHvvRo0aMU9PT/b555+zuLg4FhcXJ/p5Z82axby9vdlff/3F4uLi2BdffMFcXFzYlStXGGOMJSQksIoVK7IRI0awhIQE0UXgkpKSWExMDOvXrx+3crZGo2F3795l7u7u7NNPP2WXLl1i69atY8WKFWNjx44VxKlfYHH58uXMy8uLbdy4kTHGWHZ2NouMjGR9+vRhZ8+eZRcvXmTvv/8+K1++PLegXc+ePZm3tzfr378/u3TpEtu4cSNzd3fnFhU8fvw4UygU7M8//2Q3b95kp06dYt9//73Jv/+JEyeYXC5nEyZMYJcvX2ZLly5lbm5u3AKbT58+Zf369WMxMTEsISGBPX36VHQ/mzZtYgqFgo0ZM4ZdvHiRxcbGsilTpnDPd+jQgUVGRrL9+/ez2NhY1qpVK1amTBmWnZ3NGGNs6dKlzMXFhTVv3pwdP36cnTx5kkVGRrL333+fMZa7gm7Xrl1Z69atuWOelZVl1TGbP38+8/HxYbdu3WJ37txhRYoU4Y6Jqf0S4giUqBAiQp+oMMZYnTp1WJ8+fRhj+U9UwsLCmFar5baVL1+eNWjQgHus0WiYh4cH++uvvxhjeYkKf6XSnJwcFhISwqZPn84YY2zixImsZcuWgve+c+cOA8CtktqoUSNWrVo1i5+3ePHibPLkyYJttWrVYp9++in3uEqVKoLkQozhis6MMfbVV1+x8uXLM51Ox22bP38+8/T05I6J/nXz5s1jPj4+bO/evVzZZcuWGb0+KyuLubm5sW3btjHG8o6xRqPhynTp0oW9++67jDHG1qxZw7y9vVlKSorFY8EYY++//z5r0aKFYNvnn3/OoqKiuMdDhgxhjRo1MrufmJgY1r17d9Hnrly5wgCwQ4cOcduePHnC3Nzc2KpVqxhjuYkKAHbt2jWuzPz581lgYCD3mH+u6llzzBhjrF27dqxBgwasWbNmrGXLloLyYvslxBGUjqvLIeTlMH36dDRt2hSfffZZvvdRsWJFyOV5La2BgYGIjo7mHisUChQtWhSPHj0SvC4mJob7t1KpRM2aNXHp0iUAwJkzZ7Bnzx54enoavd/169dRrlw5AECNGjXMxpaSkoL79++jXr16gu316tXDmTNnrPyEpl26dAkxMTGCPhz16tVDWloa7t69i5IlSwIAVq9ejUePHuHQoUOoVasWV/bMmTO4du0avLy8BPt9/vw5rl+/zj2uWLEiFAoF9zg4OBjnzp0DALRo0QJhYWEoXbo0WrdujdatW+Ott96Cu7u7yZg7duwo2FavXj3MmTMHWq1W8D7mxMbGol+/fibfQ6lUonbt2ty2okWLonz58tzfGADc3d0REREh+FyG54kha4/ZL7/8gnLlykEul+PChQvUz4Y4JUpUCLGgYcOGaNWqFUaNGoVevXoJnpPL5WCMCbbx+0Xoubi4CB7LZDLRbTqdzuq40tLS0L59e0yfPt3oueDgYO7fHh4eVu/TkapVq4ZTp07hl19+Qc2aNbmbZlpaGmrUqMH1V+Hz9/fn/m3ueHp5eeHUqVPYu3cvtm/fjjFjxmDcuHE4fvw4fH197faZ3NzcCrwPsc9leM4ZsvaYnTlzBunp6ZDL5UhISBCcN4Q4C+pMS4gVpk2bho0bN+Lw4cOC7f7+/njw4IHgxmHLuU+OHDnC/Vuj0eDkyZOIjIwEAFSvXh0XLlxAeHg4ypQpI/hPSnLi7e2N4sWL49ChQ4Lthw4dQlRUlKR4VSoVtFqtYFtkZCQOHz4sOEaHDh2Cl5cXQkJCuG0RERHYs2cPNmzYgEGDBnHbq1evjqtXryIgIMDoc0oZEqxUKtG8eXPMmDEDZ8+exc2bN7F7927RspGRkaLHo1y5clbXpgBA5cqVTQ7ljoyMhEajwdGjR7ltT58+xeXLlyUdd7Fjbs0xS0xMRK9evfD111+jV69e6N69OzIzM83ulxBHoESFECtUqlQJ3bt3xw8//CDY3rhxYzx+/BgzZszA9evXMX/+fGzZssVm7zt//nysW7cOcXFxGDBgAJ49e4Y+ffoAAAYMGIDExER069YNx48fx/Xr17Ft2zb07t1b8g3m888/x/Tp07Fy5UpcvnwZX375JWJjYzFkyBBJ+wkPD8fRo0dx8+ZNPHnyBDqdDp9++inu3LmDQYMGIS4uDhs2bMDYsWMxfPhwQXMYAJQrVw579uzBmjVruPlYunfvjmLFiqFjx444cOAA4uPjsXfvXgwePBh37961Kq5Nmzbhhx9+QGxsLG7duoXff/8dOp0O5cuXFy0/YsQI7Nq1CxMnTsSVK1fw22+/Yd68eZKb/8aOHYu//voLY8eOxaVLl3Du3DmuBqxs2bLo2LEj+vXrh4MHD+LMmTP44IMPUKJECaNmJ3PCw8Nx9uxZXL58GU+ePEFOTo5Vx6x///4IDQ3FN998g1mzZkGr1Qo+n9h+CXEESlQIsdKECROMmmYiIyOxYMECzJ8/H1WqVMGxY8cK1JfF0LRp0zBt2jRUqVIFBw8exD///INixYoBAFcLotVq0bJlS1SqVAlDhw6Fr6+vUQJgyeDBgzF8+HCMGDEClSpVwtatW/HPP/+gbNmykvbz2WefQaFQICoqCv7+/rh9+zZKlCiBzZs349ixY6hSpQr69++Pvn374ptvvhHdR/ny5bF792789ddfGDFiBNzd3bF//36ULFkSb7/9NiIjI9G3b188f/4c3t7eVsXl6+uLtWvXomnTpoiMjMSPP/6Iv/76CxUrVhQtX716daxatQorVqxAdHQ0xowZgwkTJhg1/VnSuHFj/P333/jnn39QtWpVNG3aFMeOHeOeX7p0KWrUqIE333wTMTExYIxh8+bNRs095vTr1w/ly5dHzZo14e/vj0OHDlk8Zr///js2b96MZcuWQalUwsPDA3/88QcWL17MJdpi+yXEEWTMUmMnIYQQQoiDUI0KIYQQQpwWJSqEEEIIcVqUqBBCCCHEaVGiQgghhBCnRYkKIYQQQpwWJSqEEEIIcVqUqBBCCCHEaVGiQgghhBCnRYkKIYQQQpwWJSqEEEIIcVqUqBBCCCHEaVGiQgghhBCn9X8/+VUjSGfLBgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(context_length), sample_cross_entropies.mean(axis=0))\n",
    "plt.hlines(sample_cross_entropies.mean(), 0, context_length, color='black', linestyle='dashed')\n",
    "plt.title('Cross-entropy is lower when there is more context')\n",
    "plt.ylabel('Average cross-entropy per token (nats)')\n",
    "plt.xlabel('Number of tokens of context');\n",
    "\n",
    "print(f'''Loss at 1 token of context: {sample_cross_entropies[:,0].mean():0.2f} nats/token\n",
    "Loss at 20 tokens of context: {sample_cross_entropies[:,19].mean():0.2f} nats/token\n",
    "Loss at {context_length} tokens of context: {sample_cross_entropies[:,-1].mean():0.2f} nats/token\n",
    "\n",
    "Average over all context windows: {sample_cross_entropies.mean():0.2f} nats/token''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a31239-6f57-4b62-8f2a-60ce39f79d30",
   "metadata": {},
   "source": [
    "That's because they have less context; the first position only has one token of context $P(t_2 \\vert t_1)$ (we don't estimate $P(t_1)$ here, we'll come back to this when we look at multiple texts) - it's very difficult to guess what comes after 1 token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c7d8fb4e-33d0-4542-bbf5-fd0e8a6d0959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and\n",
      "\n",
      "↵\n",
      "\n",
      " \n",
      "\n",
      " designs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in tokenizer.batch_decode(input_ids[:,:1]):\n",
    "    print(t.replace('\\n', '↵') + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05a5ed-a184-4760-9214-3d26d2e3b85d",
   "metadata": {},
   "source": [
    "When you've got more context you have some chance of guessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "46c64f7c-0564-49cb-8f04-b4053af1f896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and punctuation, we made some cuts in the manuscript, I feeling that Ernest would surely have made them himself.  The book is all Ernest's\n",
      "\n",
      "↵[[Category:Condensed matter physics| ]]↵&lt;!-- [[Category:Physics]] redundant supercat --&gt;↵\n",
      "\n",
      "   <title>Hellbender</title>↵    <id>14465</id>↵    <revision>\n",
      "\n",
      " designs. Recently, several manufacturers are offering built modules ready to be integrated in audio systems.↵An early and prolific area of application is high-powered\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in tokenizer.batch_decode(input_ids[:,:30]):\n",
    "    print(t.replace('\\n', '↵') + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c066fad-b101-4eac-add4-7b46298ff058",
   "metadata": {},
   "source": [
    "Looking at the histogram of cross-entropies the model doesn't always make good predictions even with 30 tokens of context, but the predictions are often much more likely than with 1 token of context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "611a44f1-cb67-459b-94bf-721818bfcfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sample_cross_entropies[:,0], bins=20, label='1 token of context')\n",
    "plt.hist(sample_cross_entropies[:,29], bins=20, label='30 tokens of context', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('Predictions are better with more context')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Cross-entropy (nats/token)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30dbed-f8aa-4ab7-9703-5ca9be742c9b",
   "metadata": {},
   "source": [
    "### Striding across the text\n",
    "\n",
    "One way to really compress the text within a transformer's finite-window is to split the text into blocks and compress each block, of fixed size separately.\n",
    "To maximise compression we can have the blocks overlap to increase the amount of context, only compressing new section in each block.\n",
    "This increases the number of blocks but also compresses the text much more effectively.\n",
    "Note that for a model like an RNN, RWKV, or Mamba we don't need to have these blocks since the hidden state can be propagated along the whole length of text.\n",
    "\n",
    "As an example suppose we had a maximum context length of 8 tokens, and wanted to always have a context length of at least 3 tokens (that is the overlap between this window and the previous is 3 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "616d4e40-1509-407d-8d1e-0b04d44e03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 8\n",
    "min_context = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f910a52-f79e-46eb-bcc3-7276689838cf",
   "metadata": {},
   "source": [
    "The first block covers the tokens in positions (there's no additional context to look back to):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4b199b89-d205-4bcd-a8c1-e3ecbc46f806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "end_idx = max_tokens\n",
    "\n",
    "idx, end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce9366-dae2-469b-9601-de702cb345f4",
   "metadata": {},
   "source": [
    "We get the corresponding tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f4ba3a9-69e3-4b3a-96cd-3bcef8c13b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokens[idx:idx+max_tokens].to(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49166971-27b4-4eb0-9d26-5628d6f030e0",
   "metadata": {},
   "source": [
    "And targets (next tokens):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b728cecb-29e6-4634-86ac-815ffbd396d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = tokens[idx+1:end_idx+1].to(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b688fb5-d7bb-47c4-947a-7f055deb4673",
   "metadata": {},
   "source": [
    "Then calculate the logits and total cross-entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "992cfbe9-60dc-4b07-8b46-5ea3c65a7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(input_ids).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2052f225-0a87-4ad1-8258-90819127103f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31.2013, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, target_ids, reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d24f6d-009b-43e1-b130-e711e4dba4c5",
   "metadata": {},
   "source": [
    "For the next block we want to start compressing the section where the last window ended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d22cfb44-3e69-4ec1-bcc1-0e126b498220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = end_idx\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33abc1c-86e4-462e-8670-1f8c9e9a97f3",
   "metadata": {},
   "source": [
    "But we want to look back `min_context` tokens for additional context for the next block (which we can also do at decompresion time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "08fd6eb1-464c-46d8-9679-4534cf42783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = idx - min_context\n",
    "start_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15151dc2-e66d-4bcd-9c8f-7069daa002a4",
   "metadata": {},
   "source": [
    "The block then ends `max_tokens` after this `start_idx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0e457e6f-5e53-4ebf-b387-8de7ff9ca500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_idx = start_idx + max_tokens\n",
    "end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917496d4-5f77-47d7-a942-35689b9df262",
   "metadata": {},
   "source": [
    "Our input tokens is then the whole block from `start_idx` to `end_idx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "45027d12-8fee-4066-89ca-7dcb21255e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5907,  2625,  4023,  1378,  2503,    13, 11431, 15466],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokens[start_idx:end_idx].to(model.device)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e928055-79c1-4199-aec0-97d8900db447",
   "metadata": {},
   "source": [
    "But our target is only over the section we want to compress, the tokens after `idx` through to `end_idx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6cf9b75a-071f-46fb-a81d-abf5f7bfab56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2503,    13, 11431, 15466,    13], device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ids = tokens[idx+1:end_idx+1].to(model.device)\n",
    "target_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd862d5e-ff86-49b7-9628-35eb1371586b",
   "metadata": {},
   "source": [
    "We get the model's predicted logits over the whole block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cce9802c-52d6-4664-b864-1bc227ed0544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50257])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(input_ids).logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765bb2b-98dd-4828-9dcc-e64c87682561",
   "metadata": {},
   "source": [
    "And calculate the total cross-entropy, but only over the target section we want to compress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7420a621-7c7f-4d4e-b6d8-1233fbfbf130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.4940, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = F.cross_entropy(logits[-len(target_ids):],\n",
    "                                target_ids,\n",
    "                                reduction='sum')\n",
    "cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc1e0c-665e-41b2-97a1-30abcdc1fe27",
   "metadata": {},
   "source": [
    "We would then continue on with the next end index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "60535dc5-c6af-4459-a6c1-e48811fc98c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = end_idx\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb284a86-797d-4774-8510-199be8a32442",
   "metadata": {},
   "source": [
    "We can put this all together in a function, taking particular care with the first block (where there's no context) and the last block (which may not be a full block).\n",
    "It would be more efficient to run inference in batches, but I do it one at a time because the code is simpler to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b554dcf5-1b44-4bd8-803c-f7874c1b355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stride_cross_entropy(tokens, max_tokens=1024, min_context=256):\n",
    "\n",
    "    if min_context >= max_tokens:\n",
    "        raise ValueError()\n",
    "    \n",
    "    cross_entropy = 0.\n",
    "\n",
    "    idx = 0\n",
    "    while idx < len(tokens):\n",
    "        start_idx = max(idx - min_context, 0)\n",
    "        end_idx = min(start_idx + max_tokens, len(tokens))\n",
    "        \n",
    "        input_ids = tokens[start_idx:end_idx].to(model.device)\n",
    "        target_ids = tokens[idx+1:end_idx+1].to(model.device)\n",
    "    \n",
    "        with torch.inference_mode():\n",
    "            logits = model(input_ids).logits[-len(target_ids):]\n",
    "            cross_entropy += F.cross_entropy(logits[-len(target_ids):],\n",
    "                                             target_ids,\n",
    "                                             reduction='sum').item()\n",
    "    \n",
    "        idx = end_idx\n",
    "\n",
    "    return cross_entropy / len(tokens)\n",
    "        \n",
    "cross_entropy_windowed = stride_cross_entropy(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd226aed-53e7-4e9d-90b9-3b5ee777eac7",
   "metadata": {},
   "source": [
    "We can then calculate the entropy with a context of 256 tokens over a window of 1024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cf805942-ade7-4b8c-837e-e10d9d62cfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9813043866209555"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_byte * cross_entropy_windowed / math.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c69d6fe-d1b2-430e-b237-58272fa02ac2",
   "metadata": {},
   "source": [
    "If we increase the amount of context to 768 we get something just a little higher than the claimed 0.93 (I don't run the maximum 1023 because it will take a very long time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d5733fbe-4388-4b5f-a00a-82542c04e2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688098539751745"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_768 = stride_cross_entropy(tokens, min_context=768)\n",
    "tokens_per_byte * cross_entropy_768 / math.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ae622-5e58-42bd-95e3-0ca55c18d4a3",
   "metadata": {},
   "source": [
    "# Comparing Language Model Metrics\n",
    "\n",
    "I hope this article makes it easier to understand the links between different compression metrics, but also the subtlety in comparing metrics across models.\n",
    "When comparing perplexity or average cross-entropy it's important to know the same tokenization was used across models and for cross-entropy knowing the unit (base of logarithm used).\n",
    "The metrics bits-per-byte and bits-per-character are easier to compare (as long as you know the text encoding), since they are the cross-entropy in base 2, averaged over the bytes/characters respectively.\n",
    "When calculating perplexity for transformer models you have to take into account the sequence length used, and for long texts the amount of context used in each window (the more context the better the metrics, but the slower the evaluation).\n",
    "\n",
    "Older language modelling datasets have a fixed-word vocabulary and anything outside is represented with an unknown token (like `<UNK>`), and it's a little subtle how you calculate the cross-entropy of this token; it's technically infinite, but you could either skip it or explicitly assign a probability to it.\n",
    "The advantage of a BPE tokenizer in GPT-2 is all possible byte strings can be encoded and decoded, and should have a non-zero probability.\n",
    "However if you wanted to compare results on these datasets fairly you would need to know how they score out of vocabulary tokens.\n",
    "\n",
    "For datasets with multiple texts you need to decide whether you micro-average or macro-average the results.\n",
    "Typically in the loss function and metrics the results are micro-averaged, that is you calculate the cross-entropy loss across the whole dataset and divide by the total number of tokens.\n",
    "This gives a good estimate of the compressibility of the whole dataset, but it puts more weight on longer texts with more tokens.\n",
    "An alternative would be to macro-average the results; calculate the cross-entropy loss for each text separately and take the average of those losses; this is akin to averaging the compression ratios over lots of files.\n",
    "\n",
    "You should now have the tools to understand and compare the language modelling capabilities of real models, especially ones you train.\n",
    "Keep in mind that language modelling aims to minimise the cross-entropy loss on the *training corpus* and if you calculate cross-entropy loss on a corpus with a different distribution you will get a worse (higher) number; you might want to fine-tune it a little to make it more comparable.\n",
    "Also for instruction-tuned (or otherwise supervised fine-tuned) models the predictions get further from true probabalistic predictions of the likelihood of text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
